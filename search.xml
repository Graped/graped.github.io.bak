<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[使用ansible-playbook推送安装nginx]]></title>
    <url>%2F2018%2F10%2F11%2F%E4%BD%BF%E7%94%A8ansible-playbook%E6%8E%A8%E9%80%81%E5%AE%89%E8%A3%85nginx%2F</url>
    <content type="text"><![CDATA[使用ansible-playbook推送安装nginx 本文主要介绍了如何将ansible-playbook投入生产中，下面我们以推送安装nginx举例 1. 思路： 现在主机上编译，配置好nginx， 然后将安装程序目录打包 最后用ansible分发下去 2. 流程图如下： 3. 执行配置过程3.1 编译安装nginx详见： 编译安装Nginx3.2 创建ansible roles目录结构123cd /etc/ansible/mkdir -pv nginx_install/rolse/&#123;common,install&#125;/&#123;handlers,files,meta,tasks,templates,vars&#125; 说明： roles下有两个角色，common为一些准备操作，install为安装nginx的操作 每个角色下面又有6个目录， handlers 下面是当发生改变时，要执行的操作，通常用在配置文件发生改变，重启服务等 flies 为安装时用到的一些文件 meta 为说明信息，说明角色依赖等信息 tasks 里面为核心配置文件 templates 通常存一些配置文件，启动脚本等模板文件 vars 下为定义的变量 3.3 将安装好的nginx程序包打包，并放到 $/install/files/ 下面，启动脚本 放入$/install/templates中，123cp /etc/init.d/nginx /root/nginx_install/rolse/install/templates/nginxmv nginx.tar.gz /root/nginx_install/rolse/install/files/cp nginx/conf/nginx.conf /root/nginx_install/rolse/install/templates/ 3.4 在common目录下定义安装nginx的依赖包任务123456789cd common/tasksvim main.yml- name: install initaliztion require software #yum: name=&#123;&#123; items &#125;&#125; state=installed yum: name="pcre-devel,zlib-devel" #with_item # - zlib-devel # - prce-devel 3.5 定义变量12345cd install/vars/main.ymlnginx_user: wwwnginx_port: 80nginx_basedir: /usr/local/nginx 3.6 定义拷贝操作12345678910vim install/tasks/copy.yml- name: Copy Nginx Software copy: src=nginx.tar.gz dest=/tmp/nginx.tar.gz owner=root group=root- name: Uncommpreesion Nginx Software shell: tar -zxf /tmp/nginx.tar.gz -C /usr/local- name: Copy Nginx Start Scrpit template: src=nginx dest=/etc/init.d/nginx owner=root group=root mode=0755- name: Copy Nginx Config template: src=nginx.conf dest=&#123;&#123; nginx_basedir &#125;&#125;/conf/ owner=root group=root mode=0644 3.7 创建安装总线12345678910vim install/tasks/install.yml - name: Creat Nginx User user: name=&#123;&#123; nginx_user &#125;&#125; state=present createhome=no shell=/sbin/nologin- name: Start Nginx Service shell: /etc/init.d/nginx start- name: Add Boot Start Nginx Service shell: chkconfig --level 345 nginx on- name : Delete Nginx Commpression files shell: mv /tmp/nginx.tar.gz /tmp/old.tgz 3.8 创建执行总线1234vim install/tasks/main.yml- include: copy.yml- include: install.yml 3.9 创建入口配置文件vim install.yml --- - hosts: nginxlabs remote_user: root gather_facts: True roles: - common - install]]></content>
      <categories>
        <category>自动化运维</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible详解]]></title>
    <url>%2F2018%2F10%2F08%2FAnsible%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[[TOC] 一、Ansible介绍 不需要安装客户端，通过sshd去通信 基于模块工作，模块可以由任何语言开发 不仅支持命令行使用模块，也支持编写yaml格式的playbook，易于编写和阅读 安装十分简单，centos可直接yum安装 有提供UI（浏览器图形化）www.ansible.com/tower（收费） ansible已经被redhat公司收购，它在github上是一款非常受欢迎的开源软件，Github地址：https://github.com/ansible/ansible 一本非常不错的入门电子书 https://ansible-book.gitbooks.io/ansible-first-book/ 1.Ansible的安装配置 本次试验的环境 server1 GrapedLinux: CentOS 7.3 192.168.22.76 server2 Linux-Test1：CentOS 7.3 192.168.22.77 server3 Linux-Test2：CentOS 7.3 192.168.22.78 1.1 yum安装ansible123456yum list | grep ansibleansible.noarch 2.4.2.0-2.el7 extras ansible-doc.noarch 2.4.2.0-2.el7 extras # 官方文档# 可以看见自带的源里就有2.4版本的ansibleyum install -y ansible* # 安装ansible 2.配置ansible2.1 在server1 上生成公钥123456789101112131415161718192021ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:8e:a1:f5:d7:cf:fe:c2:d9:9b:f8:1e:4c:ac:2b:c2:7c root@GrapedLinuxThe key's randomart image is:+--[ RSA 2048]----+| || || || . || o S o || o = . + || . . = . .o = || = E o* +|| o .+*Bo|+-----------------+ 2.2 ssh-copy-id命令来复制Ansible公钥到本机和server2节点中,server3节点不做处理。复制到本机123456789101112ssh-copy-id -i ~/.ssh/id_rsa.pub root@127.0.0.1 The authenticity of host '127.0.0.1 (127.0.0.1)' can't be established. ECDSA key fingerprint is 96:ed:84:e0:0f:c1:71:62:fc:c3:29:fd:31:ae:8c:98.Are you sure you want to continue connecting (yes/no)? yes/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@127.0.0.1's password: Number of key(s) added: 1Now try logging into the machine, with: "ssh 'root@127.0.0.1'"and check to make sure that only the key(s) you wanted were added. 复制到server1 123456789ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.22.77# server1/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@192.168.22.77's password: Number of key(s) added: 1Now try logging into the machine, with: "ssh 'root@192.168.22.77'"and check to make sure that only the key(s) you wanted were added. 2.3 修改vi /etc/ansible/hosts12345vim /etc/ansible/hosts# 添加一下内容，其中Ansible-Test是组名[Ansible-Test]127.0.0.1192.168.22.77 至此，Ansible的配置工作已经结束，下面我们来看看怎么使用Ansible 3. 使用Ansible远程执行命令exp1 通过选择主机组的方式在远程机器上执行基础命令 exp2 通过IP/主机名的形式，在单独一台机器上执行基础命令 3.1 有时候会遇见如下图报错 这是由于server3的主机selinux没有关闭 解决办法是： 关闭selinux 安装libselinux-python 4. 使用Ansible 远程执行脚本exp3 通过选择主机组的方式在远程机器上执行脚本 需要注意的是： command 不支持带管道的命令，shell支持 5. 使用Ansible拷贝文件或者目录5.1 拷贝目录 5.1.1其中各参数表示的意义是： src表示源目录 dest表示目标目录 owner表示所属主 group表示所属组 mode表示权限 5.1.2 需要注意的是:源目录会放到目标目录下面去，如果目标指定的目录不存在，它会自动创建。如果拷贝的是文件 5.2 拷贝文件 5.2.2 需要注意的是：这里的/tmp/123和源机器上的/etc/passwd是一致的，但是如果目标机器上已经有了/tmp/123目录，则会在/tmp/123目录下面简历passwd文件 6. 使用ansible管理任务计划6.1 在serverr1上创建任务管理计划 6.2 查看在server1上创建的任务计划 6.3 删除在server1上创建的计划任务 6.4 查看server1上创建的计划任务是否已经被删除 6.5 注意，通过Ansible创建的计划任务不可以手工更改，否则之后就没法再进行其他操作了7. 使用ansible安装包和管理服务7.1 使用ansible安装httpd服务 7.2 使用ansible卸载httpd服务 7.3 使用ansible启动httpd服务 Anbsible Playbook详解 Ansible playbook相当于把模块写入到配置文件里面，例如： 1. 编写配置文件exp1:1234567vim /etc/ansible/labs.yml---- hosts: server1- remote_user: root- tasks: - name: labs - shell: echo `date` &gt;&gt; /tmp/time.txt 1.1配置文件说明 第一行需要有三个 - hosts参数指定了对哪些主机进行操作，如果是多台机器，可以用逗号分开，也可以使用主机组，在/etc/ansibl/hosts里定义 user参数制定了使用什么用户登录远程主机操作; tasks 指定了一个任务，其下面的name参数同样是对任务的描述，在执行过程中会打印出来，shell是ansible模块的名字 2. 执行nsible-playbook1ansible-play labs.yml 可以看到在server1上已经出现/tmp/time.txt 3. playbook里的变量3.1 编写创建用户Ansible Playbookexp2:123456789101112vim crean_user.yml---- name: crean_user hosts: server1 user: root gather_facts: false # 关闭facts vars: - user: "test" # 定义user变量 tasks: - name: creat_user user: name="&#123;&#123; user &#125;&#125;" # 引用user变量，“&#123;&#123;user&#125;&#125;” 相当于shell脚本中$user 执行结果如下： 4. playbook中的循环exp3:1234567891011vim while.yml ---- hosts: server1 user: root tasks: - name: change mode for files file: path=/tmp/&#123;&#123; item &#125;&#125; state=touch mode=600 # 创建/tmp/&#123;1,2,3&#125;.txt 并富裕600权限 with_items: # 循环对象 - 1.txt - 2.txt - 3.txt 执行结果如下 执行效果如下： 5. playbook中的条件判断exp4:123456789vim when.yml---- hosts: labs user: root gather_facts: true tasks: - name: use when shell: touch/tmp/when.txt;echo "`date`:the ip is real" &gt;&gt; /tmp/when.txt when: ansible_ens33.ipv4.address == "192.168.22.77" 执行结果如下： 执行效果如下： 6. playbook中的handers handers 类似于shell中的 command1 &amp;&amp; command2 exp5:1234567891011---- name: handlers test hosts: server1 user: root tasks: - name: copy file copy: src=/etc/passwd dest=/tmp/password notify: test handlers handlers: # 上一步执行成功后，再执行下一步 - name: test handlers shell: echo "copy finish" &gt;&gt; /tmp/password 执行结果如下： 执行效果如下：]]></content>
      <tags>
        <tag>Linux,Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修改Windows实例SID以搭建域环境]]></title>
    <url>%2F2018%2F10%2F07%2F18100602%2F</url>
    <content type="text"><![CDATA[[TOC] 修改Windows实例SID以搭建域环境使用同一个Windows镜像创建的几台实例之间无法互相访问域或者无法同时加入域。 原因分析使用同一个Windows镜像的几台实例，其SID（计算机安全标识符Security Identifier）是一样的。此时需要修改系统SID，以避免无法相互访问域，再进行域环境的搭建。 解决方法Windows系统自带sysprep命令可以从已安装的Windows映像删除所有系统特定的信息，其中包括SID。脚本工具sysprep.ps1使用系统自带sysprep命令完成修改Windows SID。本文描述如何使用脚本工具sysprep.ps1修改系统SID。文档描述的内容适用于Windows Server 2008、Windows Server 2012和Windows Server 2016系统。 注意： 在修改系统SID前，建议您为系统盘创建快照，避免意外失败导致系统崩溃。 sysprep会将User Profile恢复为默认值，执行sysprep后会删除桌面上创建的文件。如果您希望执行脚本后自动删除，可以将文件放置在桌面上执行。 修改系统SID按以下步骤修改系统SID。 远程连接Windows实例。 下载脚本工具 sysprep.ps1，存放在C盘。 启动CMD，运行命令 powershell。 注意：如果您不是管理员用户，必须以管理员身份运行PowerShell。 运行命令 cd\ 切换路径到C盘根目录。 运行命令 .\Sysprep.ps1 -help 查看脚本说明。 查看脚本说明参数说明： 参数 说明 -skiprearm 默认将Windows操作系统恢复到原始授权许可状态，如不需恢复，添加该参数。 -ReserveNetwork 运行脚本后保留经典网络实例的网络配置信息（IP、Subnet、Gateway、DNS），不会变动VPC网络类型ECS实例使用DHCP获取IP的配置。 -skippassword 使用默认密码 -ReserveHostname 保持主机名不变 -post_action 运行脚本后的后续操作。取值范围：shutdown,reboot,quit 运行命令 whoami /user 查看系统SID。1WhoAmIUser 运行命令12345678910111213141516.\Sysprep.ps1 -ReserveHostname -ReserveNetwork -skiprearm -post_action "reboot" ``` - 在弹窗中输入密码，并单击 确定，使实例自动重启。![image2](https://s1.ax1x.com/2018/10/09/iJqVVP.png)- [远程连接Windows实例。](https://help.aliyun.com/document_detail/25435.html?spm=a2c4g.11186623.2.14.21844abaGxsHT4)运行命令 重新查看系统SID。```powershellwhoami /user 注意事项如果没有特定要求，运行以下命令时您需要修改密码。1powershell -executionpolicy bypass -file c:\sysprep.ps1 -ReserveHostname -ReserveNetwork -skiprearm -post_action "reboot"]]></content>
      <tags>
        <tag>Windows server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bond绑定双网卡]]></title>
    <url>%2F2018%2F10%2F06%2F18100601%2F</url>
    <content type="text"><![CDATA[bond绑定双网卡 本文说明： 为什么要做bond0 &lt;a href=”https://zhidao.baidu.com/question/294361679.html target=”_blank”&gt;点击跳转 配置bond0编辑配置文件 编辑虚拟网卡band0的配置文件ifcfg-bond0,加入以下内容：示例如下: 12345678910#cat ifcfg-bond0 #需要我们手工创建DEVICE=bond0TYPE=EthernetONBOOT=yesBOOTPROTO=staticIPADDR=10.0.0.10NETMASK=255.255.255.0DNS2=4.4.4.4GATEWAY=10.0.0.2DNS1=10.0.0.2 编辑各个网卡的配置文件，这里用eth1和eth2。ens32: 12345678#cat ifcfg-ens32DEVICE=eth0TYPE=EthernetONBOOT=yesBOOTPROTO=noneMASTER=bond0SLAVE=yes #可以没有此字段，就需要开机执行ifenslave bond0 ens32 ens34命令了。BONDING_OPTS="mode=0 miimon=100" ens34: 12345678#cat ifcfg-ens34DEVICE=eth1TYPE=EthernetONBOOT=yesBOOTPROTO=noneMASTER=bond0SLAVE=yesBONDING_OPTS="mode=0 miimon=100" 系统加载bond 配置bonding驱动 123#vi /etc/modprobe.d/bond.confalias bond0 bindingoptions bond0 miimon=100 mode=0 centos7默认没有加bonding内核模板，需要手工加载，加载方式 1modprobe --first-time bonding bond0验证 重启网卡后，可以使用 123456789101112131415161718192021222324#cat /proc/net/bonding/bond0Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)Bonding Mode: load balancing (round-robin)MII Status: upMII Polling Interval (ms): 0Up Delay (ms): 0Down Delay (ms): 0Slave Interface: ens32MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 00:50:56:bf:55:22Slave queue ID: 0Slave Interface: ens34MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 00:50:56:bf:4a:64Slave queue ID: 0 来查看bond的状态。如上图，即为绑定成功。 bond的七种模式 概览目前网卡绑定mode共有七种(0~6)bond0、bond1、bond2、bond3、bond4、bond5、bond6 常用的有三种: mode=0：平衡负载模式，有自动备援，但需要”Switch”支援及设定。 mode=1：自动备援模式，其中一条线若断线，其他线路将会自动备援。 mode=6：平衡负载模式，有自动备援，不必”Switch”支援及设定。 说明: 需要说明的是如果想做成mode 0的负载均衡,仅仅设置这里optionsbond0 miimon=100 mode=0是不够的,与网卡相连的交换机必须做特殊配置（这两个端口应该采取聚合方式），因为做bonding的这两块网卡是使用同一个MAC地址.从原理分析一下（bond运行在mode0下）： mode 0下bond所绑定的网卡的IP都被修改成相同的mac地址，如果这些网卡都被接在同一个交换机，那么交换机的arp表里这个mac地址对应的端口就有多 个，那么交换机接受到发往这个mac地址的包应该往哪个端口转发呢？正常情况下mac地址是全球唯一的，一个mac地址对应多个端口肯定使交换机迷惑了。所以 mode0下的bond如果连接到交换机，交换机这几个端口应该采取聚合方式（cisco称为 ethernetchannel，foundry称为portgroup），因为交换机做了聚合后，聚合下的几个端口也被捆绑成一个mac地址.我们的解 决办法是，两个网卡接入不同的交换机即可。 mode6模式下无需配置交换机，因为做bonding的这两块网卡是使用不同的MAC地址。 七种bond模式说明：第一种模式：mod=0 ，即：(balance-rr)Round-robin policy（平衡抡循环策略）特点： 传输数据包顺序是依次传输（即：第1个包走eth0，下一个包就走eth1….一直循环下去，直到最后一个传输完毕），此模式提供负载平衡和容错能力；但是我们知道如果一个连接或者会话的数据包从不同的接口发出的话，中途再经过不同的链路，在客户端很有可能会出现数据包无序到达的问题，而无序到达的数据包需要重新要求被发送，这样网络的吞吐量就会下降 第二种模式：mod=1，即： (active-backup)Active-backup policy（主-备份策略）特点： 只有一个设备处于活动状态，当一个宕掉另一个马上由备份转换为主设备。mac地址是外部可见得，从外面看来，bond的MAC地址是唯一的，以避免switch(交换机)发生混乱。此模式只提供了容错能力；由此可见此算法的优点是可以提供高网络连接的可用性，但是它的资源利用率较低，只有一个接口处于工作状态，在有 N 个网络接口的情况下，资源利用率为1/N 第三种模式：mod=2，即：(balance-xor)XOR policy（平衡策略）特点： 基于指定的传输HASH策略传输数据包。缺省的策略是：(源MAC地址 XOR 目标MAC地址)% slave数量。其他的传输策略可以通过xmit_hash_policy选项指定，此模式提供负载平衡和容错能力 第四种模式：mod=3，即：broadcast（广播策略）特点： 在每个slave接口上传输每个数据包，此模式提供了容错能力 第五种模式：mod=4，即：(802.3ad)IEEE 802.3ad Dynamic link aggregation（IEEE802.3ad 动态链接聚合）特点： 创建一个聚合组，它们共享同样的速率和双工设定。根据802.3ad规范将多个slave工作在同一个激活的聚合体下。外出流量的slave选举是基于传输hash策略，该策略可以通过xmit_hash_policy选项从缺省的XOR策略改变到其他策略。需要注意的 是，并不是所有的传输策略都是802.3ad适应的，尤其考虑到在802.3ad标准43.2.4章节提及的包乱序问题。不同的实现可能会有不同的适应 性。 ==必要条件==： 条件1：ethtool支持获取每个slave的速率和双工设定 条件2：switch(交换机)支持IEEE802.3ad Dynamic link aggregation 条件3：大多数switch(交换机)需要经过特定配置才能支持802.3ad模式 第六种模式：mod=5，即：(balance-tlb)Adaptive transmit load balancing（适配器传输负载均衡）特点： 不需要任何特别的switch(交换机)支持的通道bonding。在每个slave上根据当前的负载（根据速度计算）分配外出流量。如果正在接受数据的slave出故障了，另一个slave接管失败的slave的MAC地址。==该模式的必要条件：== ethtool支持获取每个slave的速率 第七种模式：mod=6，即：(balance-alb)Adaptive load balancing（适配器适应性负载均衡）特点： 该模式包含了balance-tlb模式，同时加上针对IPV4流量的接收负载均衡(receiveload balance, rlb)，而且不需要任何switch(交换机)的支持。接收负载均衡是通过ARP协商实现的。bonding驱动截获本机发送的ARP应答，并把源硬件地址改写为bond中某个slave的唯一硬件地址，从而使得不同的对端使用不同的硬件地址进行通信。来自服务器端的接收流量也会被均衡。当本机发送ARP请求时，bonding驱动把对端的IP信息从ARP包中复制并保存下来。当ARP应答从对端到达时，bonding驱动把它的硬件地址提取出来，并发起一个ARP应答给bond中的某个slave。使用ARP协商进行负载均衡的一个问题是：每次广播 ARP请求时都会使用bond的硬件地址，因此对端学习到这个硬件地址后，接收流量将会全部流向当前的slave。这个问题可以通过给所有的对端发送更新（ARP应答）来解决，应答中包含他们独一无二的硬件地址，从而导致流量重新分布。当新的slave加入到bond中时，或者某个未激活的slave重新 激活时，接收流量也要重新分布。接收的负载被顺序地分布（roundrobin）在bond中最高速的slave上当某个链路被重新接上，或者一个新的slave加入到bond中，接收流量在所有当前激活的slave中全部重新分配，通过使用指定的MAC地址给每个 client发起ARP应答。下面介绍的updelay参数必须被设置为某个大于等于switch(交换机)转发延时的值，从而保证发往对端的ARP应答 不会被switch(交换机)阻截。==必要条件==： 条件1：ethtool支持获取每个slave的速率； 条件2：底层驱动支持设置某个设备的硬件地址，从而使得总是有个slave(curr_active_slave)使用bond的硬件地址，同时保证每个 bond 中的slave都有一个唯一的硬件地址。如果curr_active_slave出故障，它的硬件地址将会被新选出来的 curr_active_slave接管其实mod=6与mod=0的区别：mod=6，先把eth0流量占满，再占eth1，….ethX；而mod=0的话，会发现2个口的流量都很稳定，基本一样的带宽。而mod=6，会发现第一个口流量很高，第2个口只占了小部分流量]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Galera：多主同步MySQL集群原理解析]]></title>
    <url>%2F2017%2F05%2F08%2F17050801%2F</url>
    <content type="text"><![CDATA[Galera Cluster 实现mysql群集参考：http://blog.itpub.net/14431099/viewspace-1316643/ http://lovestoned.blog.51cto.com/2904444/1617817http://www.itbaofeng.com/?p=59http://lansgg.blog.51cto.com/5675165/1180305http://www.yunweipai.com/archives/19574.html 1. MySQL Galera介绍 MySQL/Galera是MySQL/InnoDB的多主集群,有以下特性: 同步复制 Active-active的多主拓扑结构 集群任意节点可以读和写 自动身份控制,失败节点自动脱离集群 自动节点接入 真正的基于”行”级别和ID检查的并行复制 客户端连接跟操作单台MySQL数据库的体验一致 总结下来，官网上给出了大概以上等数条优势，总结下来就是两个比较突出的点：多主和同步。多主：Galera Cluster没有MySQL主从集群只有一个主能提供写服务的限制，集群中每个节点都可读可写，无需读写分离。在一个Galera Cluster前直接部署HAProxy做读写负责均衡是比较常用的做法。同步：Galera replication具有实时性，能够保障不同节点的数据视图在较小的时间范围内是一致的。MySQL原生replication方案slave中的SQL线程和IO线程是分离的，即便使用半同步甚至同步复制，也可能因为SQL线程的速度跟不上IO线程而导致slave数据落后很多，当然5.7引入并行复制后会好很多，而Galera中除了具有并行复制的功能外，还具有flow control的功能来控制节点间数据同步的速度。 Galera本质是一个wsrep提供者（provider），运行依赖于wsrep的API接口。Wsrep API定义了一系列应用回调和复制调用库，来实现事务数据库同步写集(writeset)复制以及相似应用。目的在于从应用细节上实现抽象的，隔离的复制。虽然这个接口的主要目标是基于认证的多主复制，但同样适用于异步和同步的主从复制。 2. MySQL Galera安装安装前准备 机器准备(虚拟机) master 192.168.137.128 backup 192.168.137.129 joiner 192.168.137.130 安装依赖 确认安装有gcc和gcc-c++的版本最少为4.4 1yum install -y gcc gcc-c++ 确认安装有boost-devel的版本至少为1.4.1 1yum install -y boost-devel 安装scons check-devel openssl-devel 1yum install -y scons check-devel openssl-devel MySQL Galera安装（从网上拷贝了一份安装文档，里面的版本为5.5.29，所以这里暂时用5.5.29版本） 安装含wsrep Patch的MySQL 5.5.29 1234567891011yum install libaiowget https://launchpad.net/codership-mysql/5.5/5.5.29-23.7.3/+download/mysql-5.5.29_wsrep_23.7.3-linux-x86_64.tar.gztar zxvf mysql-5.5.29_wsrep_23.7.3-linux-x86_64.tar.gz mv mysql-5.5.29_wsrep_23.7.3-linux-x86_64 /usr/local/mysqlcd /usr/local/mysql/groupadd mysqluseradd -r -g mysql mysqlchown -R mysql:mysql ../scripts/mysql_install_db --no-defaults --datadir=/usr/local/mysql/data --user=mysqlchown -R root .chown -R mysql data 安装Galera复制插件 123456wget https://launchpad.net/galera/2.x/23.2.4/+download/galera-23.2.4-src.tar.gztar zxvf galera-23.2.4-src.tar.gzcd galera-23.2.4-srcsconscp garb/garbd /usr/local/mysql/bin/cp libgalera_smm.so /usr/local/mysql/lib/plugin/ MySQL Galera配置 MySQL Galera配置例子: 12345678910111213141516171819202122232425262728293031323334353637383940414243 cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld mkdir -p /var/lib/mysql chown mysql:mysql /var/lib/mysql vi /etc/my.cnf cat /etc/my.cnf [client]port = 3306socket = /var/lib/mysql/mysql.sock[mysqld_safe]log-error = /var/lib/mysql/mysql.logpid-file = /var/lib/mysql/mysql.pid[mysqld]wsrep_node_name = node1wsrep_provider = /usr/local/mysql/lib/plugin/libgalera_smm.so#wsrep_provider_options =&apos;gcache.size=1G;socket.ssl_key=my_key;socket.ssl_cert=my_cert&apos;#wsrep_slave_threads=16wsrep_sst_method = rsync#wsrep_sst_auth=root:port = 3306socket = /var/lib/mysql/mysql.sockuser = mysqlbasedir = /usr/local/mysqldatadir = /usr/local/mysql/datadefault_storage_engine=InnoDB#innodb_buffer_pool_size=1G#innodb_log_file_size=256Minnodb_autoinc_lock_mode=2innodb_locks_unsafe_for_binlog=1innodb_flush_log_at_trx_commit=0innodb_doublewrite=0innodb_file_per_table=1binlog_format=ROWlog-bin=mysql-binserver-id=101relay-log=mysql-relay-bin#read_only=1log-slave-updates=1 注：以上配置，参考与Mysql wsrep 参数 Mysql Galera启动与关闭 初次启动 123456/usr/local/mysql/bin/mysqld_safe --wsrep_cluster_address=gcomm:// &gt;/dev/null &amp;# 或service mysql start --wsrep_cluster_address=gcomm://# ”gcomm://”是特殊的地址,仅仅是galera cluster初始化启动时候使用,再次启动的时候需要使用具体的IP地址. 启动完成后发现mysqld的监听端口有两个123[root@master ~]# netstat -plantu | grep mysqldtcp 0 0 0.0.0.0:4567 0.0.0.0:* LISTEN 3656/mysqld tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN 3656/mysqld 这里4567端口是wsrep 使用的默认端口。 MySQL Galera新节点 节点接入添加新节点的时候,新接入的节点叫Joiner,给joiner提供复制的节点叫Donor.新的节点接入需要: 安装带wsrep patch的MySQL版本 安装Galera复制插件 配置好新节点的MySQL(参考Donnor的my.cnf) 配置或启动的gcomm://的地址是需要使用donnor的IP. 接入节点backup：1/usr/local/mysql/bin/mysqld_safe --wsrep_cluster_address=&quot;gcomm://192.168.137.128:4567,192.168.137.130:4567&quot; &gt;/dev/null &amp; 接入节点joiner:1service mysql start --wsrep_cluster_address=&quot;gcomm://192.168.137.128:4567,192.168.137.129:4567&quot; 修改节点的wsrep_cluster_address修改wsrep_cluster_address有两种方式: i. 使用新的wsrep_cluster_address重启节点:1service mysql restart --wsrep_cluster_address=&quot;gcomm://192.168.137.129:4567,192.168.137.130:4567&quot; ii. 直接修改MySQL全局变量 1234567891011121314151617mysql&gt; SHOW VARIABLES LIKE &apos;wsrep_cluster_address&apos;;+-----------------------+----------------------------+| Variable_name | Value |+-----------------------+----------------------------+| wsrep_cluster_address | gcomm://192.168.137.129:4567 |+-----------------------+----------------------------+1 row in set (0.00 sec)mysql&gt; set global wsrep_cluster_address=&quot;gcomm://192.168.137.129:4567,192.168.137.130:4567&quot;; Query OK, 0 rows affected (2.20 sec)mysql&gt; SHOW VARIABLES LIKE &apos;wsrep_cluster_address&apos;;+-----------------------+-------------------------------------------------------+| Variable_name | Value |+-----------------------+-------------------------------------------------------+| wsrep_cluster_address | gcomm://192.168.137.129:4567,192.168.137.130:4567 |+-----------------------+-------------------------------------------------------+1 row in set (0.00 sec) MySQL Galera监控 查看相关变量 查看MySQL版本: 1234567mysql&gt; SHOW GLOBAL VARIABLES LIKE &apos;version&apos;;+---------------+------------+| Variable_name | Value |+---------------+------------+| version | 5.5.29-log |+---------------+------------+1 row in set (0.00 sec) 查看wsrep版本: 1234567mysql&gt; SHOW GLOBAL STATUS LIKE &apos;wsrep_provider_version&apos;;+------------------------+------------+| Variable_name | Value |+------------------------+------------+| wsrep_provider_version | 2.4(rXXXX) |+------------------------+------------+1 row in set (0.00 sec) 查看wsrep有关的所有变量:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101mysql&gt; SHOW VARIABLES LIKE &apos;wsrep%&apos; \G*************************** 1. row ***************************Variable_name: wsrep_OSU_method Value: TOI*************************** 2. row ***************************Variable_name: wsrep_auto_increment_control Value: ON*************************** 3. row ***************************Variable_name: wsrep_causal_reads Value: OFF*************************** 4. row ***************************Variable_name: wsrep_certify_nonPK Value: ON*************************** 5. row ***************************Variable_name: wsrep_cluster_address Value: gcomm://192.168.1.222:4567,192.168.1.223:4567*************************** 6. row ***************************Variable_name: wsrep_cluster_name Value: my_wsrep_cluster*************************** 7. row ***************************Variable_name: wsrep_convert_LOCK_to_trx Value: OFF*************************** 8. row ***************************Variable_name: wsrep_data_home_dir Value: /usr/local/mysql/data/*************************** 9. row ***************************Variable_name: wsrep_dbug_option Value: *************************** 10. row ***************************Variable_name: wsrep_debug Value: OFF*************************** 11. row ***************************Variable_name: wsrep_drupal_282555_workaround Value: OFF*************************** 12. row ***************************Variable_name: wsrep_forced_binlog_format Value: NONE*************************** 13. row ***************************Variable_name: wsrep_log_conflicts Value: OFF*************************** 14. row ***************************Variable_name: wsrep_max_ws_rows Value: 131072*************************** 15. row ***************************Variable_name: wsrep_max_ws_size Value: 1073741824*************************** 16. row ***************************Variable_name: wsrep_mysql_replication_bundle Value: 0*************************** 17. row ***************************Variable_name: wsrep_node_address Value: *************************** 18. row ***************************Variable_name: wsrep_node_incoming_address Value: AUTO*************************** 19. row ***************************Variable_name: wsrep_node_name Value: node1*************************** 20. row ***************************Variable_name: wsrep_notify_cmd Value: *************************** 21. row ***************************Variable_name: wsrep_on Value: ON*************************** 22. row ***************************Variable_name: wsrep_provider Value: /usr/local/mysql/lib/plugin/libgalera_smm.so*************************** 23. row ***************************Variable_name: wsrep_provider_options Value: base_host = 192.168.1.221; base_port = 4567; cert.log_conflicts = no; evs.causal_keepalive_period = PT1S; evs.debug_log_mask = 0x1; evs.inactive_check_period = PT0.5S; evs.inactive_timeout = PT15S; evs.info_log_mask = 0; evs.install_timeout = PT15S; evs.join_retrans_period = PT1S; evs.keepalive_period = PT1S; evs.max_install_timeouts = 1; evs.send_window = 4; evs.stats_report_period = PT1M; evs.suspect_timeout = PT5S; evs.use_aggregate = true; evs.user_send_window = 2; evs.version = 0; evs.view_forget_timeout = PT5M; gcache.dir = /usr/local/mysql/data/; gcache.keep_pages_size = 0; gcache.mem_size = 0; gcache.name = /usr/local/mysql/data//galera.cache; gcache.page_size = 128M; gcache.size = 128M; gcs.fc_debug = 0; gcs.fc_factor = 1; gcs.fc_limit = 16; gcs.fc_master_slave = NO; gcs.max_packet_size = 64500; gcs.max_throttle = 0.25; gcs.recv_q_hard_limit = 9223372036854775807; gcs.recv_q_soft_limit = 0.25; gcs.sync_donor = NO; gmcast.listen_addr = tcp://0.0.0.0:4567; gmcast.mcast_addr = ; gmcast.mcast_ttl = 1; gmcast.peer_timeout = PT3S; gmcast.time_wait = PT5S; gmcast.version = 0; ist.recv_addr = 192.168.1.221; pc.checksum = true; pc.ignore_quorum = false; pc.ignore_sb = false; pc.linger = PT20S; pc.npvo = false; pc.version = 0; pc.weight = 1; protonet.backend = asio; protonet.version = 0; replicator.causal_read_timeout = PT30S; replicator.commit_order = 3*************************** 24. row ***************************Variable_name: wsrep_recover Value: OFF*************************** 25. row ***************************Variable_name: wsrep_replicate_myisam Value: OFF*************************** 26. row ***************************Variable_name: wsrep_retry_autocommit Value: 1*************************** 27. row ***************************Variable_name: wsrep_slave_threads Value: 2*************************** 28. row ***************************Variable_name: wsrep_sst_auth Value: *************************** 29. row ***************************Variable_name: wsrep_sst_donor Value: *************************** 30. row ***************************Variable_name: wsrep_sst_donor_rejects_queries Value: OFF*************************** 31. row ***************************Variable_name: wsrep_sst_method Value: rsync*************************** 32. row ***************************Variable_name: wsrep_sst_receive_address Value: AUTO*************************** 33. row ***************************Variable_name: wsrep_start_position Value: 80cdd13d-8cf2-11e2-0800-e0817023b754:033 rows in set (0.00 sec) 状态监控查看Galera集群状态: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546mysql&gt; show status like &apos;wsrep%&apos;;+----------------------------+----------------------------------------------------------+| Variable_name | Value |+----------------------------+----------------------------------------------------------+| wsrep_local_state_uuid | 80cdd13d-8cf2-11e2-0800-e0817023b754 || wsrep_protocol_version | 4 || wsrep_last_committed | 3 || wsrep_replicated | 3 || wsrep_replicated_bytes | 522 || wsrep_received | 6 || wsrep_received_bytes | 1134 || wsrep_local_commits | 1 || wsrep_local_cert_failures | 0 || wsrep_local_bf_aborts | 0 || wsrep_local_replays | 0 || wsrep_local_send_queue | 0 || wsrep_local_send_queue_avg | 0.000000 || wsrep_local_recv_queue | 0 || wsrep_local_recv_queue_avg | 0.000000 || wsrep_flow_control_paused | 0.000000 || wsrep_flow_control_sent | 0 || wsrep_flow_control_recv | 0 || wsrep_cert_deps_distance | 1.000000 || wsrep_apply_oooe | 0.000000 || wsrep_apply_oool | 0.000000 || wsrep_apply_window | 1.000000 || wsrep_commit_oooe | 0.000000 || wsrep_commit_oool | 0.000000 || wsrep_commit_window | 1.000000 || wsrep_local_state | 4 || wsrep_local_state_comment | Synced || wsrep_cert_index_size | 5 || wsrep_causal_reads | 0 || wsrep_incoming_addresses | 192.168.1.221:3306,192.168.1.222:3306,192.168.1.223:3306 || wsrep_cluster_conf_id | 13 || wsrep_cluster_size | 3 || wsrep_cluster_state_uuid | 80cdd13d-8cf2-11e2-0800-e0817023b754 || wsrep_cluster_status | Primary || wsrep_connected | ON || wsrep_local_index | 0 || wsrep_provider_name | Galera || wsrep_provider_vendor | Codership Oy || wsrep_provider_version | 2.4(rXXXX) || wsrep_ready | ON |+----------------------------+----------------------------------------------------------+40 rows in set (0.00 sec) 监控状态说明 集群完整性检查: wsrep_cluster_state_uuid:在集群所有节点的值应该是相同的,有不同值的节点,说明其没有连接入集群. wsrep_cluster_conf_id:正常情况下所有节点上该值是一样的.如果值不同,说明该节点被临时”分区”了.当节点之间网络连接恢复的时候应该会恢复一样的值. wsrep_cluster_size:如果这个值跟预期的节点数一致,则所有的集群节点已经连接. wsrep_cluster_status:集群组成的状态.如果不为”Primary”,说明出现”分区”或是”split-brain”状况. 节点状态检查: wsrep_ready: 该值为ON,则说明可以接受SQL负载.如果为Off,则需要检查wsrep_connected. wsrep_connected: 如果该值为Off,且wsrep_ready的值也为Off,则说明该节点没有连接到集群.(可能是wsrep_cluster_address或wsrep_cluster_name等配置错造成的.具体错误需要查看错误日志) wsrep_local_state_comment:如果wsrep_connected为On,但wsrep_ready为OFF,则可以从该项查看原因. 复制健康检查: wsrep_flow_control_paused:表示复制停止了多长时间.即表明集群因为Slave延迟而慢的程度.值为0~1,越靠近0越好,值为1表示复制完全停止.可优化wsrep_slave_threads的值来改善. wsrep_cert_deps_distance:有多少事务可以并行应用处理.wsrep_slave_threads设置的值不应该高出该值太多. wsrep_flow_control_sent:表示该节点已经停止复制了多少次. wsrep_local_recv_queue_avg:表示slave事务队列的平均长度.slave瓶颈的预兆. 最慢的节点的wsrep_flow_control_sent和wsrep_local_recv_queue_avg这两个值最高.这两个值较低的话,相对更好. 检测慢网络问题: wsrep_local_send_queue_avg:网络瓶颈的预兆.如果这个值比较高的话,可能存在网络瓶 冲突或死锁的数目: wsrep_last_committed:最后提交的事务数目 wsrep_local_cert_failures和wsrep_local_bf_aborts:回滚,检测到的冲突数目]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker详解]]></title>
    <url>%2F2017%2F04%2F14%2F17041401%2F</url>
    <content type="text"><![CDATA[容器虚拟化–docker核心概念 镜像是一个只读的模板，类似于安装系统用到的那个iso文件，我们通过镜像来完成各种应用的部署。 docker容器镜像类似于操作系统，而容器类似于虚拟机本身。它可以被启动、开始、停止、删除等操作，每个容器都是相互隔离的。 docker仓库存放镜像的一个场所，仓库分为公开仓库和私有仓库。 最大的公开仓库是hub.docker.com，国内公开仓库http://dockerpool.com/ 安装centos6(6.5之前版本需要升级一下 yum update )12yum install -y epel-releaseyum install -y docker-io centos71yum install -y docker 启动docker1/etc/init.d/docker start 镜像管理123456789docker pull centos //从docker.com获取centos镜像，如果太慢，直接做个加速http://www.apelearn.com/bbs/thread-15126-1-1.htmldocker images //查看本地都有哪些镜像docker tag centos graped123 //为centos镜像设置标签为graped123，再使用docker images查看会多出来一行，改行的image id和centos的一样docker search (image-name) //从docker仓库搜索docker镜像，后面是关键词docker run -t -i centos /bin/bash //用下载到的镜像开启容器，-i表示让容器的标准输入打开，-t表示分配一个伪终端，要把-i -t 放到镜像名字前面当该镜像发生修改后，我们可以把该镜像提交重新生成一个新版本进行在本地。docker ps //查看运行的容器docker rmi centos //用来删除指定镜像， 其中后面的参数可以是tag，如果是tag时，实际上是删除该tag，只要该镜像还有其他tag，就不会删除该镜像。当后面的参数为镜像ID时，则会彻底删除整个镜像，连通所有标签一同删除docker ps -a //查看所有容器，包括已经退出的。 创建镜像-基于已有镜像的容器创建运行docker run后，进入到该容器中1docker exec -it f68 /bin/bash 我们做一些变更，比如安装一些东西，然后针对这个容器进行创建新的镜像123docker commit -m &quot;change somth&quot; -a &quot;somebody info&quot; image_id #例如：ocker commit -m &quot;install httpd&quot; -a &quot;Graped&quot; 2c74d574293f graped/centos 这个命令有点像svn的提交，-m 加一些改动信息，-a 指定作者相关信息 2c74d这一串为容器id，再后面为新镜像的名字。 创建镜像-基于本地模板导入模块获取，可以直接在网上下载一个模块 http://openvz.org/Download/templates/precreated 可惜速度并不快，假如我们下载了一个centos的模板 centos-5-x86.tar.gz 那么导入该镜像的命令为：1cat centos-6-x86_64-minimal.tar.gz |docker import - centos-6-x86_64 把现有镜像，导出为一个文件：1docker save -o centos_with_net.tar graped/centos 我们还可以用该文件恢复本地镜像：12docker load --input centos_net.tar #或者docker load &lt; centos_net.tar 上传镜像1docker push image_name]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL调优]]></title>
    <url>%2F2017%2F04%2F07%2F17040701%2F</url>
    <content type="text"><![CDATA[MySQL调优可以从几个方面来做： 架构层：做从库，实现读写分离； 系统层次：增加内存；给磁盘做raid0或者raid5以增加磁盘的读写速度；RAID相关可以重新挂载磁盘，并加上noatime参数，这样可以减少磁盘的i/o; MySQL本身调优：(1) 如果未配置主从同步，可以把bin-log功能关闭，减少磁盘i/o(2) 在my.cnf中加上skip-name-resolve,这样可以避免由于解析主机名延迟造成mysql执行慢(3) 调整几个关键的buffer和cache。调整的依据，主要根据数据库的状态来调试。如何调优可以参考5. 应用层次：查看慢查询日志，根据慢查询日志优化程序中的SQL语句，比如增加索引 调整几个关键的buffer和cache 1) key_buffer_size 首先可以根据系统的内存大小设定它，大概的一个参考值：1G以下内存设定128M；2G/256M; 4G/384M;8G/1024M；16G/2048M.这个值可以通过检查状态值Key_read_requests和 Key_reads,可以知道key_buffer_size设置是否合理。比例key_reads / key_read_requests应该尽可能的低，至少是1:100，1:1000更好(上述状态值可以使用SHOW STATUS LIKE ‘key_read%’获得)。注意：该参数值设置的过大反而会是服务器整体效率降低! 2) table_open_cache 打开一个表的时候，会临时把表里面的数据放到这部分内存中，一般设置成1024就够了，它的大小我们可以通过这样的方法来衡量： 如果你发现 open_tables等于table_cache，并且opened_tables在不断增长，那么你就需要增加table_cache的值了(上述状态值可以使用SHOW STATUS LIKE ‘Open%tables’获得)。注意，不能盲目地把table_cache设置成很大的值。如果设置得太高，可能会造成文件描述符不足，从而造成性能不稳定或者连接失败。 3) sort_buffer_size 查询排序时所能使用的缓冲区大小,该参数对应的分配内存是每连接独占!如果有100个连接，那么实际分配的总共排序缓冲区大小为100 × 4 = 400MB。所以，对于内存在4GB左右的服务器推荐设置为4-8M。 4) read_buffer_size 读查询操作所能使用的缓冲区大小。和sort_buffer_size一样，该参数对应的分配内存也是每连接独享! 5) join_buffer_size 联合查询操作所能使用的缓冲区大小，和sort_buffer_size一样，该参数对应的分配内存也是每连接独享! 6) myisam_sort_buffer_size 这个缓冲区主要用于修复表过程中排序索引使用的内存或者是建立索引时排序索引用到的内存大小，一般4G内存给64M即可。 7) query_cache_size MySQL查询操作缓冲区的大小，通过以下做法调整：SHOW STATUS LIKE ‘Qcache%’; 如果Qcache_lowmem_prunes该参数记录有多少条查询因为内存不足而被移除出查询缓存。通过这个值，用户可以适当的调整缓存大小。如果该值非常大，则表明经常出现缓冲不够的情况，需要增加缓存大小;Qcache_free_memory:查询缓存的内存大小，通过这个参数可以很清晰的知道当前系统的查询内存是否够用，是多了，还是不够用，我们可以根据实际情况做出调整。一般情况下4G内存设置64M足够了。 8) thread_cache_size 表示可以重新利用保存在缓存中线程的数，参考如下值：1G —&gt; 8 2G —&gt; 16 3G —&gt; 32 &gt;3G —&gt; 64除此之外，还有几个比较关键的参数： 9) thread_concurrency 这个值设置为cpu核数的2倍即可 10) wait_timeout 表示空闲的连接超时时间，默认是28800s，这个参数是和interactive_timeout一起使用的，也就是说要想让wait_timeout 生效，必须同时设置interactive_timeout，建议他们两个都设置为10 11) max_connect_errors 是一个MySQL中与安全有关的计数器值，它负责阻止过多尝试失败的客户端以防止暴力破解密码的情况。与性能并无太大关系。为了避免一些错误我们一般都设置比较大，比如说10000 12) max_connections 最大的连接数，根据业务请求量适当调整，设置500足够 13) max_user_connections 是指同一个账号能够同时连接到mysql服务的最大连接数。设置为0表示不限制。通常我们设置为100足够]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop伪分布式安装]]></title>
    <url>%2F2017%2F04%2F05%2F17040502%2F</url>
    <content type="text"><![CDATA[Hadoop内容官网：http://hadoop.apache.org/#What+Is+Apache+Hadoop%3F Hadoop内容较复杂，安装根据不同的需求有三种模式独立模式（standalong/local model ）：无需任何守护进程，所有程序都单个的JVM上执行。本模式适用于开发阶段下的测试和调式MapReduce。伪分布（pesudo-distributed model）：Hadoop守护进程都运行在本地服务器上，模拟一个小规模的集群全分布(full distributed model)：Hadoop 守护进程运行在一个集群上。 先安装伪分布式进行结合测试 1. 安装前准备： JDK1.6.X SSH RSYNC 2. 下载hadoop文件之后解压到目录,直接解压后设定为Hadoop目录即可在环境变量中添加JAVA目录与Hadoop目录12345678PATH=$PATH:$HOME/bin#export PATHexport JAVA_HOME=/usr/local/java/jdk1.6.0_30export PATH=$JAVA_HOME/bin:/usr/local/mysql/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarunset USERNAMEexport HADOOP_INSTALL=/usr/local/hadoopexport PATH=$PATH:$HADOOP_INSTALL/bin 执行hadoop version 查看hadoop版本，且查看是否运行123456[root@test /] hadoop versionHadoop 1.2.1Subversion https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152Compiled by mattf on Mon Jul 22 15:23:09 PDT 2013From source with checksum 6923c86528809c4e7e6f493b6b413a9aThis command was run using /usr/local/hadoop/hadoop-core-1.2.1.jar 3. 配置SSH首先要能ssh登录到本机 1ssh localhost 如果无法登录，执行12[root@zabbix hadoop] ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_sea[root@zabbix hadoop] cat ~/.ssh/id_dsa.pub &amp;gt;&amp;gt;~/.ssh/authorized_keys 4. 格式化HDFS文件系统使用Hadoop前，必须格式化一个全新的HDFS系统 ，创建一个空的文件系统。1hadoop namenode -frmat 5. Hadoop配置文件conf目录中core-site.xml 配置Common组件hdfs-site.xml 配置HDFS属性mapred-site.xml 配置MapReduce属性默认情况下，三种模式的默认配置如图 修改配置文件123456/core-site.xmlfs.default.namehdfs://localhost///hdfs-site.xmldfs.replication1//mapred-site.xmlmapred.job.trackerlocalhost:8021 6. 启动HDFS和MapReduce守护进程1234567[root@test conf] start-dfs.shstarting namenode, logging to /usr/local/hadoop/libexec/../logs/hadoop-root-namenode-zabbix.outlocalhost: starting datanode, logging to /usr/local/hadoop/libexec/../logs/hadoop-root-datanode-zabbix.outlocalhost: starting secondarynamenode, logging to /usr/local/hadoop/libexec/../logs/hadoop-root-secondarynamenode-zabbix.out[root@test conf] start-mapred.shstarting jobtracker, logging to /usr/local/hadoop/libexec/../logs/hadoop-root-jobtracker-zabbix.outlocalhost: starting tasktracker, logging to /usr/local/hadoop/libexec/../logs/hadoop-root-tasktracker-zabbix.out 7. 查看进程是否启动123456http://namenode:50030/jobtracker.jsphttp://namenode:50070/dfshealth.jsp[root@test conf]# netstat -lnp |grep 50030tcp 0 0 :::50030 :::* LISTEN 3071/java [root@test conf]# netstat -lnp |grep 50070tcp 0 0 :::50070 :::* LISTEN 2676/java JAVA的jps查看1234567jps3220 TaskTracker2676 NameNode3071 JobTracker2803 DataNode2962 SecondaryNameNode3503 Jps Hadoop常用命令123456789101112131415161718192021222324252627282930313233//查看HDFS文件列表hadoop fs -ls /usr/local/log///创建文件目录hadoop fs -mkdir /usr/local/log/test//删除文件/hadoop fs -rm /usr/local/log/11//上传一个本机文件到HDFS中/usr/local/log/目录下adoop fs -put /usr/local/src/infobright-4.0.6-0-x86_64-ice.rpm /usr/local/log///下载hadoop fs –get /usr/local/log/infobright-4.0.6-0-x86_64-ice.rpm /usr/local/src///查看文件hadoop fs -cat /usr/local/log/20131008_10/access.log.zabbix//查看HDFS基本使用情况[root@hh ~] hadoop dfsadmin -reportConfigured Capacity: 10397683712 (9.68 GB)Present Capacity: 9388027904 (8.74 GB)DFS Remaining: 9324613632 (8.68 GB)DFS Used: 63414272 (60.48 MB) DFS Used%: 0.68%Under replicated blocks: 1Blocks with corrupt replicas: 0Missing blocks: 1-------------------------------------------------Datanodes available: 1 (1 total, 0 dead)Name: 127.0.0.1:50010Decommission Status : NormalConfigured Capacity: 10397683712 (9.68 GB)DFS Used: 63414272 (60.48 MB)Non DFS Used: 1009655808 (962.88 MB)DFS Remaining: 9324613632(8.68 GB)DFS Used%: 0.61%DFS Remaining%: 89.68%Last contact: Tue Oct 08 13:41:05 CST 2013]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rsync 自动安装脚本]]></title>
    <url>%2F2017%2F04%2F05%2F17040501%2F</url>
    <content type="text"><![CDATA[rsync 自动安装脚本 #!/bin/bash #home_page http://grapedlinux.cn rpm -q rsync &amp;&gt;/dev/null; rpm -q xinetd &amp;&gt;/dev/null || yum install rsync xinetd --nogpgcheck -y &amp;&gt;/dev/null t=$(echo $?) if [[ &quot;$t&quot; != 0 ]];then echo &quot;rsync is not install,try to install is faild,please check you yum configure or network! &quot; exit 5 fi sed -i &apos;s/yes/no/&apos; /etc/xinetd.d/rsync cat &gt; /etc/rsyncd.conf &lt;&lt;EOF uid = root gid = root user chroot = no max connections = 0 [nginxconf] path=/usr/local/nginx/conf/ ignore errors read only = yes list = no hosts allow = 10.15.6.50 auth users = syncuser secrets file = /etc/server.pass [blogdata] path=/data/blog_data_bak/ ignore errors read only = yes list = no hosts allow = 10.23.16.8 auth users = syncuser secrets file = /etc/server.pass EOF cat &gt; /etc/server.pass &lt;&lt;EOF syncuser:password-not-found EOF chmod 600 /etc/server.pass service xinetd restart &amp;&gt;/dev/null res=$(netstat -nutlp | grep 873 | grep -v grep | wc -l) if [[ $res -ne 1 ]];then echo &quot;Something wrong! please check.&quot; fi cat &lt;&lt;EOF Rynsc configure is success! config file is /etc/rsyncd.conf pass file is /etc/server.pass EOF]]></content>
      <categories>
        <category>shellscripts</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis详解]]></title>
    <url>%2F2017%2F04%2F04%2F17040403%2F</url>
    <content type="text"><![CDATA[一、Redis介绍 redis是一个key-value存储系统，官方站点http://redis.io 和memcached类似，但支持数据持久化 支持更多value类型，除了和string外，还支持hash、lists(链表）、sets(集合）和sorted sets（有序集合）集中数据类型 redis使用了两种文件格式：全量数据(RDB)和增量请求(aof)。全量数据格式是把内存中的数据写入磁盘，便于下次读取文件进行加载。增量请求文件则是把内存中的数据序列化为操作请求，用于读取文件进行replay得到数据 redis的存储分为内存存储、磁盘存储和log文件三部分 二、Redis下载安装下载解压：1234cd /usr/local/srcwget https://codeload.github.com/antirez/redis/tar.gz/2.8.21mv 2.8.21 redis-2.8.21.tar.gztar xf redis-2.8.21.tar.gz 安装：12345cd redis-2.8.21yum install -y gcc gcc-c++makecd src &amp;&amp; make PREFIX=/usr/local/redis install 三、Redis配置 配置Redis的配置文件12mkdir /usr/local/redis/etcvim /usr/local/redis/etc/redis.conf 加入如下内容：123456789101112131415daemonize yespidfile /usr/local/redis/var/redis.pidport 6379timeout 300loglevel debuglogfile /usr/local/redis/var/redis.logdatabases 16save 900 1save 300 10save 60 10000rdbcompression yesdbfilename dump.rdbdir /usr/local/redis/var/appendonly noappendfsync always 下面是redis.conf的主 要配置参数的意义：daemonize：是否以后台daemon方式运行pidfile：pid文件位置port：监听的端口号timeout：请求超时时间loglevel：log信息级别logfile：log文件位置databases：开启数据库的数量save x x ：保存快照的频率，第一个x表示多长时间，第三个x表示执行多少次写操作。在一定时间内执行一定数量的写操作时，自动保存快照。可设置多个条件。rdbcompression：是否使用压缩dbfilename：数据快照文件名（只是文件名，不包括目录）dir：数据快照的保存目录（这个是目录）appendonly：是否开启appendonlylog，开启的话每次写操作会记一条log，这会提高数据抗风险能力，但影响效率。appendfsync：appendonlylog如何同步到磁盘（三个选项，分别是每次写都强制调用fsync、每秒启用一次fsync、不调用fsync等待系统自己同步） 编写一个redis启动脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990vi /etc/init.d/redis //加入如下内容：#!/bin/sh## redis init file for starting up the redis daemon## chkconfig: - 20 80# description: Starts and stops the redis daemon.# Source function library.. /etc/rc.d/init.d/functionsname=&quot;redis-server&quot;basedir=&quot;/usr/local/redis&quot;exec=&quot;$basedir/bin/$name&quot;pidfile=&quot;$basedir/var/redis.pid&quot;REDIS_CONFIG=&quot;$basedir/etc/redis.conf&quot;[ -e /etc/sysconfig/redis ] &amp;&amp; . /etc/sysconfig/redislockfile=/var/lock/subsys/redisstart() &#123; [ -f $REDIS_CONFIG ] || exit 6 [ -x $exec ] || exit 5 echo -n $&quot;Starting $name: &quot; daemon --user $&#123;REDIS_USER-redis&#125; &quot;$exec $REDIS_CONFIG&quot; retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125;stop() &#123; echo -n $&quot;Stopping $name: &quot; killproc -p $pidfile $name retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125;restart() &#123; stop start&#125;reload() &#123; false&#125;rh_status() &#123; status -p $pidfile $name&#125;rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125;case &quot;$1&quot; in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 restart ;; *) echo $&quot;Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart&#125;&quot; exit 2esacexit $? 因为脚本启动时以redis用户启动的，所以需要增加redis用户1234567useradd -s /sbin/nologin redismkdir /usr/local/redis/varchmod 777 /usr/local/redis/varchmod 755 /etc/init.d/redischkconfig --add redischkconfig redis onservice redis start 四、Redis数据类型 string：是最简单的类型，你可以理解成Memcached一样的类型，一个key对应一个value，支持的操作与Memcached的操作类似，它的功能更丰富。设置可以存二进制的对象。12345678/usr/local/redis/bin/redis-cli 127.0.0.1:6379&gt; mset key1 szk key2 love key3 ycOK127.0.0.1:6379&gt; mget key1 key2 key31) &quot;szk&quot;2) &quot;love&quot;3) &quot;yc&quot; list:是一个链表结构，主要功能是push、pop、获取一个范围的所有值等等。操作中key理解为链接的名字。使用List结构，我们可以轻松的实现最新消息排行等功能。使用List结构，我们可以轻松地实现最新消息排行等功能。List的另一个应用就是消息队列，可以利用list的push操作，将任务存在list中，然后工作线程再用pop操作将任务取出进行执行。1234567891011127.0.0.1:6379&gt; lpush list1 123(integer) 1127.0.0.1:6379&gt; lpush list1 aaa(integer) 2127.0.0.1:6379&gt; lpush list1 &quot;123 456&quot;(integer) 3127.0.0.1:6379&gt; rpop list1&quot;123&quot;127.0.0.1:6379&gt; rpop list1&quot;aaa&quot;127.0.0.1:6379&gt; rpop list1 set:是集合，和我们数学中的集合概念类似，对集合的操作有添加删除元素，有对多个集合求交并差等操作。操作中key理解为集合的名字。比如在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。因为Redis非常人性化的为几个提供了求交集、并集、差集等操作，那么就可以非常方便的实现如共同关注、共同喜好、二度好友等功能，对上面的所有集合 操作，你还可以使用不同的命令选择将结果返回给客户端还是存集到一个新的集合中。QQ有一个社交功能叫做”好友标签”，这时就可以使用redis的集合来实现，把每一个用户的标签都存储在一个集合之中。123456127.0.0.1:6379&gt; sadd set1 zbc(integer) 1127.0.0.1:6379&gt; sadd set1 szk(integer) 1127.0.0.1:6379&gt; smembers set11) &quot;zbc&quot; sorted set:是有序集合，它比set多了一个权重参数score，使得集合中的元素能够按score进行有序排列，比如一个存储全班同学成绩的Sorted Sets，其集合value可以是同学的学号，而score就可以是其考试得分，这样在数据插入集合的时候，就已经进行了天然的排序。12345678910127.0.0.1:6379&gt; zadd mset2 2 &quot;cde 123&quot;(integer) 1127.0.0.1:6379&gt; zadd mset2 4 &quot;a123a&quot;(integer) 1127.0.0.1:6379&gt; zadd mset2 24 &quot;123-aaa&quot;(integer) 1127.0.0.1:6379&gt; zrange mset2 0 -11) &quot;cde 123&quot;2) &quot;a123a&quot;3) &quot;123-aaa&quot; hash：在memcached中，经常将一些结构化的信息打包成hashmap，在客户端序列化后存储为一个字符串的值（一般是JSON格式），比如用户的昵称、年龄、性别、积分等。 六、Redis通用配置 daemonize no #默认情况下，redis并不是以daemon形式来运行的。通过daemonize配置项可以控制redis的运行形式。 pidfile /path/to/redis.pid #当以daemon形式运行时，redis会生成一个pid文件，默认会生成在/var/run/redis.pid bind 192.168.1.200 #指定绑定的IP，可以有多个 port 6379 #指定监听端口 unixsocket /tmp/redis.sock #也可以监听socket unixsocketperm 755 #当监听socket时可以指定权限为755 timeout 0 #当一个redis-client一直没有请求发向server端，那么server端有权主动关闭这个连接，可以通过timeout来设置“空间超时时限”,0表示永不关闭 tcp-keepalive 0 #TCP连接保活策略，可以通过tcp-keepalive配置项来进行设置，单位为秒，假如设置为60秒，则server端会每60秒向连接空闲的客户端发起一次ACk请求，以检查客户端是否已经挂掉，对于无响应的客户端则会关闭其连接。如果设置为0，则不会进行保活检测 loglevel notice #日志级别，有四种debug，verbose，notice，warning logfile “” #定义日志路径 syslog-ident redis #如果希望日志打印到sysllog中，通过syslog-enabled来控制 syslog-facility local0 #指定syslog的设备，可以是USER或者local0-local7 databases 16 #设置数据库的总数量，select n 选择数据库，0 - 15 七、Redis快照配置（rdb持久化） save 900 1 #表示每15分钟且至少有1个key改变，就触发一次持久化 save 300 10 #表示每5分钟至少有10个key改变，就触发一次持久化 save 60 1000 #表示每60秒至少有10000个key改变，就触发一次持久 save “” #这样可以禁用rdb持久化 stop-write-on-bgsave-error yes #rdb持久化写入磁盘避免不了会出现失败的情况，默认一旦出现失败，redis会马上停止写操作。如果你觉得无所谓，那就可以使用选项关闭这个功能 rdbcompression yes #是否要压缩 rdbchecksum yes #是否进行数据校验 dir ./ #定义快照文件储存路径 八、Redis安全相关配置 1234vim /usr/local/redis/etc/redis.conf #设置redis-server的密码#增加下面配置requirepass szk 1/usr/local/redis/bin/redis-cli -a szk #-a指定密码登录 rename-command CONFIG szk.config #将CONFIG命令更名为szk.config，这样可以避免误操作，但 如果使用了AOF持久化，建议不要启用该功能 rename-command CONFIG “” #也可以后面定义为空，这样就禁掉了该CONFIG命令 九、Redis限制相关配置 maxclients 10000 #限制最大客户端连接数 maxmemory #设定最大内存使用数，单位是byte maxmemory-policy volatile-lru #指定内存移除规则 maxmemory-samples 3 #LRU算大和最小TTL算法都并非是精确的算法，而是估算值。所以你可以设置样本的大小。假如redis默认会检查三个key，并选择其中LRU的那个，那么你可以改变这个key样本的数量。 十、Redis AOF持久化相关配置 appendonly no #如果是yes，则开启aof持久化 appendfilename “appendonly.aof” #指定aof文件名字，保存在dir参数指定的命令 appendfsync everysec #指定fsync()调用模式，有三种no(不调用fsync)，always（每次写都会调用fsync)，exerysec(每秒钟调用一次fsync)。第一种最快，第二种数据最安全，但性能会差一些，默认为第三种方案，性能和安全兼顾。 no-appendfsync-on-rewrite no #使用no可避免当写入量非常大时的磁盘IO阻塞 auto-aof-rewrite-percentage 10 #规定什么情况下触发aof重写。该值为一个比例，10表示当aof文件增幅达到10%时则会触发重写机制 auto-aof-rewrite-min-size 64mb #重写会有一个条件，就是不能低于64MB 十一、Redis慢日志相关配置 针对慢日志，你可以设置两个参数，一个是执行时长，单位是微秒，另一个是慢日志的长度。当一个新的命令被写入日志时，最老的一条会从命令日志队列中被移除。 slowlog-log-slower-than 10000 #慢于10000ms则记录日志 slowlog-max-len 128 #日志长度 十二、Redis主从配置 分别按照之前介绍的步骤安装好redis并启动 master 配置文件不用动 slave配置文件上加一行:slaveof 192.168.1.200 6379 masterauth szk #如果主上设置了密码，要加这行 分别启动master和slave12345678910tail /usr/local/redis/var/redis.log 3966] 18 Feb 15:02:58.330 * MASTER &lt;-&gt; SLAVE sync: receiving 192 bytes from master[3966] 18 Feb 15:02:58.330 * MASTER &lt;-&gt; SLAVE sync: Flushing old data[3966] 18 Feb 15:02:58.330 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory[3966] 18 Feb 15:02:58.330 * MASTER &lt;-&gt; SLAVE sync: Finished with success[3966] 18 Feb 15:03:03.344 - DB 0: 7 keys (0 volatile) in 8 slots HT.[3966] 18 Feb 15:03:03.344 - 1 clients connected (0 slaves), 466840 bytes in use[3966] 18 Feb 15:03:08.396 - DB 0: 7 keys (0 volatile) in 8 slots HT.[3966] 18 Feb 15:03:08.397 - 1 clients connected (0 slaves), 466848 bytes in use 测试：123456/usr/local/redis/bin/redis-cli -a szk #主127.0.0.1:6379&gt; set key1 szkOK127.0.0.1:6379&gt; get key1 &quot;szk&quot; 123456/usr/local/redis/bin/redis-cli #从127.0.0.1:6379&gt; get key1&quot;szk&quot;OK 十三、Redis主从其他相关配置 slave-read-only yes #让从只读 repl-ping-slave-period 10 #设置slave向master发起ping的频率，每10s发起一次 repl-timeout 60 #设置slave ping不同master多少s后就超时 repl-disable-tcp-nodelay no #是否开启tcp_nodeay，开启后将会使用更少的带宽，但会有延迟，所以建议关闭 repl-backlog-size 1mb #同步队列的长度，backuplog是master的一个缓冲区，主从断开后，master会先把数据写到缓冲区，slave再次连接会从缓冲区中同步数据 repl-backlog-ttl 3600 #主从断开后，缓冲区的有效期，默认1小时 slave-priority 100 #多个slave是可以设置优先级的，数值越小优先级越高，应用于集群中，支持slave切换为mster，优先级最高的才会切换 min-slave-to-write 3 #和下面的一起使用，它的意思是master发现有超过3个slave的延迟高于10s，那么master就会暂时停止写操作。这两个数值任何一个为0，则关闭该功能，默认第一数值是0 min-slaves-max-log 10 十四、string常用操作12345678910111213141516171819127.0.0.1:6379&gt; set key1 szk #给key1赋值为szkOK 127.0.0.1:6379&gt; get key1 #获取这个值value&quot;szk&quot;127.0.0.1:6379&gt; set key1 yc #一个key对应一个value，多次赋值，会覆盖前面的valueOK127.0.0.1:6379&gt; get key1 &quot;yc&quot;127.0.0.1:6379&gt; setex key3 10 1 #用来给key设定过期时间,ttl key3查看时间OK127.0.0.1:6379&gt; mset key1 1 key2 2 key3 3 #同时设置多个keyOK127.0.0.1:6379&gt; mget key1 key2 key3 1) &quot;1&quot;2) &quot;2&quot;3) &quot;3&quot; 十五、Hash常用操作123456789101112131415161718192021222324252627282930313233343536373839404142127.0.0.1:6379&gt; hset hash1 name szk(integer) 1127.0.0.1:6379&gt; hset hash1 age 23(integer) 1127.0.0.1:6379&gt; hset hash1 job it(integer) 1127.0.0.1:6379&gt; hgetall hash1 1) &quot;name&quot;2) &quot;szk&quot;3) &quot;age&quot;4) &quot;23&quot;5) &quot;job&quot;6) &quot;it&quot;127.0.0.1:6379&gt; hmset hash2 name yc age 24 job teacher #批量创建OK127.0.0.1:6379&gt; hgetall hash21) &quot;name&quot;2) &quot;yc&quot;3) &quot;age&quot;4) &quot;24&quot;5) &quot;job&quot;6) &quot;teacher&quot;127.0.0.1:6379&gt; hdel hash2 job #删除某个值(integer) 1127.0.0.1:6379&gt; hgetall hash21) &quot;name&quot;2) &quot;yc&quot;3) &quot;age&quot;4) &quot;24&quot;127.0.0.1:6379&gt; hkeys hash2 #查看所有的key1) &quot;name&quot;2) &quot;age&quot;127.0.0.1:6379&gt; hvals hash2 #查看所有的values1) &quot;yc&quot;2) &quot;24&quot;127.0.0.1:6379&gt; hlen hash2 #查看hash有几个filed(integer) 2 十六、list常用操作1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162127.0.0.1:6379&gt; lpush list1 a #从左边插入(integer) 3127.0.0.1:6379&gt; lpush list1 b #从左边插入(integer) 4127.0.0.1:6379&gt; lpush list1 c #从左边插入(integer) 5127.0.0.1:6379&gt; lrange list1 0 -1 #从左边往右罗列，最先插入在最后边1) &quot;c&quot;2) &quot;b&quot;3) &quot;a&quot;127.0.0.1:6379&gt; lpop list1 #从最左边取出&quot;c&quot;127.0.0.1:6379&gt; lrange list1 0 -1 #从左边往右罗列1) &quot;b&quot;2) &quot;a&quot;127.0.0.1:6379&gt; rpush list1 1 #从右边插入(integer) 5127.0.0.1:6379&gt; rpush list1 2 #从右边插入(integer) 6127.0.0.1:6379&gt; rpush list1 3 #从右边插入(integer) 7127.0.0.1:6379&gt; lrange list1 0 -1 #从右往左罗列，最后插入在最后边1) &quot;b&quot;2) &quot;a&quot;3) &quot;1&quot;4) &quot;2&quot;5) &quot;3&quot;127.0.0.1:6379&gt; linsert list1 before 3 5 #在3前面插入一个5(integer) 8127.0.0.1:6379&gt; lrange list1 0 -11) &quot;b&quot;2) &quot;a&quot;3) &quot;1&quot;4) &quot;2&quot;5) &quot;5&quot;6) &quot;3&quot;127.0.0.1:6379&gt; lset list1 7 6 #将0开始的第7个元素换成6OK127.0.0.1:6379&gt; lrange list1 0 -11) &quot;b&quot;2) &quot;a&quot;3) &quot;456&quot;4) &quot;123&quot;5) &quot;1&quot;6) &quot;2&quot;7) &quot;5&quot;8) &quot;6&quot;127.0.0.1:6379&gt; lindex list1 7 #查看从0开始的第7个元素&quot;6&quot;127.0.0.1:6379&gt; llen list1 #查看列表中有几个元素(integer) 8 十七、set数据常用操作 123456789101112131415161718192021222324252627127.0.0.1:6379&gt; sadd set1 1 #向集合set1中放入元素(integer) 1127.0.0.1:6379&gt; sadd set1 2(integer) 1127.0.0.1:6379&gt; sadd set1 3(integer) 1127.0.0.1:6379&gt; sadd set1 4(integer) 1127.0.0.1:6379&gt; smembers set1 #查看集合中所有元素1) &quot;zbc&quot;2) &quot;1&quot;3) &quot;szk&quot;4) &quot;2&quot;5) &quot;3&quot;6) &quot;4&quot;127.0.0.1:6379&gt; spop set1 #随机取出一个元素，删除&quot;szk&quot;127.0.0.1:6379&gt; sdiff set1 seta #比较差集，以set1为主来比较1) &quot;zbc&quot;2) &quot;4&quot;127.0.0.1:6379&gt; sdiffstore set3 seta set1 #比较差集，将结果存入set3中(integer) 2127.0.0.1:6379&gt; SMEMBERS set3 #tab自动补全，但显示为大写1) &quot;2&quot;2) &quot;szk&quot; 十八、zset常用操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960127.0.0.1:6379&gt; zadd zset1 1 abc #创建有序集合(integer) 1127.0.0.1:6379&gt; zadd zset1 10 aabc #创建有序集合(integer) 1127.0.0.1:6379&gt; zadd zset1 5 aaa #创建有序集合(integer) 1127.0.0.1:6379&gt; zadd zset1 88 bbb #创建有序集合(integer) 1127.0.0.1:6379&gt; zadd zset1 888 szk #创建有序集合(integer) 1127.0.0.1:6379&gt; ZRANGE zset1 0 -1 #显示所有元素，按顺序显示1) &quot;abc&quot;2) &quot;aaa&quot;3) &quot;aabc&quot;4) &quot;bbb&quot;5) &quot;szk&quot;127.0.0.1:6379&gt; ZRANGE zset1 0 -1 withscores #可以带上分值1) &quot;abc&quot;2) &quot;1&quot;3) &quot;aaa&quot;4) &quot;5&quot;5) &quot;aabc&quot;6) &quot;10&quot;7) &quot;bbb&quot;8) &quot;88&quot;9) &quot;szk&quot;10) &quot;888&quot;127.0.0.1:6379&gt; ZREM zset1 abc #删除指定元素(integer) 1127.0.0.1:6379&gt; ZRANGE zset1 0 -1 withscores1) &quot;aaa&quot;2) &quot;5&quot;3) &quot;aabc&quot;4) &quot;10&quot;5) &quot;bbb&quot;6) &quot;88&quot;7) &quot;szk&quot;8) &quot;888&quot;127.0.0.1:6379&gt; zrevrank zset1 szk #返回元素的索引值，索引值从0开始，按score正向排序(integer) 0127.0.0.1:6379&gt; zrank zset1 szk #同上，不同的是，按score反序排序(integer) 3127.0.0.1:6379&gt; ZCARD zset1 #查看集合元素的个数(integer) 4 127.0.0.1:6379&gt; zcount zset1 1 20 #查看分值区间内的元素个数(integer) 2127.0.0.1:6379&gt; zrangebyscore zset1 1 100 withscores #返回分支范围在1-100的元素1) &quot;aaa&quot;2) &quot;5&quot;3) &quot;aabc&quot;4) &quot;10&quot;5) &quot;bbb&quot;6) &quot;88&quot;127.0.0.1:6379&gt; zrangebyscore zset1 0 10 #删除分支范围在0-10的元素，按score排序1) &quot;aaa&quot;2) &quot;aabc&quot; 十九、键值和服务器命令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768127.0.0.1:6379&gt; keys * #列出所有键值1) &quot;key3&quot;2) &quot;seta&quot;3) &quot;hash1&quot;4) &quot;list1&quot;5) &quot;key2&quot;6) &quot;zset1&quot;7) &quot;mset2&quot;8) &quot;set2&quot;9) &quot;set1&quot;10) &quot;key1&quot;11) &quot;hash2&quot;12) &quot;set3&quot;127.0.0.1:6379&gt; keys key*1) &quot;key3&quot;2) &quot;key2&quot;3) &quot;key1&quot;127.0.0.1:6379&gt; EXISTS list1 #查看是否有list1(integer) 1127.0.0.1:6379&gt; del key1 #删除key1(integer) 1127.0.0.1:6379&gt; EXISTS key1(integer) 0127.0.0.1:6379&gt; EXPIRE key3 10 #设置过期时间(integer) 1127.0.0.1:6379&gt; get key3&quot;3&quot;127.0.0.1:6379&gt; ttl key3 #查看key的过期时间，-1不存在过期 -2不存储键值(integer) -2127.0.0.1:6379&gt; EXists key3 (integer) 0127.0.0.1:6379&gt; select 0 #切换库，默认16个库OK127.0.0.1:6379&gt; select 1OK127.0.0.1:6379[1]&gt; set key1 111 #新建一个键值OK127.0.0.1:6379[1]&gt; keys *1) &quot;key1&quot;127.0.0.1:6379[1]&gt; move set1 2 #移动到库2(integer) 0127.0.0.1:6379[1]&gt; select 2 #切换库2OK127.0.0.1:6379[2]&gt; keys * 1) &quot;key1&quot;127.0.0.1:6379[2]&gt; EXPIRE key1 200 #设置过期时间(integer) 1127.0.0.1:6379[2]&gt; ttl key1(integer) 193127.0.0.1:6379[2]&gt; PERSIST key1 #取消过期时间(integer) 1127.0.0.1:6379[2]&gt; ttl key1(integer) -1127.0.0.1:6379[2]&gt; RANDOMKEY #随机返回一个key&quot;key1&quot;127.0.0.1:6379[2]&gt; RENAME key1 szk #更改一个key的名字OK127.0.0.1:6379[2]&gt; keys *1) &quot;szk&quot;127.0.0.1:6379[2]&gt; type szk #查看一个键值的类型string 二十、服务相关的操作123456789101112131415161718192021222324127.0.0.1:6379[2]&gt; DBSIZE #查看一个库的键值数(integer) 1127.0.0.1:6379[2]&gt; select 0OK127.0.0.1:6379&gt; DBSIZE (integer) 10127.0.0.1:6379&gt; info #查看redis服务信息# Serverredis_version:2.8.21redis_git_sha1:00000000略127.0.0.1:6379&gt; flushdb #清空当前数据库中所有的键OK127.0.0.1:6379&gt; keys *(empty list or set)127.0.0.1:6379&gt; flushall #清空所有数据库中的所有的keyOK127.0.0.1:6379&gt; SELECT 1OK127.0.0.1:6379[1]&gt; keys *(empty list or set) 二十一、PHP中应用Redis12345678910111213141516cd /usr/local/srcwget http://pecl.php.net/get/redis-2.2.5.tgztar xf redis-2.2.5.tgzcd redis-2.2.5/usr/local/php/bin/phpize./configure --with-php-config=/usr/local/php/bin/php-confimake ; make installmv /usr/local/php/lib/php/extensions/no-debug-zts-20100525/redis.so /usr/lib64/vim /usr/local/php/php.iniextension_dir = /usr/lib64/extension = redis.sousr/local/php/bin/php -m | grep redisredis 加载成功，可以重启 nginx 看看 phpinfo 页 二十二、Redis实现session共享php.ini中加入session.save_handler = “redis”session.save_path = “tcp://127.0.0.1:6379”或者apache虚拟主机加入php_value session.save_handler “redis”php_value session.save_path “tcp://127.0.0.1:6379”或者php-fpm.conf对应的pool中加入php_value[session.save_handler] = redisphp_value[session.save_path] = “ tcp://127.0.0.1:6379 “]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx+tomcat 配置负载均衡集群]]></title>
    <url>%2F2017%2F04%2F04%2F17040401%2F</url>
    <content type="text"><![CDATA[一、Hello world1、前期环境准备 准备两个解压版tomcat，如何同时启动两个tomcat，方法如下：首先去apache tomcat官网下载一个tomcat解压版。解压该压缩包，生成n份tomcat 分别命名为 tomcat1，tomcat2，然后修改server.xml配置文件，分别进入tomcat/conf/目录，修改server.xml，一共三处。第一处：第二处、tomcat访问端口号：第三处：之后修改bin下的启动文件分别进入tomcat/bin目录，修改 startup.bat在文件第一行添加如下配置（添加时删除#注释，在startup.bat文件中rem代表注释）：在文件第一行添加如下配置（添加时删除#注释，在startup.bat文件中rem代表注释）：1234567# tomcat名称set TITLE=&quot;tomcat1&quot;# tomcat启动路径set CATALINA_BASE=&quot;D:\tools\tomcat1&quot;set CATALINA_HOME=&quot;D:\tools\tomcat1&quot;# JDK所在路径，如果环境变量已经配置，则可忽略，前提是你所有tomcat要共用一个jdk。另外如果设置，此处路径不能有空格SET JAVA_HOME=&quot;D:\Java\jdk1.7.0_45&quot; 如图：启动tomcat平常直接双击startup.bat即可，但是为了查看配置信息，可以在cmd中启动，如下图：访问tomcat在浏览器地址栏输入：http://localhost:8081 和 http://localhost:8082 nginx官网下载解压版nginx。 创建一个简单的web项目。为了直观的区分访问的哪个tomcat，在页面写上标记8081、8082。 分别部署到对应的tomcat下。如图：2、配置nginx进入nginx-1.10.1\conf路径，修改配置文件nginx.conf。 配置服务器组，在http{}节点之间添加upstream配置。（注意不要写localhost，不然访问速度会很慢） 1234upstream nginxDemo &#123; server 127.0.0.1:8081; #服务器地址1 server 127.0.0.1:8082; #服务器地址2&#125; 修改nginx监听的端口号80，改为8080。 1234server &#123; listen 8080; ......&#125; 在location{}中，利用proxy_pass配置反向代理地址；此处“http://”不能少，后面的地址要和第一步upstream定义的名称保持一致。 12345location / &#123; root html; index index.html index.htm; proxy_pass http://nginxDemo; #配置方向代理地址 &#125; 如下图： 3、启动nginx和tomcat，访问我是Windows系统，所以直接在nginx-1.10.1目录下双击nginx.exe即可。可在任务管理器中查看：最后在浏览器输入地址：http://localhost:8080/nginxDemo/index.jsp，每次访问就会轮流访问tomcat了（如果F5刷新不管用，建议试试鼠标指针放到地址栏，点击Enter键）。到这里，一个非常简单的负载均衡就配置完成了。]]></content>
      <categories>
        <category>负载均衡</category>
      </categories>
      <tags>
        <tag>nginx,java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx主要应用场景]]></title>
    <url>%2F2017%2F04%2F03%2F17040301%2F</url>
    <content type="text"><![CDATA[前言本文只针对Nginx在不加载第三方模块的情况能处理哪些事情，由于第三方模块太多所以也介绍不完，当然本文本身也可能介绍的不完整，毕竟只是我个人使用过和了解到过得。所以还请见谅，同时欢迎留言交流。 Nginx能做什么1. 反向代理2. 负载均衡3. HTTP服务器（包含动静分离）4. 正向代理以上就是我了解到的Nginx在不依赖第三方模块能处理的事情，下面详细说明每种功能怎么做。 反向代理反向代理应该是Nginx做的最多的一件事了，什么是反向代理呢，以下是百度百科的说法：反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。简单来说就是真实的服务器不能直接被外部网络访问，所以需要一台代理服务器，而代理服务器能被外部网络访问的同时又跟真实服务器在同一个网络环境，当然也可能是同一台服务器，端口不同而已。 下面贴上一段简单的实现反向代理的代码。12345678910server &#123; listen 80; server_name localhost; client_max_body_size 1024M; location / &#123; proxy_pass http://localhost:8080; proxy_set_header Host $host:$server_port; &#125; &#125; 保存配置文件后启动Nginx，这样当我们访问localhost的时候，就相当于访问localhost:8080了。 负载均衡负载均衡也是Nginx常用的一个功能，负载均衡其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。简单而言就是当有2台或以上服务器时，根据规则随机的将请求分发到指定的服务器上处理，负载均衡配置一般都需要同时配置反向代理，通过反向代理跳转到负载均衡。而Nginx目前支持自带3种负载均衡策略，还有2种常用的第三方策略。 1、RR（默认）每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。简单配置1234567891011121314upstream test &#123; server localhost:8080; server localhost:8081; &#125; server &#123; listen 81; server_name localhost; client_max_body_size 1024M; location / &#123; proxy_pass http://test; proxy_set_header Host $host:$server_port; &#125; &#125; 负载均衡的核心代码为1234upstream test &#123; server localhost:8080; server localhost:8081;&#125; 这里我配置了2台服务器，当然实际上是一台，只是端口不一样而已，而8081的服务器是不存啊在的,也就是说访问不到，但是我们访问http://localhost 的时候,也不会有问题，会默认跳转到http://localhost:8080 具体是因为Nginx会自动判断服务器的状态，如果服务器处于不能访问（服务器挂了），就不会跳转到这台服务器，所以也避免了一台服务器挂了影响使用的情况，由于Nginx默认是RR策略，所以我们不需要其他更多的设置。 2、权重指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 例如1234upstream test &#123; server localhost:8080 weight=9; server localhost:8081 weight=1;&#125; 那么10次一般只会有1次会访问到8081，而有9次会访问到8080 3、ip_hash上面的2种方式都有一个问题，那就是下一个请求来的时候请求可能分发到另外一个服务器，当我们的程序不是无状态的时候（采用了session保存数据），这时候就有一个很大的很问题了，比如把登录信息保存到了session中，那么跳转到另外一台服务器的时候就需要重新登录了，所以很多时候我们需要一个客户只访问一个服务器，那么就需要用iphash了，iphash的每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。12345upstream test &#123; ip_hash; server localhost:8080; server localhost:8081;&#125; 4、fair（第三方）按后端服务器的响应时间来分配请求，响应时间短的优先分配。12345upstream backend &#123; fair; server localhost:8080; server localhost:8081;&#125; 5、url_hash（第三方）按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法123456upstream backend &#123; hash $request_uri; hash_method crc32; server localhost:8080; server localhost:8081;&#125; 以上5种负载均衡各自适用不同情况下使用，所以可以根据实际情况选择使用哪种策略模式,不过fair和url_hash需要安装第三方模块才能使用，由于本文主要介绍Nginx能做的事情，所以Nginx安装第三方模块不会再本文介绍 HTTP服务器Nginx本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用Nginx来做服务器，同时现在也很流行动静分离，就可以通过Nginx来实现，首先看看Nginx做静态资源服务器1234567891011server &#123; listen 80; server_name localhost; client_max_body_size 1024M; location / &#123; root e:\wwwroot; index index.html; &#125; &#125; 这样如果访问http://localhost 就会默认访问到E盘wwwroot目录下面的index.html，如果一个网站只是静态页面的话，那么就可以通过这种方式来实现部署。 动静分离动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路1234567891011121314151617181920212223242526272829upstream test&#123; server localhost:8080; server localhost:8081; &#125; server &#123; listen 80; server_name localhost; location / &#123; root e:\wwwroot; index index.html; &#125; # 所有静态请求都由nginx处理，存放目录为html location ~ \.(gif|jpg|jpeg|png|bmp|swf|css|js)$ &#123; root e:\wwwroot; &#125; # 所有动态请求都转发给tomcat处理 location ~ \.(jsp|do)$ &#123; proxy_pass http://test; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root e:\wwwroot; &#125; &#125; 这样我们就可以吧HTML以及图片和css以及js放到wwwroot目录下，而tomcat只负责处理jsp和请求，例如当我们后缀为gif的时候，Nginx默认会从wwwroot获取到当前请求的动态图文件返回，当然这里的静态文件跟Nginx是同一台服务器，我们也可以在另外一台服务器，然后通过反向代理和负载均衡配置过去就好了，只要搞清楚了最基本的流程，很多配置就很简单了，另外localtion后面其实是一个正则表达式，所以非常灵活 正向代理正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。当你需要把你的服务器作为代理服务器的时候，可以用Nginx来实现正向代理，但是目前Nginx有一个问题，那么就是不支持HTTPS，虽然我百度到过配置HTTPS的正向代理，但是到最后发现还是代理不了，当然可能是我配置的不对，所以也希望有知道正确方法的同志们留言说明一下。1234567891011121314resolver 114.114.114.114 8.8.8.8;server &#123; resolver_timeout 5s; listen 81; access_log e:\wwwroot\proxy.access.log; error_log e:\wwwroot\proxy.error.log; location / &#123; proxy_pass http://$host$request_uri; &#125;&#125; resolver是配置正向代理的DNS服务器，listen 是正向代理的端口，配置好了就可以在ie上面或者其他代理插件上面使用服务器ip+端口号进行代理了。 补充Nginx是支持热启动的，也就是说当我们修改配置文件后，不用关闭Nginx，就可以实现让配置生效，当然我并不知道多少人知道这个，反正我一开始并不知道，导致经常杀死了Nginx线程再来启动。。。Nginx从新读取配置的命令是 1nginx -s reload windows下面就是 1nginx.exe -s reload]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix安装配置]]></title>
    <url>%2F2017%2F04%2F02%2F17040202%2F</url>
    <content type="text"><![CDATA[zabbix安装配置安装zabbix1yum install -y epel-release 安装rpm包的lamp环境1yum install -y httpd mysql mysql-libs php php-mysql mysql-server php-bcmath php-gd php-mbstring 安装zabbix服务端1yum install zabbix20 zabbix20-agent zabbix20-server zabbix20-server-mysql zabbix20-web zabbix20-web-mysql net-snmp-devel 启动服务1/etc/init.d/zabbix-server start; /etc/init.d/zabbix-agent start; /etc/init.d/httpd start; 修改一下mysql配置文件1234567vim /etc/my.cnf //修改或增加如下内容[mysql]default-character-set = utf8[mysqld]character_set_server = utf8 启动mysql服务1/etc/init.d/mysqld start 建库，导入数据1234mysql -uroot -p -e &quot;create database zabbix&quot;mysql -uroot -p --default-character-set=utf8 zabbix &lt; /usr/share/zabbix-mysql/schema.sqlmysql -uroot -p --default-character-set=utf8 zabbix &lt; /usr/share/zabbix-mysql/images.sqlmysql -uroot -p --default-character-set=utf8 zabbix &lt; /usr/share/zabbix-mysql/data.sql 网页安装zabbix浏览器访问 http://ip/zabbix, 默认会有“It is not safe to rely on the system‘s timezone settings ”这样的警告信息，需要vim /etc/php.ini 设置 date.timezone=“Asia/Shanghai”点next解决相关的报错信息，点retry (vim /etc/php.ini)输入mysql相关信息, 首先要测试一下，如果不通过，则需要调试，测试通过后，点nextName 写127.0.0.1，（可以自定义）点next，再点next，最后点finish默认管理员账号密码为 admin:zabbix这时会遇到“zabbix server is not running”这样的错误，需要编辑一下 /etc/zabbix/zabbix_server.conf ，配置DBUser, DBPassword接入要监控的主机在客户端上123456yum install zabbix20-agentvim /etc/zabbix_agentd.conf //更改Server=服务端ip; ServerActive=0.0.0.0:10050Hostname=xxx 启动客户端1etc/init.d/zabbix-agent start 服务端上命令行测试：1zabbix_get -s 客户端ip -p10050 -k &quot;system.hostname&quot; 在web界面下，点”configuration” –&gt; “host” –&gt; 右上角点”Create Host” 其中host name, visible name自定义，可以选择groups，这里默认即可，ip address 写入客户端ip配置监控项目模板：点“templates”, 点add, 在弹出的小窗口中选择Template OS Linux, 然后点select, 最后点save自定义templatesZabbix自带了很多模板，模板中有很多监控项目，比如CPU、网卡、内存、进程等等。使用系统自带模板有点太多了，所以我们可以自定义模板。点configuration 选择 templates，点右上角的create templateTemplate name和Visible name 自定义，Groups 选择templates, 点save然后我们去挑选一些项目拷贝到该模板下：比如我们找到Template OS Linux 点一下items,选择我们想要的项目，然后在下面选择copy selected to … 然后点goGroup 选择templates, 找到刚才我们自定义的templates,点copy点configuration 选择 templates可以看到新建的templates中已经有刚刚我们copy的items了我们可以使用和上面相同的方法自定义拷贝Triggers（触发器 ）,它用来设置告警的阀值，当然我们也可以自定义编辑它。例如：监控客户端网卡流量配置发邮件12345678yum install -y sendmail mkdir -p /home/zabbix/binvim /home/zabbix/bin/baojing.sh //加入内容：#! /bin/bashecho &quot;$3&quot; |/bin/mail -s &quot;$2&quot; $1//保存退出后给予执行权限chmod +x /home/zabbix/bin/baojing.sh 在zabbix_server.conf配置文件中，有参数AlertScriptsPath和ExternalScriptsAlertScriptsPath=/home/zabbix/bin/ —用户自定义的media types脚本ExternalScripts=/home/zabbix/bin/ —用户自定义的检查的脚本（item）这样才能找到你的脚本，因为你在frontend中只是输入脚本的名称，没有路径。创建mediea types: “Administration” –&gt;”Media types”，点击右上角“Create Media Type”其中Description填”baojing” 或其它自定义名称，Type选择”Script”，Script填”baojing.sh”然后点”Save”.创建user: “Adimistration” –&gt; “Users”在右上角，选择”Users”，点击”Create User”, alias: test1,自定义name和lastname password:123456;group 选择guest，回到上面点一下media,type 选择baojing，send to 写要发送邮件的邮箱，点add, 最后点save创建action: “configuration” –&gt; actions,右上角“Create Actions”, Name自定义，我这里写”baojing”,其他默认，然后点右侧的“Operations”下的“New”按钮，“Operation Type”选择“Send message”，“Send Message to”选择一个或多个要发送消息的用户组，Send to Users选择我们之前新增的test1, “Send only to”选择baojing , 点一下add最后点save。 扩展：zabbix历史记录乱码问题zabbix图形中乱码问题Zabbix自定义监控脚本配置Zabbix汇总]]></content>
      <categories>
        <category>monitor</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nagios 安装和配置]]></title>
    <url>%2F2017%2F04%2F02%2F17040201%2F</url>
    <content type="text"><![CDATA[Nagios 安装和配置Nagios官网:http://www.nagios.org实验环境：一台服务端（IP：192.168.0.200）；一台客户端（IP：192.168.0.201）。 1. Nagios安装 - 服务端（192.168.0.200）Centos6默认的yum源里没有nagios相关的rpm包，但是我们可以安装一个epel的扩展源：1yum install -y epel-release 然后安装nagios相关的包1yum install -y httpd nagios nagios-plugins nagios-plugins-all nrpe nagios-plugins-nrpe 设置登录nagios后台的用户和密码：1htpasswd -c /etc/nagios/passwd nagiosadmin 检测配置文件1nagios -v /etc/nagios/nagios.cfg 启动服务：1service httpd start; service nagios start 浏览器访问： http:/192.168.0.200ip/nagios/ 2. Nagios安装 - 客户端（192.168.0.201）在客户端机器上:123456yum install -y epel-releaseyum install -y nagios-plugins nagios-plugins-all nrpe nagios-plugins-nrpe vim /etc/nagios/nrpe.cfg找到“allowed_hosts=127.0.0.1” 改为 “allowed_hosts=127.0.0.1,192.168.0.200”找到” dont_blame_nrpe=0” 改为 “dont_blame_nrpe=1” 启动客户端1/etc/init.d/nrpe start 3. 监控中心（192.168.0.200）添加被监控主机（192.168.0.201）123456789101112131415161718192021222324252627282930313233343536cd /etc/nagios/conf.d/vim 192.168.0.201.cfg //加入：define host&#123; use linux-server host_name 192.168.0.201201 alias 0.201 address 192.168.0.201 &#125;define service&#123; use generic-service host_name 192.168.0.201 service_description check_ping check_command check_ping!100.0,20%!200.0,50% max_check_attempts 5 normal_check_interval 1&#125;define service&#123; use generic-service host_name 192.168.0.201 service_description check_ssh check_command check_ssh max_check_attempts 5 ；当nagios检测到问题时，一共尝试检测5次都有问题才会告警，如果该数值为1，那么检测到问题立即告警 normal_check_interval 1 ；重新检测的时间间隔，单位是分钟，默认是3分钟 notification_interval 60 ；在服务出现异常后，故障一直没有解决，nagios再次对使用者发出通知的时间。单位是分钟。如果你认为，所有的事件只需要一次通知就够了，可以把这里的选项设为0。 &#125;define service&#123; use generic-service host_name 192.168.0.201 service_description check_http check_command check_http max_check_attempts 5 normal_check_interval 1&#125; 以上服务不依赖于客户端nrpe服务，我们可以想象，我们在自己电脑上可以使用ping或者telnet探测远程任何一台机器是否存活、是否开启某个端口或服务。 而当我们想要检测客户端上的某个具体服务的情况时，就需要借助于nrpe了，比如想知道客户端机器的负责或磁盘使用情况。 4. 继续添加服务服务端123456vim /etc/nagios/objects/commands.cfg//增加： define command&#123; command_name check_nrpe command_line $USER1$/check_nrpe -H $HOSTADDRESS$ -c $ARG1$ &#125; 继续编辑123456789101112131415161718192021222324252627282930vim /etc/nagios/conf.d/192.168.0.12.cfg//增加如下内容：define service&#123; use generic-service host_name 192.168.0.12 service_description check_load check_command check_nrpe!check_load max_check_attempts 5 normal_check_interval 1&#125;define service&#123; use generic-service host_name 192.168.0.12 service_description check_disk_hda1 check_command check_nrpe!check_hda1 max_check_attempts 5 normal_check_interval 1&#125;define service&#123; use generic-service host_name 192.168.0.12 service_description check_disk_hda2 check_command check_nrpe!check_hda2 max_check_attempts 5 normal_check_interval 1&#125; 说明：check_nrpe!check_load：这里的check_nrpe就是在commands.cfg刚刚定义的，check_load是远程主机上的一个检测脚本在远程主机上vim /etc/nagios/nrpe.cfg 搜索check_load，这行就是在服务端上要执行的脚本了，我们可以手动执行这个脚本把check_hda1更改一下：/dev/hda1 改为 /dev/sda1再加一行command[check_hda2]=/usr/lib/nagios/plugins/check_disk -w 20% -c 10% -p /dev/sda2客户端上重启一下nrpe服务:1service nrpe restart 服务端也重启一下nagios服务:1service nagios restart 5. 配置告警123456789101112131415161718192021222324vim /etc/nagios/objects/contacts.cfg //增加：define contact&#123; contact_name 123 use generic-contact alias aming email lishiming2009@139.com &#125;define contact&#123; contact_name 456 use generic-contact alias aaa email aminglinux@139.com &#125;define contactgroup&#123; contactgroup_name common alias common members 123,456 &#125; 然后在要需要告警的服务里面加上contactgroup 123456789101112define service&#123; use generic-service host_name 192.168.0.12 service_description check_load check_command check_nrpe!check_load max_check_attempts 5 normal_check_interval 1 contact_groups common notifications_enabled 1 ；是否开启提醒功能。1为开启，0为禁用。一般，这个选项会在主配置文件（nagios.cfg）中定义，效果相同。 notification_period 24x7 ；发送提醒的时间段。非常重要的主机（服务）我定义为7×24，一般的主机（服务）就定义为上班时间。如果不在定义的时间段内，无论什么问题发生，都不会发送提醒。 notification_options:w,u,c,r ；这个是service的状态。w为waning， u为unknown, c为critical, r为recover(恢复了），类似的还有一个 host对应的状态：d,u,r d = 状态为DOWN, u = 状态为UNREACHABLE , r = 状态恢复为OK，需要加入到host的定义配置里。&#125; 扩展：调用短信接口整合微信 6. 配置图形显示 pnp4nagios安装1yum install pnp4nagios rrdtool 配置主配置文件123456vim /etc/nagios/nagios.cfg //修改如下配置process_performance_data=1 host_perfdata_command=process-host-perfdataservice_perfdata_command=process-service-perfdataenable_environment_macros=1 修改commands.cfg1234567891011vim /etc/nagios/objects/commands.cfg //注释掉原有对process-host-perfdata和process-service-perfdata，重新定义define command &#123; command_name process-service-perfdata command_line /usr/bin/perl /usr/libexec/pnp4nagios/process_perfdata.pl &#125; define command &#123; command_name process-host-perfdata command_line /usr/bin/perl /usr/libexec/pnp4nagios/process_perfdata.pl -d HOSTPERFDATA &#125; 修改配置文件templates.cfg 123456789101112vim /etc/nagios/objects/templates.cfg define host &#123; name hosts-pnp register 0 action_url /pnp4nagios/index.php/graph?host=$HOSTNAME$&amp;srv=_HOST_ process_perf_data 1&#125;define service &#123; name srv-pnp register 0 action_url /pnp4nagios/index.php/graph?host=$HOSTNAME$&amp;srv=$SERVICEDESC$ process_perf_data 1&#125; 修改host和service配置 1234567891011121314151617181920212223242526vim /etc/nagios/conf.d/192.168.0.12.cfg 把 “define host&#123; use linux-server” 改为：define host&#123; use linux-server,hosts-pnp修改对应的service，比如把define service&#123; use generic-service host_name 192.168.0.12 service_description check_disk_hda1 check_command check_nrpe!check_hda1 max_check_attempts 5 normal_check_interval 1&#125;改为：define service&#123; use generic-service,srv-pnp host_name 192.168.0.12 service_description check_disk_hda1 check_command check_nrpe!check_hda1 max_check_attempts 5 normal_check_interval 1&#125; 重启和启动各个服务：123service nagios restartservice httpd restartservice npcd start 两种访问方法： ip/nagios/ip/pnp4nagios/]]></content>
      <categories>
        <category>monitor</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS上搭建Git服务器]]></title>
    <url>%2F2017%2F04%2F01%2F17040102%2F</url>
    <content type="text"><![CDATA[Git是一个分布式版本控制软件，原来是linux内核开发者Linus Torvalds为了更好地管理linux内核开发而创立的。发展至今，Git已经成为了一个相当好用的版本管理工具。相比于SVN，如果想要保存一些微小的修改也必须得提交服务器保存才可以，这样使服务器的版本号过多，而Git解决了这个问题，一些小的修改只在本地提交即可，只需最后修改完成后再提交服务器。正是由于这样的便捷性，现在越来越多的社区项目都开始使用Git来取代SVN之类较为传统的版本管理工具进行开发。使用CentOS搭建Git服务器是一件比较轻松的事儿，本次折腾主要涉及git, gitosis, gitweb的安装配置。其中，gitosis和gitweb是两种比较常用的方式，gitosis是以SSH方式访问和管理git， gitweb是通过http的方式访问和管理。利用这些工具即可满足Git服务器的基本功能。此外比较好的一点是，Git的管理工具几乎不会给服务器带来较大的性能压力。下面正式开始我们的Git安装配置记录。 一、安装Git1yum install git 然后进行配置：12useradd --home /home/git gitpasswd git 创建完用户后就可以切换到git用户下进行后面的设置，如用户名和邮箱：123su gitgit config --global user.name &quot;somebody&quot;git config --global user.email &quot;somebody@example.com&quot; 设置默认将会保存在~/.gitconfig文件中。此时，Git的功能就已经可以使用了。为了方便后面的操作，可以先来创建一个空版本库。1mkdir ~/repo 然后建立项目目录1mkdir ~/repo/huhamhire-hosts 切换到项目目录，并进行初始化12cd ~/repo/huhamhire-hostsgit init -bare 至此，一个初始的空项目版本库就配置完成了，后面安装了gitosis之后便可向库中推送我们的代码库内容。 二、安装gitosis在安装之前，可以看一下gitosis的实现原理：浅谈Gitosis实现原理先切换回root权限。1su root 并先安装python-setuptool1yum install python-setuptools 然后开始安装gitosis，值得注意的是gitosis的安装程序本身就是由git管理的，需要使用git来获取。这里在/tmp目录下进行相关的安装操作：12cd /tmpgit clone https://github.com/res0nat0r/gitosis.git 接下来进入下载的gitosis版本库进行安装:12cd gitosispython setup.py install 安装完成后，便进入对gitosis的设置阶段。由于gitosis需要通过SSH进行管理，所以需要创建SSH密钥对，并将公钥放在服务器端，私钥放在客户端。一般的流程是客户端创建完密钥后，将公钥传到服务器上生效。不过，偷懒的话直接在服务器上操作问题也不大。 切换到git用户并建立文件夹.ssh：12su gitmkdir /home/git/.ssh 一定记得，在客户机上生成公钥，上传到服务器，或者在服务器上生成，下载到客户机。进入~/.ssh目录并使用ssh-keygen生成公钥：cd /home/git/.ssh1ssh-keygen -t rsa 注意不能忘记私钥的密码。默认会生成~/.ssh/id_rsa.pub公钥文件。有了密钥以后便可初始化gitosis，使gitosis获得对Git的管理权限：1gitosis-init &lt; /home/git/.ssh/id_rsa.pub 初始化之后，会在/home/git/repositories创建gitosis-admin.git项目，可以通过维护这个项目来对gitosis进行配置。除此以外，还需要对gitosis-admin.git/hooks/post-update目录赋上特殊权限：1chmod u+x /home/git/repositories/gitosis-admin.git/hooks/post-update 至此，服务器端的gitosys配置就完成了。 三、设置并使用gitosys在服务器端完成了gitosys的配置之后，便可在客户端进行接下来的设置，以便使用Git服务器。较为正规的做法是在客户端通过gitosis-admin版本库做管理设置，之后提交到服务器使项目权限生效，当然也可以使用操作系统的ssh登录方式进行验证，不过这里仅介绍前面一种方法。在进行以下操作时，需要确认一下，你的公钥是不是已经放在客户机~/.ssh/目录下。如果你也在用github的话，那么你需要设置一下多公钥共存的东西。.ssh/config，在这个文件中写入：12345678910111213Host github.com HostName github.com User git IdentityFile C:/Users/abc/.ssh/id_rsaHost git.oschina.net HostName git.oschina.net User git IdentityFile C:/Users/abc/.ssh/id_rsa_aHost abc.ueder.info HostName abc.ueder.info User git Port 1000 IdentityFile C:/Users/abc/.ssh/id_rsa_new 如我就使用了好几个git服务，每个都有自己的公钥，需要配置文件来区分开来，并且我自己的服务器ssh端口已经不是默认端口，需要在配置文件中声明，否则在每次clone的时候要声明端口。在客户机上下载gitosis-admin版本库，这里以linux客户机为例：1git clone git@VPS的IP/Domain:/home/git/repositories/gitosis-admin.git 获取完成后对gitosis-admin/gitosis.conf文件进行设置，以上面新建的项目为例，新增：123[group huhamhire-hosts]writable = huhamhire-hostsmembers = hamhire@myhost 随后要将客户端的公钥放到keydir目录下，并随后提交设置到服务器：123456cp ~/.ssh/id_rsa.pub ~/gitosis-admin/keydir/hamhire@myhost.pub cd ~/gitosis-admingit add ./git commit -a -m &quot;add new repo&quot;git push 由于之前已经在/home/git/repo/目录下设置了huhamhire-hosts的版本库位置，所以可以直接进行推送操作。在本例中可以通过hamhire@myhost:/home/git/repo/huhamhire-hosts的路径来提交项目。至此，gitosys的配置全部完成。 四、安装gitweb在配置完成了git服务器以后，如果需要方便在线查看，使用gitweb来提供一个简单网页版的版本显示界面是一个不错的选择。在centos 下安装gitweb如下：123456789yum install fcgi-devel cd /usr/local/src/git clone git://github.com/gnosek/fcgiwrap.gitcd fcgiwrapautoreconf -i./configuremakemake install 至此，fcgiwrap已经安装到 /usr/local/sbin/fcgiwrap然后再安装spawn-fcgi1yum install spawn-fcgi 安装好后:1234567891011121314151617vim /etc/sysconfig/spawn-fcgi# 修改文件为：# You must set some working options before the &quot;spawn-fcgi&quot; service will work.# If SOCKET points to a file, then this file is cleaned up by the init script.## See spawn-fcgi(1) for all possible options.## Example :#SOCKET=/var/run/php-fcgi.sock#OPTIONS=&quot;-u apache -g apache -s $SOCKET -S -M 0600 -C 32 -F 1 -P /var/run/spawn-fcgi.pid -- /usr/bin/php-cgi&quot;FCGI_SOCKET=/var/run/fcgiwrap.socketFCGI_PROGRAM=/usr/local/sbin/fcgiwrapFCGI_USER=nginxFCGI_GROUP=nginxFCGI_EXTRA_OPTIONS=&quot;-M 0700&quot;OPTIONS=&quot;-u $FCGI_USER -g $FCGI_GROUP -s $FCGI_SOCKET -S $FCGI_EXTRA_OPTIONS -F 1 -P /var/run/spawn-fcgi.pid -- $FCGI_PROGRAM&quot; 然后设置开机运行：12chkconfig --levels 2345 spawn-fcgi on/etc/init.d/spawn-fcgi start 这里已经完成了fcgi的安装运行。如果你用的nginx，还需要对nginx.conf进行配置，才能将.cgi的请求转发给fcgiwrap.socket1234567891011121314location /cgi-bin/ &#123; # Disable gzip (it makes scripts feel slower since they have to complete # before getting gzipped) gzip off; # Set the root to /usr/lib (inside this location this means that we are # giving access to the files under /usr/lib/cgi-bin) root /var/www/www.example.com; # Fastcgi socket fastcgi_pass unix:/var/run/fcgiwrap.socket; # Fastcgi parameters, include the standard ones include /etc/nginx/fastcgi_params; # Adjust non standard parameters (SCRIPT_FILENAME) fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; &#125; 最后重启nginx就可以了。]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux监控之cacti]]></title>
    <url>%2F2017%2F04%2F01%2F17040101%2F</url>
    <content type="text"><![CDATA[cacti 重图形，有数据历史，需用到数据库支持，支持web配置，默认不支持告警，可以加插件。 cacti安装配置1. 首先要安装epel扩展源1yum install epel-release 2. （lamp）然后分别安装httpd、php、mysql1yum install -y httpd php php-mysql mysql mysql-server mysql-devel php-gd libjpeg libjpeg-devel libpng libpng-devel 3. 安装cacti net-snmp rrdtool1yum install -y cacti net-snmp net-snmp-utils rrdtool 4. 启动服务：123/etc/init.d/mysqld start/etc/init.d/httpd start/etc/init.d/snmpd start 5. 编辑httpd配置文件1234vim /etc/httpd/conf.d/cacti.conf # 把&quot;Deny from all&quot; 改为 &quot;Allow from all&quot;/etc/init.d/httpd restart 6. 导入数据创建cacti库123mysql -uroot -e &quot;create database cacti&quot; #创建数据库mysql -uroot -e &quot;grant all on cacti.* to &apos;cacti&apos;@&apos;127.0.0.1&apos; identified by &apos;cacti&apos;;&quot; #创建cacti用户mysql -uroot cacti &lt; /usr/share/doc/cacti-0.8.8b/cacti.sql #导入cacti文件 7. 编辑cacti配置文件123456789vim /usr/share/cacti/include/config.php 更改如下：$database_type = &quot;mysql&quot;;$database_default = &quot;cacti&quot;;$database_name = &quot;cacti&quot;;$database_hostname = &quot;127.0.0.1&quot;;$database_username = &quot;cacti&quot;;$database_password = &quot;cacti&quot;;$database_port = &quot;3306&quot;;$database_ssl = false; 8. web访问cacti并安装http://192.168.209.131/cacti/点两下“next” 和一次”Finish“ 即可输入admin admin 登录，重新设置新的密码 9. 执行poller.php, 生成图形， 加入计划任务123/usr/bin/php /usr/share/cacti/poller.php添加cron任务//crontab -e 增加：*/5 * * * * /usr/bin/php /usr/share/cacti/poller.php 以下10-12步骤在客户端机器上操作 10. 安装snmp1yum install -y net-snmp 11. 修改snmpd.conf修改syslocation以及syscontact, 其中syslocation 可以写本机ip，syscontact写管理员邮箱12syslocation 192.168.209.131syscontact Root graped@aliyun.com 12. 启动snmp1service snmpd start 13. 登录cacti管理后台，点console , 再点Device， 在右上角点”Add“Description 写本机ip或你自定义一个名字Hostname 写本机ipHost Template 选ucd/net SNMP HostSNMP Version 选Version 2点右下角的create点右上角的”Create Graphs for this Host“Graph Types: 选择SNMP - Interface Statistics在下面框中选择要监控的网卡，比如我选择eth0, 在最右侧小方块里打对勾，然后点右下角的create（如果在这一步找不到网卡，可以根据这个帖子修改配置文件：cacti监控找到网卡的方法）Graph Types: 再选择 Graph Template Based在下面的框中，选择你要监控的项目，比如ucd/net - Load Average在右侧小方块中打对勾，然后点右下角的create 14. 点左侧的Graph Trees选中”Default Tree“点右上角的AddTree Item Type 选择 ”Host“Host 选择我们刚刚增加的那个机器ip点右下角的create 15. 点左上角的Graphs在左侧可以看到Defaut Tree下面已经增加了我们刚刚添加的主机，图形一开始不会那么快出来，要等一小会才可以。]]></content>
      <categories>
        <category>monitor</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 的负载均衡集群]]></title>
    <url>%2F2017%2F03%2F30%2F17033001%2F</url>
    <content type="text"><![CDATA[Nginx 的负载均衡集群Nginx的负载均衡和lvs相比，Nginx属于更高级的应用层，不会牵扯到IP和内核的改动，它只是单纯的把用户的请求转发到后面的机器上。这就意味着：后端的RS不需要配置公网IP。 1. 环境说明Nginx分发器（公网IP：192.168.0.161；内网IP：192.168.209.131）RS1：只有内网，IP为：192.168.209.132RS2：只有内网，IP为：192.168.209.133 2. 配置在nginx分发器上编辑配置文件12345678910111213141516vim /usr/local/nginx/conf/vhosts/lb.conf#加入以下内容upstream graped &#123; ip_hash; server 192.168.209.132:80; server 192.168.209.133:80;&#125;server &#123; listen 80; server_name www.123.com; location / &#123; proxy_pass http://graped/; proxy_set_header Host $host; &#125; &#125; 说明： upstream用来定义后端的RS，可以只写一个。ip_bash 为nginx的一种调度算法，加上这一行后会达到这样的效果：即一个用户的请求会始终被分发到固定的一个RS上。这样的好处是：可以避免吧同一个用户的请求分发到不同的机器上面而导致session丢失的情况。upstream里面，RS后面的IP后面还可以加权重，比如：1server 192.168.209.132:80 weight=100 还需要注意的是，upstream后面的graped是自定义的一个名字，可以随便写，唯一的要求是要和后面的proxy_pass后面保持一致。 另外：还可以根据访问的目录来区分后端Web，请参考：nginx代理扩展：根据目录区分后端web]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LB集群之LVS介绍]]></title>
    <url>%2F2017%2F03%2F29%2F17032902%2F</url>
    <content type="text"><![CDATA[1. LB集群之LVS介绍LB集群是load balance 集群的简写，翻译成中文就是负载均衡集群。常用的负载均衡开源软件有，nginx、lvs、keepalived，商业的硬件负载均衡设备有F5，Netscale。 LB集群的结构如下图，原理也很简单，就是当用户的请求过来时，会直接发到分发器（Director Server）上，然后它把用户的请求根据预先设置好的算法，只能均衡的分发到后端真正的服务器（Real Server）上。如果不同的机器，可能用户请求到的数据不一样，为了避免这样情况的发生，所以用到了共享存储，这样保证所有用户请求的数据是一样的。 LVS是一个实现负载均衡集群的开源软件项目，LVS架构从逻辑上课分为调度层（Director），server层（Real server）和共享存储。LVS从实现上，分为下面三种模式： NAT（调度器将请求的目标IP即vip改为Real Server的ip，返回的数据包也经过调度器，调度器再把原地址修改为vip）。 TUN （调度器将请求来的数据包封装加密通过IP隧道转发到后端的real server上，而real server会直接把数据返回给客户端，而不再经过调度器。） DR （调度器将请求来的数据包的目标mac地址改为real server的mac地址，返回的时候也不经过调度器，直接返回给客户端） 参考资料：LVS原理详解（3种工作方式8种调度算法） 图中出现的几个IP概念，需要解释一下： DIP（Director ip）为分发器IP，NAT模式下它必须是公网IP，要对外服务。 VIP（Virtual ip）为虚拟IP，用在TUN和DR模式中，需要同时配置在分发器和后端真实服务器上。 RIP（Real ip）为后端真实服务器的IP，在TUN和DR模式中，RIP为公网IP。 要想把用户的请求调度给后端RS，是需要经过调度算法来实现的，那么关于LVS的调度算法，都有哪些？ 轮叫调度（Round Robin）（简称rr），这种算法是最简单的，不管后端RS配置和处理能力，非常均衡的分发下去。 加权轮叫（Weighted Round Robin）（简称wrr），比上面的算法多了一个权重概念，可以给RS设置权重，权重越高，那么分发的请求数越多，权重的取值范围0-100. 最少链接（least connection）（LC），这个算法会根据后端RS的连接数来决定把请求分发给谁，比如RS1链接数比RS2链接数少，那么请求就优先发给RS1。 加权最少链接（Weighted Least Connection）（WLC），比第三个算法多了一个权重概念。 基于局部性的最少连接调度算法(lblc)是请求数据包的目标IP地址的一种调度算法，该算法先根据请求的目标IP地址寻找最近的该目标IP地址所有使用的服务器，如果这台服务器依然可用，并且用能力处理该请求，调度器会尽量选择相同的服务器，否则会继续选择其他可行的服务器。 带复杂的基于局部性最少的连接算法(lblcr)激励的不是一个目标IP与一台服务器之间的连接记录，他会维护一个目标IP到一组服务器之间的映射关系，防止单点服务器负责过高。 目标地址散列调度算法(DH)也是根据目标IP地址通过散列函数将目标IP与服务器建立映射关系，出现服务器不可用或负载过高的情况下，发往该目标IP的请求会固定发给该服务器。 源地址散列调度算法(SH)与目标地址散列调度算法类似，但它是根据源地址散列算法进行静态分配固定的服务器资源。 2. LVS的NAT模式1. 环境说明台服务器一台作为director, 两台作为real serverDirector 有一个外网ip (192.168.31.166) 和一个内网ip(192.168.21.166), 两个real server上只有内网ip(192.168.21.100)和(192.168.21.101) 并且需要把两个real server的内网网关设置为director的内网ip(192.168.21.166) 补充：lvs nat模式时设置网络环境的方法 2. 安装和配置两个real server 上都安装httpd:1yum install -y nginx Director上安装ipvsadm1yum install -y ipvsadm Direcotr 上12345678910111213141516171819202122vim /usr/local/sbin/lvs_nat.sh //增加:#! /bin/bash# director 服务器上开启路由转发功能: echo 1 &gt; /proc/sys/net/ipv4/ip_forward # 关闭icmp的重定向echo 0 &gt; /proc/sys/net/ipv4/conf/all/send_redirectsecho 0 &gt; /proc/sys/net/ipv4/conf/default/send_redirectsecho 0 &gt; /proc/sys/net/ipv4/conf/eth0/send_redirectsecho 0 &gt; /proc/sys/net/ipv4/conf/eth1/send_redirects# director 设置nat防火墙iptables -t nat -Fiptables -t nat -Xiptables -t nat -A POSTROUTING -s 192.168.21.0/24 -j MASQUERADE# director设置ipvsadmIPVSADM=&apos;/sbin/ipvsadm&apos;$IPVSADM -C$IPVSADM -A -t 192.168.31.166:80 -s lc -p 300$IPVSADM -a -t 192.168.31.166:80 -r 192.168.21.100:80 -m -w 1$IPVSADM -a -t 192.168.31.166:80 -r 192.168.21.101:80 -m -w 1 直接运行这个脚本就可以完成lvs/nat的配置了: 1/bin/bash /usr/local/sbin/lvs_nat.sh 3. 测试通过浏览器测试两台机器上的web内容，为了区分开，我们可以把nginx的默认页修改一下： 12rs1上： echo &quot;rs1rs1&quot; &gt;/usr/share/nginx/html/index.htmlrs2上： echo &quot;rs2rs2&quot; &gt;/usr/share/nginx/html/index.html 3. LVS的DR设置1. 环境说明三台机器:director(eth0192.168.31.166, vip eth0:0: 192.168.31.110)real server1(eth0 rip: 192.168. 31.100, vip lo:0: 192.168.31.110)real server2(eth0 rip: 192.168.31.101, vip lo:0: 192.168.31.110) 2. 编写脚本Director 上1234567891011121314vim /usr/local/sbin/lvs_dr.sh //增加#! /bin/bashecho 1 &gt; /proc/sys/net/ipv4/ip_forwardipv=/sbin/ipvsadmvip=192.168.31.110rs1=192.168.31.100rs2=192.168.31.101ifconfig eth0:0 $vip broadcast $vip netmask 255.255.255.255 uproute add -host $vip dev eth0:0$ipv -C$ipv -A -t $vip:80 -s rr $ipv -a -t $vip:80 -r $rs1:80 -g -w 1$ipv -a -t $vip:80 -r $rs2:80 -g -w 1 两台rs上：123456789vim /usr/local/sbin/lvs_dr_rs.sh#! /bin/bashvip=192.168.31.110ifconfig lo:0 $vip broadcast $vip netmask 255.255.255.255 up route add -host $vip lo:0echo &quot;1&quot; &gt;/proc/sys/net/ipv4/conf/lo/arp_ignoreecho &quot;2&quot; &gt;/proc/sys/net/ipv4/conf/lo/arp_announceecho &quot;1&quot; &gt;/proc/sys/net/ipv4/conf/all/arp_ignoreecho &quot;2&quot; &gt;/proc/sys/net/ipv4/conf/all/arp_announce 关于arp_ignore和 arp_announce参考：LVS负载均衡中arp_ignore和arp_annonuce参数配置的含义 然后director上执行:1bash /usr/local/sbin/lvs_dr.sh 两台rs上执行:1bash /usr/local/sbin/lvs_dr_rs.sh Windows下浏览器测试访问。 4. LVS/DR + keepalived配置注意：前面虽然我们已经配置过一些操作，但是下面我们使用keepaliave操作和之前的操作是有些冲突的，所以若是之前配置过DR，请首先做如下操作： dr上执行：12$ipv -Cifconfig eth0:0 down 前面的lvs虽然已经配置成功也实现了负载均衡，但是我们测试的时候发现，当某台real server把httpd进程停掉，那么director照样会把请求转发过去，这样就造成了某些请求不正常。所以需要有一种机制用来检测real server的状态，这就是keepalived。它的作用除了可以检测rs状态外，还可以检测备用director的状态，也就是说keepalived可以实现ha集群的功能，当然了也需要一台备用director.备用director也需要安装一下keepalived软件 1yum install -y keepalived 安装好后，编辑配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041vim /etc/keepalived/keepalived.conf //加入如下：vrrp_instance VI_1 &#123; state MASTER #备用服务器上为 BACKUP interface eth0 virtual_router_id 51 priority 100 #备用服务器上为90 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.31.110 &#125;&#125;virtual_server 192.168.31.110 80 &#123; delay_loop 6 #(每隔10秒查询realserver状态) lb_algo wlc #(lvs 算法) lb_kind DR #(Direct Route) persistence_timeout 60 #(同一IP的连接60秒内被分配到同一台realserver) protocol TCP #(用TCP协议检查realserver状态)real_server 192.168.31.100 80 &#123; weight 100 #(权重) TCP_CHECK &#123; connect_timeout 10 #(10秒无响应超时) nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125;real_server 192.168.31.101 80 &#123; weight 100 TCP_CHECK &#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125;&#125; 以上为主director的配置文件，从director的配置文件只需要修改 12state MASTER -&gt; state BACKUPpriority 100 -&gt; priority 90 配置完keepalived后，需要开启端口转发（主从都要做）： 1echo 1 &gt; /proc/sys/net/ipv4/ip_forward 然后，两个rs上执行 /usr/local/sbin/lvs_dr_rs.sh 脚本：1bash /usr/local/sbin/lvs_dr_rs.sh 最后，两个director上启动keepalived服务（先主后从）： 1/etc/init.d/keepalived start 另外，需要注意的是，启动keepalived服务会自动生成vip和ipvsadm规则，不需要再去执行上面提到的/usr/local/sbin/lvs_dr.sh 脚本。]]></content>
      <categories>
        <category>LVS</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HA集群配置]]></title>
    <url>%2F2017%2F03%2F29%2F17032901%2F</url>
    <content type="text"><![CDATA[HA集群配置HA 即 （high available）高可用，又被叫做双机热备，用于关键性业务。 简单理解就是，有两台机器A和B，正常是A提供服务，B待命闲置，当A宕机或服务宕掉，会切换至B机器继续提供服务。常用实现高可用的开源软件有heartbeat和keepalived，其中keepalived有负载均衡的功能。如图所示为一个HA架构，一个交换机下面有两台机器web1和web2，其中web1为主节点，正常是它在提供服务，web2为备用闲置节点。web1和web2中间有一个心跳线，检查对方是否存活状态。流动IP，也叫vip是对外提供服务的IP，正常情况下是配置在web1上的，当web1宕机后，web2会自动配置该vip，对外提供服务。 下面我们用heartbeat来做HA集群，并且把Nginx服务作为HA对应的服务。 准备工作：两个机器，都是CentOS6.5 网卡eth0 ip如下： master 192.168.0.161 slave 192.168.0.162 1. 设置hostname （主从上都要进行）123456# 在主上hostname masterbash#在从上hostname slavebash 2. 关闭防火墙 （主从上都要进行）123456# iptablesiptables -F service iptables save# selinuxsetenforce 0sed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/&apos; /etc/selinux/config 3. 配置hosts （主从上都要进行）1234vim /etc/hosts# 加入：192.168.0.161 master192.168.0.162 slave 4. 安装epel扩展源 （主从上都要进行）1yum install -y epel-release 5. 安装heartbeat libnet Nginx1yum install -y heartbeat* libnet nginx 6. 主（master）上配置12345678910111213141516171819202122232425262728cd /usr/share/doc/heartbeat-3.0.4/cp authkeys ha.cf haresources /etc/ha.d/cd /etc/ha.dvi authkeys //加入或更改为auth 33 md5 Hello!chmod 600 authkeysvi haresources //加入master 192.168.0.150/24/eth0:0 nginx vi ha.cf //改为如下内容：debugfile /var/log/ha-debuglogfile /var/log/ha-loglogfacility local0keepalive 2deadtime 30warntime 10initdead 60udpport 694ucast eth0 192.168.0.162auto_failback onnode masternode slaveping 192.168.0.1respawn hacluster /usr/lib/heartbeat/ipfail 配置说明： debugfile /var/log/ha-debug：保存heartbeat的调试信息； dlogfile /var/log/ha-log：heartbeat日志信息； dlogfacility local0：日志级别； dkeepalive 2：跳时间间隔； ddeadtime 30：超出该时间间隔未收到对方节点心跳，则认为对方已死亡； dwarntime 10：超出该时间间隔未收到对方节点心跳，则发出警告并记录到日志； dinitdead 60：在某些系统上，系统启动或重启之后需要经过一段时间网络才能恢复正常工作，该选项用于解决这种情况产生的时间间隔； dudpport 694：设置广播通信使用的端口，649为默认端口； ducast eth0 192.168.0.162：设置对方奇迹心跳检测的网卡和IP； dauto_failback on：heartbeat的两台之极分别为主节点和从节点，主节点在正常情况下占用资源并运行所有服务，遇到故障时把资源交给从节点并由从节点运行服务； dnode master：指定主； dnode slave：指定从； dping 192.168.0.1 drespawn hacluster/usr/lib/heartbeat/ipfail：指定与heartbeat一同启动和关闭的进程，该进程被自动监听视，遇到故障则从新启动。最常见的进程是ipfail，该进程用于检测和处理网络故障，需要配合ping语句指定pingnode来检测网络连接。如果你的系统是64位，请注意该文件路径 7. 把主上的三个配置拷贝到从上12cd /etc/ha.d/scp authkeys ha.cf haresources slave:/etc/ha.d/ 8. 到从上(slave) 编辑ha.cf12vi /etc/ha.d/ha.cf //只需要更改一个地方ucast eth1 192.168.0.162 改为 ucast eth1 192.168.0.161 9. 启动heartbeat先主后从 1service heartbeat start 10. 检查测试1ifconfig 看是否有 eth0:0 1ps aux |grep nginx 看是否有nginx进程 11. 测试1主上故意禁ping 1iptables -I INPUT -p icmp -j DROP 可以看到日志/var/log/ha-log 发生如下变化 1234567891011121314151617181920212223242526ResourceManager(default)[1751]: 2017/03/28_23:01:07 info: Running /etc/init.d/nginx startMar 28 23:06:49 master heartbeat: [1543]: WARN: node 192.168.0.1: is deadMar 28 23:06:49 master heartbeat: [1543]: info: Link 192.168.0.1:192.168.0.1 dead.Mar 28 23:06:49 master ipfail: [1571]: info: Status update: Node 192.168.0.1 now has status deadharc(default)[2053]: 2017/03/28_23:06:49 info: Running /etc/ha.d//rc.d/status statusMar 28 23:06:51 master ipfail: [1571]: info: NS: We are dead. :&lt;Mar 28 23:06:51 master ipfail: [1571]: info: Link Status update: Link 192.168.0.1/192.168.0.1 now has status deadMar 28 23:06:52 master ipfail: [1571]: info: We are dead. :&lt;Mar 28 23:06:52 master ipfail: [1571]: info: Asking other side for ping node count.Mar 28 23:06:55 master ipfail: [1571]: info: Giving up because we were told that we have less ping nodes.Mar 28 23:06:55 master ipfail: [1571]: info: Delayed giveup in 4 seconds.Mar 28 23:06:59 master ipfail: [1571]: info: giveup() called (timeout worked)Mar 28 23:06:59 master heartbeat: [1543]: info: master wants to go standby [all]Mar 28 23:07:00 master heartbeat: [1543]: info: standby: slave can take our all resourcesMar 28 23:07:00 master heartbeat: [2079]: info: give up all HA resources (standby).ResourceManager(default)[2092]: 2017/03/28_23:07:00 info: Releasing resource group: master 192.168.0.150/24/eth0:0 nginxResourceManager(default)[2092]: 2017/03/28_23:07:00 info: Running /etc/init.d/nginx stopResourceManager(default)[2092]: 2017/03/28_23:07:00 info: Running /etc/ha.d/resource.d/IPaddr 192.168.0.150/24/eth0:0 stopIPaddr(IPaddr_192.168.0.150)[2178]: 2017/03/28_23:07:00 INFO: IP status = ok, IP_CIP=/usr/lib/ocf/resource.d//heartbeat/IPaddr(IPaddr_192.168.0.150)[2152]: 2017/03/28_23:07:00 INFO: SuccessMar 28 23:07:00 master heartbeat: [2079]: info: all HA resource release completed (standby).Mar 28 23:07:00 master heartbeat: [1543]: info: Local standby process completed [all].Mar 28 23:07:02 master heartbeat: [1543]: WARN: 1 lost packet(s) for [slave] [197:199]Mar 28 23:07:02 master heartbeat: [1543]: info: remote resource transition completed.Mar 28 23:07:02 master heartbeat: [1543]: info: No pkts missing from slave!Mar 28 23:07:02 master heartbeat: [1543]: info: Other node completed standby takeover of all resources. 12. 测试2主上停止heartbeat服务 1service heartbeat stop]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS服务及安装配置]]></title>
    <url>%2F2017%2F03%2F27%2F17032701%2F</url>
    <content type="text"><![CDATA[DNS介绍DNS 为Domain Name System（域名系统）的缩写，它是一种将ip地址转换成对应的主机名或将主机名转换成与之相对应ip地址的一种服务机制。 其中通过域名解析出ip地址的叫做正向解析，通过ip地址解析出域名的叫做反向解析。 DNS使用TCP和UDP, 端口号都是53, 但它主要使用UDP，服务器之间备份使用TCP。 全世界只有13台“根”服务器，1个主根服务器放在美国，其他12台为辅根服务器，DNS服务器根据角色可以分为：主DNS, 从DNS, 缓存DNS服务器，DNS转发服务器。 有了网站域名，下面来看看域名www.baidu.com是如何解析到IP的，下图为域名解析流程图： 域名解析过程 在浏览器输入www.baidu.com域名，操作系统会先检查自己本地的hosts文件，是否有这个网址的映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 如果hosts里没有这个域名的映射，则查找本地的DNS解析缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 如果hosts与本地DNS解析缓存器中都没有相应的网址映射关系，首先会找本机设置的首选DNS服务器，再次我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址的映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。 如果本地DNS服务器本地区域文件与缓存解析都失败，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用本地转发，本地DNS就把请求发至13台跟DNS，跟DNS收到请求后会判断这个域名（.com）是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS收到IP后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己已无法解析，他会找一个关系.com域下一级的DNS服务器地址（baidu.com）域服务器，重复上面的动作进行查询，直到找到www.baidu.com主机。 如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级进行解析，上一级服务器如果不能解析，或找跟DNS或把转发请求转至上上级，以此循环，不管是本地DNS服务器用到是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由这个DNS服务器再返回给客户机。 DNS安装配置我们使用bind来搭建DNS服务首先： 1. 安装bind1yum install -y bind bind-utils 清空默认配置文件，自定义配置。12345678910111213141516171819cp /etc/named.conf /etc/named.conf.bak &gt;/etc/named.confvim /etc/named.conf #写入如下配置options &#123; directory &quot;/var/named&quot;;&#125;;zone &quot;.&quot; IN &#123; type hint; file &quot;named.ca&quot;;&#125;;zone &quot;localhost&quot; IN &#123; type master; file &quot;localhost.zone&quot;;&#125;;zone &quot;0.0.127.in-addr.arpa&quot; IN &#123; type master; file &quot;named.local&quot;;&#125;; 保存配置，然后修改其属性，定义本地根域配置 123chown named /etc/named.confcd /var/named/dig -t NS . &gt; named.ca 2. 增加一个域名（zone）1234567891011121314vim /etc/named.conf // 增加:zone &quot;123.com&quot; IN &#123; type master; file &quot;123.com.zone&quot;;&#125;;zone &quot;189.168.192.in-addr.arpa&quot; IN &#123; type master; file &quot;189.168.192.zone&quot;;&#125;;// 修改： listen-on port 53 &#123; 127.0.0.1;192.168.189.131; &#125;; 编辑zone文件:12345678910111213141516vim /var/named/123.com.zone//增加下列配置： $TTL 1D@ IN SOA @ admin.123.com. ( 2017032602 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum IN NS ns.123.com. IN MX 5 mail.123.com.mail IN A 192.168.189.133ns IN A 192.168.189.131www IN A 11.11.11.11bbs IN CNAME www 编辑反解析文件:123456789101112vim /var/named/189.168.192.zone//增加$TTL 1D@ IN SOA @ admin.123.com. ( 20170326 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum IN NS ns.123.com.131 IN PTR ns.123.com.133 IN PTR mail.123.com. 重启named服务，测试 12345/etc/init.d/named restart 停止 named： [确定]启动 named： [确定]dig @192.168.189.131 www.123.com #检测正解析dig @192.168.189.131 -x 192.168.189.131 #检测反解析 3. 配置DNS转发我们配置的DNS是只能解析我们定义的zone的，我们没有定义的是不能解析的。配置DNS转发就可以解析其他互联网上的域名了，前提是这个域名在互联网中的确在使用，也就是说这个域名已经被某个DNS服务器解析了。1234vim /etc/named.conf //在options&#123;&#125; 里面增加forward first; forwarders &#123; 114.114.114.114; &#125;; 这两行就是用来配置转发的，该DNS服务器不能解析的域名会转发到114.114.114.114这个DNS服务器上去解析。 4. 配置主从在从服务器上1yum install -y bind bind-utils 修改一下从的/etc/named.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546options &#123;// listen-on port 53 &#123; 127.0.0.1; &#125;; // listen-on-v6 port 53 &#123; ::1; &#125;;// 注释掉后表明监听任何端口 directory &quot;/var/named&quot;; dump-file &quot;/var/named/data/cache_dump.db&quot;; statistics-file &quot;/var/named/data/named_stats.txt&quot;; memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;; allow-query &#123; localhost; &#125;; recursion yes; dnssec-enable yes; dnssec-validation yes; /* Path to ISC DLV key */ bindkeys-file &quot;/etc/named.iscdlv.key&quot;; managed-keys-directory &quot;/var/named/dynamic&quot;;&#125;;logging &#123; channel default_debug &#123; file &quot;data/named.run&quot;; severity dynamic; &#125;;&#125;;zone &quot;.&quot; IN &#123; type hint; file &quot;named.ca&quot;;&#125;;include &quot;/etc/named.rfc1912.zones&quot;;include &quot;/etc/named.root.key&quot;;zone &quot;123.com&quot; IN &#123; type slave ; file &quot;slaves/123.com.zone&quot;; masters &#123; 192.168.189.131; &#125;;&#125;;zone &quot;189.168.192.in-addr.arpa&quot; IN &#123; type slave; file &quot;slaves/189.168.192.zone&quot;; masters &#123; 192.168.189.131; &#125;;&#125;; 从上生成rndc.key:12rndc-confgen -r /dev/urandom -a chown named:named /etc/rndc.key 从上启动named:1/etc/init.d/named start 启动成功后会在 /var/named/下生成一个slaves目录，这个目录下会有192.168.zone, abc.com.zone这两个文件，内容是和主上的一样的在从上测试：12dig @192.168.189.133 www.123.com #检测正解析dig @192.168.189.132 -x 192.168.189.131 #检测反解析 5. 测试主从同步在主dns上更改文件1234vim /var/named/123.com.zone // 在最后增加一行：graped IN A 111.111.111.111 另外需要修改一下第三行的那个数字串，这个是用来做标记的，只有这个数字变化了，才可以让从自动跟着变，数字只能是变大，不能减小，12016081601 -&gt; 2016081602 重启主namd服务:1/etc/init.d/named restart 经测试我们发现一个问题，就是从经常会同步特别慢，这是很要命的。所以需要我们做一个特殊操作，在主上的/etc/named.conf中，123.com的zone中增加两行： 12notify yes;also-notify &#123; 192.168.0.12; &#125;;]]></content>
      <categories>
        <category>Linux_Network</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用mysql-proxy 快速实现mysql 集群 读写分离]]></title>
    <url>%2F2017%2F03%2F23%2F17032304%2F</url>
    <content type="text"><![CDATA[使用mysql-proxy 快速实现mysql 集群 读写分离目前较为常见的mysql读写分离分为两种： 基于程序代码内部实现：在代码中对select操作分发到从库；其它操作由主库执行；这类方法也是目前生产环境应用最广泛，知名的如DISCUZ X2。优点是性能较好，因为在程序代码中实现，不需要增加额外的设备作为硬件开支。缺点是需要开发人员来实现，运维人员无从下手。 基于中间代理层实现：我们都知道代理一般是位于客户端和服务器之间，代理服务器接到客户端请求后通过判断然后转发到后端数据库。在这有两个代表性程序。 mysql-proxy： mysql-proxy为mysql开源项目，通过其自带的lua脚本进行sql判断，虽然是mysql官方产品，但是mysql官方并不建议将mysql-proxy用到生产环境。 amoeba： 由陈思儒开发，作者曾就职于阿里巴巴，现就职于盛大。该程序由java语言进行开发，目前只听说阿里巴巴将其用于生产环境。另外，此项目严重缺少维护和推广（作者有个官方博客，很多用户反馈的问题发现作者不理睬） 经过上述简单的比较，通过程序代码实现mysql读写分离自然是一个不错的选择。但是并不是所有的应用都适合在程序代码中实现读写分离，像大型SNS、B2C这类应用可以在代码中实现，因为这样对程序代码本身改动较小；像一些大型复杂的java应用，这种类型的应用在代码中实现对代码改动就较大了。所以，像这种应用一般就会考虑使用代理层来实现。 下面我们看一下如何搭建mysql-proxy来实现mysql读写分离。 环境拓扑如下： 关于mysql、mysql主从的搭建，在此不再演示，如下的操作均在mysql-proxy（192.168.1.200）服务器进行。 1. 安装mysql-proxyi. 安装lua (mysql-proxy需要使用lua脚本进行数据转发) 1234567tar zxvf lua-5.1.4.tar.gz cd lua-5.1.4 vi Makefile，修改INSTALL_TOP= /usr/local/lua make posix make install ii. 安装libevent 12345tar zxvf libevent-2.0.8-rc.tar.gz cd libevent-2.0.8-rc ./configure --prefix=/usr/local/libevent make &amp;&amp; make install iii. 安装check123tar zxvf check-0.9.8.tar.gz cd check-0.9.8 ./configure &amp;&amp; make &amp;&amp; make install iv. 安装mysql客户端 123tar zxvf mysql-5.0.92.tar.gz cd mysql-5.0.92 ./configure --without-server &amp;&amp; make &amp;&amp; make install v. 设置环境变量 （安装mysql-proxy所需变量） 12345vi /etc/profile export LUA_CFLAGS=&quot;-I/usr/local/lua/include&quot; LUA_LIBS=&quot;-L/usr/local/lua/lib -llua -ldl&quot; LDFLAGS=&quot;-L/usr/local/libevent/lib -lm&quot; export CPPFLAGS=&quot;-I/usr/local/libevent/include&quot; export CFLAGS=&quot;-I/usr/local/libevent/include&quot; source /etc/profile vi. 安装mysql-proxy 12345tar zxvf mysql-proxy-0.6.0.tar.gz cd mysql-proxy-0.6.0 ./configure --prefix=/usr/local/mysql-proxy --with-mysql --with-lua make &amp;&amp; make install vii. 启动mysql-proxy 本次对两台数据库实现了读写分离；mysql-master为可读可写，mysql-slave为只读1234/usr/local/mysql-proxy/sbin/mysql-proxy --proxy-backend-addresses=192.168.1.201:3306 --proxy-read-only-backend-addresses=192.168.1.202:3306 --proxy-lua-script=/usr/local/mysql-proxy/share/mysql-proxy/rw-splitting.lua &amp; 注：如果正常情况下启动后终端不会有任何提示信息，mysql-proxy启动后会启动两个端口4040和4041，4040用于SQL转发，4041用于管理mysql-proxy。如有多个mysql-slave可以依次在后面添加 2. 测试i. 连接测试 因为默认情况下mysql数据库不允许用户在远程连接1234mysql&gt;grant all privileges on *.* to identified by &apos;123456&apos;; mysql&gt;flush privileges; 客户端连接1mysql -uroot -p123456 -h192.168.1.200 -P4040 ii. 读写分离测试 为了测试出mysql读写分离的真实性，在测试之前，需要开启两台mysql的log功能，然后在mysql-slave服务器停止复制 ① 在两台mysql配置文件my.cnf中加入log=query.log，然后重启 ② 在mysql-slave上执行SQL语句stop slave ③ 在两台mysql上执行#tail -f /usr/local/mysql/var/query.log ④ 在客户端上连接mysql（三个连接以上），然后执行create、select等SQL语句，观察两台mysql的日志有何变化 注：生产环境中除了进行程序调试外，其它不要开启mysql查询日志，因为查询日志记录了客户端的所有语句，频繁的IO操作将会导致mysql整体性能下降 总结：在上述环境中，mysql-proxy和mysql-master、mysql-slave三台服务器均存在单点故障。如果在可用性要求较高的场合，单点隐患是绝对不允许的。为了避免mysql-proxy单点隐患有两种方法，一种方法是mysql-proxy配合keepalived做双机，另一种方法是将mysql-proxy和应用服务安装到同一台服务器上；为了避免mysql-master单点故障可以使用DRBD+heartbear做双机；避免mysql-slave单点故障增加多台mysql-slave即可，因为mysql-proxy会自动屏蔽后端发生故障的mysql-slave。 附: mysql-proxy LUA 读写分离脚本代码:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327--[[---- author : KDr2 -- version 0.01-- SYNOPSIS:--- 1.维护了一个连接池--- 2.读写分离，简单的将select开头的语句放到slave上执行--- 3.事务支持，所有事务放到master上执行，事务中不更改连接--- 4.简单日志----]]--- config varslocal min_idle_connections = 4local max_idle_connections = 8local log_level=1local encoding=&quot;utf8&quot;--- end of config-- 事务标识，在事务内不归还连接local transaction_flags=&#123;&#125;setmetatable(transaction_flags,&#123;__index=function() return 0 end&#125;)-- log systemlog=&#123; level=&#123;debug=1,info=2,warn=3,error=4&#125;, funcs=&#123;&quot;debug&quot;,&quot;info&quot;,&quot;warn&quot;,&quot;error&quot;&#125;,&#125;function log.log(level,m) if level &gt;= log_level then local msg=&quot;[&quot; .. os.date(&quot;%Y-%m-%d %X&quot;) ..&quot;] &quot;.. log.funcs[level] .. &quot;: &quot; .. tostring(m) print(msg) -- TODO write msg into a log file. endendfor i,v in ipairs(log.funcs) do log[v]=function(m) log.log(log.level[v],m) endend-- connect to serverfunction connect_server() log.info(&quot; starting connect_server ... &quot;) local least_idle_conns_ndx = 0 local least_idle_conns = 0 for i = 1, #proxy.backends do local s = proxy.backends[i] local pool = s.pool local cur_idle = pool.users[&quot;&quot;].cur_idle_connections log.debug(&quot;[&quot;.. s.address ..&quot;].connected_clients = &quot; .. s.connected_clients) log.debug(&quot;[&quot;.. s.address ..&quot;].idling_connections = &quot; .. cur_idle) log.debug(&quot;[&quot;.. s.address ..&quot;].type = &quot; .. s.type) log.debug(&quot;[&quot;.. s.address ..&quot;].state = &quot; .. s.state) if s.state ~= proxy.BACKEND_STATE_DOWN then -- try to connect to each backend once at least if cur_idle == 0 then proxy.connection.backend_ndx = i log.info(&quot;server [&quot;.. proxy.backends[i].address ..&quot;] open new connection&quot;) return end -- try to open at least min_idle_connections if least_idle_conns_ndx == 0 or ( cur_idle &lt; min_idle_connections and cur_idle &lt; least_idle_conns ) then least_idle_conns_ndx = i least_idle_conns = cur_idle end end end if least_idle_conns_ndx &gt; 0 then proxy.connection.backend_ndx = least_idle_conns_ndx end if proxy.connection.backend_ndx &gt; 0 then local s = proxy.backends[proxy.connection.backend_ndx] local pool = s.pool local cur_idle = pool.users[&quot;&quot;].cur_idle_connections if cur_idle &gt;= min_idle_connections then -- we have 4 idling connections in the pool, that&apos;s good enough log.debug(&quot;using pooled connection from: &quot; .. proxy.connection.backend_ndx) return proxy.PROXY_IGNORE_RESULT end end -- open a new connection log.info(&quot;opening new connection on: &quot; .. proxy.backends[proxy.connection.backend_ndx].address)end----- auth.packet is the packetfunction read_auth_result( auth ) if auth.packet:byte() == proxy.MYSQLD_PACKET_OK then -- 连接正常 proxy.connection.backend_ndx = 0 elseif auth.packet:byte() == proxy.MYSQLD_PACKET_EOF then -- we received either a -- * MYSQLD_PACKET_ERR and the auth failed or -- * MYSQLD_PACKET_EOF which means a OLD PASSWORD (4.0) was sent log.error(&quot;(read_auth_result) ... not ok yet&quot;); elseif auth.packet:byte() == proxy.MYSQLD_PACKET_ERR then log.error(&quot;auth failed!&quot;) endend--- -- read/write splittingfunction read_query( packet ) log.debug(&quot;[read_query]&quot;) log.debug(&quot;authed backend = &quot; .. proxy.connection.backend_ndx) log.debug(&quot;used db = &quot; .. proxy.connection.client.default_db) if packet:byte() == proxy.COM_QUIT then proxy.response = &#123; type = proxy.MYSQLD_PACKET_OK, &#125; return proxy.PROXY_SEND_RESULT end if proxy.connection.backend_ndx == 0 then local is_read=(string.upper(packet:sub(2))):match(&quot;^SELECT&quot;) local target_type=proxy.BACKEND_TYPE_RW if is_read then target_type=proxy.BACKEND_TYPE_RO end for i = 1, #proxy.backends do local s = proxy.backends[i] local pool = s.pool local cur_idle = pool.users[proxy.connection.client.username].cur_idle_connections if cur_idle &gt; 0 and s.state ~= proxy.BACKEND_STATE_DOWN and s.type == target_type then proxy.connection.backend_ndx = i break end end end -- sync the client-side default_db with the server-side default_db if proxy.connection.server and proxy.connection.client.default_db ~= proxy.connection.server.default_db then local server_db=proxy.connection.server.default_db local client_db=proxy.connection.client.default_db local default_db= (#client_db &gt; 0) and client_db or server_db if #default_db &gt; 0 then proxy.queries:append(2, string.char(proxy.COM_INIT_DB) .. default_db) proxy.queries:append(2, string.char(proxy.COM_QUERY) .. &quot;set names &apos;&quot; .. encoding ..&quot;&apos;&quot;) log.info(&quot;change database to &quot; .. default_db); end end if proxy.connection.backend_ndx &gt; 0 then log.debug(&quot;Query[&quot; .. packet:sub(2) .. &quot;] Target is [&quot; .. proxy.backends[proxy.connection.backend_ndx].address ..&quot;]&quot;) end proxy.queries:append(1, packet) return proxy.PROXY_SEND_QUERYend----- as long as we are in a transaction keep the connection-- otherwise release it so another client can use itfunction read_query_result( inj ) local res = assert(inj.resultset) local flags = res.flags if inj.id ~= 1 then -- ignore the result of the USE &lt;default_db&gt; return proxy.PROXY_IGNORE_RESULT end is_in_transaction = flags.in_trans if flags.in_trans then transaction_flags[proxy.connection.server.thread_id] = transaction_flags[proxy.connection.server.thread_id] + 1 elseif inj.query:sub(2):lower():match(&quot;^%s*commit%s*$&quot;) or inj.query:sub(2):lower():match(&quot;^%s*rollback%s*$&quot;) then transaction_flags[proxy.connection.server.thread_id] = transaction_flags[proxy.connection.server.thread_id] - 1 if transaction_flags[proxy.connection.server.thread_id] &lt; 0 then transaction_flags[proxy.connection.server.thread_id] = 0 end end log.debug(&quot;transaction res : &quot; .. tostring(transaction_flags[proxy.connection.server.thread_id])); if transaction_flags[proxy.connection.server.thread_id]==0 or transaction_flags[proxy.connection.server.thread_id] == nil then -- isnot in a transaction, need to release the backend proxy.connection.backend_ndx = 0 endend--- -- close the connections if we have enough connections in the pool---- @return nil - close connection -- IGNORE_RESULT - store connection in the poolfunction disconnect_client() log.debug(&quot;[disconnect_client]&quot;) if proxy.connection.backend_ndx == 0 then for i = 1, #proxy.backends do local s = proxy.backends[i] local pool = s.pool local cur_idle = pool.users[proxy.connection.client.username].cur_idle_connections if s.state ~= proxy.BACKEND_STATE_DOWN and cur_idle &gt; max_idle_connections then -- try to disconnect a backend proxy.connection.backend_ndx = i log.info(&quot;[&quot;.. proxy.backends[i].address ..&quot;] closing connection, idling: &quot; .. cur_idle) return end end return proxy.PROXY_IGNORE_RESULT endend]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看mysql主从复制延迟和数据中断--带脚本]]></title>
    <url>%2F2017%2F03%2F23%2F17032303%2F</url>
    <content type="text"><![CDATA[查看mySQL延迟的方法，查看了多个案例，大家众说纷纭，意见差不多一致。如下也是我参考别人经验做的一些测试，希望能检测到mysql复制延迟、数据中断。 方法一、查看Seconds_Behind_Master该参数有如下值： NULL 表示io_thread或sql_thread有一个发生故障，就是说该线程的Running状态时No，而非Yes0 表示主从复制良好，没有lag存在正值 表示主从已出现延时，数字越大表示从库落后主库越多负值 很罕见，是一个BUG，按理说不应该出现 该方法是使用命令show slave status,通过比较SQL THREAD接受events时间的时间戳与IO THREAD执行事件events时间戳的差值–秒数，来确定slave落后于master多少，如主从 时间不同，改时间的计算不受影响众所周知备库relay-log和主库的bin-log里的内容一样，真正和主库有关两的是io_thread，当主库I/O负载很大或网络阻塞时，io_thread不能及时复制binlog，而sql_thread一 直能跟上io_thread的脚步，这时seconds_behind_master的值是0，实际上却不是，这时用该值作为延迟参考则不准。change master to master_host=’192.168.2.7’,master_user=’tongbu’,master_password=’123456’,master_log_file=’mysql-bin.000008’,master_log_pos=291263843; 方法二、使用pt-heartbeat工具 该工具可以计算出MySQL复制或者是PostgreSQL,它可以更新master或者监控复制。它还可以从f 读取配置。它借助timestmp的比较实现的，首先需要保证主从服务器时间必须要 保持一致，通过与相同的一个NTP server同步时钟。它需要在主库上创建一个heartbeat的表，里面的时间戳ts就是当前的时间戳 now()，该结构也会被复制到从库上。表建好以后 ，会在主库上以后台进程的模式去执行一行更新操作的命令，定期去向表中的插入数据，这 个周期默认为1 秒，同时从库也会在后台执行一个监控命令，与主库保持一致的周期 +0.5S（默认0.5S延迟检查）去比较，复制过来记录的ts值与主库上的同一条ts值，差值为0表示无延时，差值越大表示 延时的秒数越多。 使用工具前提： 在主库上建立heartbeat表 1pt-heartbeat -h localhost -D test --create-table --update 更新主库上的heartbeat 1pt-heartbeat -D test --master-server-id=1 --update 在从库上监控复制延迟 1234567891011121314151617pt-heartbeat --user=tongbu --password=&apos;123456&apos; -D test --monitor -h 192.168.2.9 --print-master-server-id0.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.01s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 1 当然还有其他一些操作命令： 12345678910111213#将主库上的update使用守护进程方式调度pt-heartbeat -D test --master-server-id=1 --update --daemonize#修改主库上的更新时间间隔为2spt-heartbeat -D test --update --daemonize --interval=2#修改主库上的pt-heartbeat守护进程pt-heartbeat --stopSuccessfully created file /tmp/pt-heartbeat-sentinelrm -rf /tmp/pt-heartbeat-sentinel#单词查看从库上的延迟情况pt-heartbeat --user=tongbu --password=&apos;123456&apos; -D test -h 192.168.2.9 --check0.00#使用守护进程监控从库并输出日志pt-heartbeat --user=tongbu --password=&apos;123456&apos; -h 192.168.2.9 -D test --master-server-id=1 --monitor --print-master-server-id --daemonize --log=/var/log/pt_slave_lag.log 如下是脚本的方式，只不过使用脚本的方式实现的。如果有什么地方需要完善的，请各位看客留言提示哦 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111#!/bin/sh#description:check slave replication delayPT=`which pt-heartbeat`ADMIN=`which mysqladmin`MYSQL=`which mysql`WARN=10CRITIC=20COMMON=3MASTERID=1###############watch_update()&#123;RE=`ps -ef|grep $PT|grep -v grep|grep &quot;\--update&quot;`if [ ! -n &quot;$RE&quot; ];then $PT -D test --master-server-id=$MASTERID --update --daemonizefi&#125;################watch_mysql()&#123;SAFE_STATUS=`ps -ef|grep -w mysqld_safe|grep -v grep`MYSQLD_STATUS=`ps -ef|grep -w mysqld|grep -v grep`if [ ! -n &quot;$SAFE_STATUS&quot; ];then echo &quot;Mysqld_safe doesn&apos;t running,Please check your mysqld_safe status&quot; exit 1fiif [ ! -n &quot;$MYSQLD_STATUS&quot; ];then echo &quot;Mysqld program status --stop,Please check your mysqld status &quot; exit 1fi&#125;####################watch_mysql_slave()&#123;REP_STATUS=`$ADMIN processlist|grep &quot;Binlog Dump&quot;`if [ ! -n &quot;$REP_STATUS&quot; ];then echo &quot;slave process doesn&apos;t running,Please check your replication&quot; exit 1fi&#125;#################enter_slave_info()&#123; echo &quot;please enter your slave username:&quot; read NAME if [ -n &quot;$NAME&quot; ];then echo &quot; you enter username is: $NAME&quot; fi echo &quot;please enter your slave user password:&quot; read PASS if [ -n &quot;$PASS&quot; ];then echo &quot;you enter user password is: $PASS&quot; fi echo &quot;please enter your slave hostname or address:&quot; read ADDR if [ -n &quot;$ADDR&quot; ];then echo &quot;you enter slave hostname or address is: $ADDR&quot; fi&#125;##################watch_slave_delay()&#123;# echo &quot;please enter your watch options(1.check 2.monitor)&quot;# read OPTION# if [ $OPTION -eq 1 ];then SLAVE_DELAY=`$PT --user=$NAME --password=&quot;$PASS&quot; -h $ADDR -D test --master-server-id=$MASTERID --check --print-master-server-id`# elif [ $OPTION -eq 2 ];then# `$PT --user=$NAME --password=&quot;PASS&quot; -h $ADDR -D test --master-server-id=$MASTERID --monitor --print-master-server-id`# else# echo &quot;your enter are error,now EXIT&quot;# exit 1# fiif [ ! -n &quot;$SLAVE_DELAY&quot; ];then echo &quot;Your pt-heartbeat tool must haven&apos;t install or you username,password,slave hostname ERROR&quot; exit 1else echo &quot;DELAY TIME: $SLAVE_DELAY&quot;fi &#125;##################################watch_slave_interrupt()&#123; INT_RE=`$MYSQL -s -u $NAME -p&quot;$PASS&quot; -h $ADDR -e &apos;show slave status\G&apos;|grep &quot;Last_Error:&quot;` if [ -n &quot;$INT_RE&quot; ];then echo &quot;$INT_RE&quot; else echo &quot;INTERUUPT Info: &quot; echo &quot;$INT_RE&quot; fi&#125;########################WATCH()&#123;watch_slave_delaywatch_slave_interrupt&#125;#########################START_WATCH()&#123; watch_mysql watch_mysql_slave watch_update enter_slave_info &#125;##########################LOOP_WATCH()&#123; START_WATCHecho &quot;+++++++++++++ DELAY INFO ++++++++++++++++&quot; while true;do WATCH sleep 30 done&#125;##########################LOOP_WATCH 脚本运行结果如下：1234567891011121314151617181920212223./delay.sh please enter your slave username:tongbuyou enter username is: tongbuplease enter your slave user password:123456you enter user password is: 123456please enter your slave hostname or address:192.168.2.9you enter slave hostname or address is: 192.168.2.9+++++++++++++ DELAY INFO ++++++++++++++++DELAY TIME: 0.36 1Warning: Using a password on the command line interface can be insecure. Last_Error: DELAY TIME: 0.96 1Warning: Using a password on the command line interface can be insecure. Last_Error: DELAY TIME: 0.12 1Warning: Using a password on the command line interface can be insecure. Last_Error: DELAY TIME: 1.91 1Warning: Using a password on the command line interface can be insecure. Last_Error:]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XtraBackup不停机不锁表搭建MySQL主从同步实践]]></title>
    <url>%2F2017%2F03%2F23%2F17032302%2F</url>
    <content type="text"><![CDATA[前言Percona XtraBackup可以说是一个相对完美的免费开源数据备份工具，支持在线无锁表同步复制和可并行高效率的安全备份恢复机制相比mysqldump来说确实让人眼前一亮，与MySQL Enterprise Backup(InnoDB Hot Backup)的功能对比可以参考扩展阅读。当然我们在实际运维过程中都应针对不同的业务需求分析和选择合适的备份恢复方案，这篇文章就是针对MySQL多实例且一个实例对应多个database的情况，实现MySQL在线不停机不锁表的主从同步，日后再继续更新分享基于XtraBackup的其它实用技能。 XtraBackup是目前首选的备份方案之一 原理MySQL主从同步原理MySQL主从同步是在MySQL主从复制(Master-Slave Replication)基础上实现的，通过设置在Master MySQL上的binlog(使其处于打开状态)，Slave MySQL上通过一个I/O线程从Master MySQL上读取binlog，然后传输到Slave MySQL的中继日志中，然后Slave MySQL的SQL线程从中继日志中读取中继日志，然后应用到Slave MySQL的数据库中。这样实现了主从数据同步功能。 XtraBackup备份原理innobackupex在后台线程不断追踪InnoDB的日志文件，然后复制InnoDB的数据文件。数据文件复制完成之后，日志的复制线程也会结束。这样就得到了不在同一时间点的数据副本和开始备份以后的事务日志。完成上面的步骤之后，就可以使用InnoDB崩溃恢复代码执行事务日志（redo log），以达到数据的一致性。备份分为两个过程： backup，备份阶段，追踪事务日志和复制数据文件（物理备份）。 preparing，重放事务日志，使所有的数据处于同一个时间点，达到一致性状态。XtraBackup的优点 可以快速可靠的完成数据备份（复制数据文件和追踪事务日志） 数据备份过程中不会中断事务的处理（热备份） 节约磁盘空间和网络带宽 自动完成备份鉴定 因更快的恢复时间而提高在线时间 配置准备工作MySQL步骤和my.cnf配置参考mysql主从配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#原有主数据库版本mysql -Vmysql Ver 14.14 Distrib 5.5.31, for Linux (x86_64) using readline 5.1#迁移从数据库版本mysql -Vmysql Ver 14.14 Distrib 5.6.25, for linux-glibc2.5 (x86_64) using EditLine wrapper#检查数据库引擎show engines;+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+| MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || CSV | YES | CSV storage engine | NO | NO | NO || MyISAM | YES | MyISAM storage engine | NO | NO | NO || BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO || MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || InnoDB | DEFAULT | Supports transactions, row-level locking, and foreign keys | YES | YES | YES || ARCHIVE | YES | Archive storage engine | NO | NO | NO || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || FEDERATED | NO | Federated MySQL storage engine | NULL | NULL | NULL |+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+#主从数据库同步注意点[mysqld]#主从之间的id不能相同server-id#启用二进制日志log-bin#一般在从库开启（可选）read_only#推荐使用InnoDB并做好相关配置#检查主从数据库状态mysql -S /tmp/mysql.sock -e &quot;show global variables like &apos;server_id&apos;;&quot;+---------------+-------+| Variable_name | Value |+---------------+-------+| server_id | 1 |+---------------+-------+mysql -S /tmp/mysql.sock -e &quot;show global variables like &apos;log_bin&apos;;&quot;+---------------+-------+| Variable_name | Value |+---------------+-------+| log_bin | ON |+---------------+-------+ 安装percona-xtrabackup一般推荐rpm安装 - https://www.percona.com/downloads/XtraBackup/LATEST/123yum -y install perl perl-devel libaio libaio-devel perl-Time-HiRes perl-DBD-MySQL#rpm -ivh percona-xtrabackup-2.2.12-1.el6.x86_64.rpm rpm -Uvh percona-xtrabackup-2.2.12-1.el6.x86_64.rpm 备份和恢复通常一般都直接使用innobackupex，因为它能同时备份InnoDB和MyISAM引擎的表 重点关注Slave_IO_Running和Slave_SQL_Runningd的状态是否为YES.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#备份innobackupex --socket=/usr/local/var/mysql2/mysql2.sock --user=root --password --defaults-file=/etc/mysqld_multi.cnf --parallel=4 --database=passport /tmp/backup#保持事务一致性innobackupex --socket=/usr/local/var/mysql2/mysql2.sock --user=root --password --defaults-file=/etc/mysqld_multi.cnf --database=passport --apply-log /tmp/backup/2015-08-05_16-08-14#传输scp -r /tmp/backup/2015-08-05_16-08-14 10.10.16.24:/tmp/backup/ #恢复innobackupex --socket=/tmp/mysql.sock --user=root --password --defaults-file=/app/local/mysql/my.cnf --copy-back /tmp/backup/2015-08-05_16-08-14/#还原权限chown -R mysql:mysql /app/data/mysql/dataservice mysqld start/app/local/mysql/scripts/mysql_install_db --basedir=/app/local/mysql --datadir=/app/data/mysql/data --no-defaults --skip-name-resolve --user=mysql#主库授权同步帐号SELECT DISTINCT CONCAT(&apos;User: &apos;&apos;&apos;,user,&apos;&apos;&apos;@&apos;&apos;&apos;,host,&apos;&apos;&apos;;&apos;) AS query FROM mysql.user;GRANT REPLICATION SLAVE ON *.* TO &apos;slave_passport&apos;@&apos;10.10.16.24&apos; IDENTIFIED BY &apos;slave_passport&apos;;FLUSH PRIVILEGES;#从库开启同步cat /tmp/backup/2015-08-05_16-08-14/xtrabackup_binlog_info mysql-bin.002599 804497686CHANGE MASTER TOMASTER_HOST=&apos;10.10.16.51&apos;,MASTER_USER=&apos;slave_passport&apos;,MASTER_PASSWORD=&apos;slave_passport&apos;,MASTER_PORT=3307,MASTER_LOG_FILE=&apos;mysql-bin.002599&apos;,MASTER_LOG_POS=804497686;#开启主从同步start slave;#查看从库状态show slave status\ G#从库的检查参数Slave_IO_Running=YesSlave_SQL_Running=Yes#主库的检查参数show master status \G+------------------+-----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+------------------+-----------+--------------+------------------+| mysql-bin.002600 | 454769337 | | |+------------------+-----------+--------------+------------------+1 row in set (0.00 sec)show processlist;Master has sent all binlog to slave; waiting for binlog to be updated MySQL主从切换切换前断开主库访问连接观察进程状态，无写操作后再停止从库IO_THREAD进行切换 123456789101112131415161718192021222324252627282930313233343536373839404142#查看主库状态show processlist;Master has sent all binlog to slave; waiting for binlog to be updatedshow master status \G#从库停止 IO_THREAD 线程stop slave IO_THREAD;show processlist;Slave has read all relay log; waiting for the slave I/O thread to update itshow slave status \G#从库切换为主库stop slave;reset master;reset slave all;show master status \G#激活帐户SELECT DISTINCT CONCAT(&apos;User: &apos;&apos;&apos;,user,&apos;&apos;&apos;@&apos;&apos;&apos;,host,&apos;&apos;&apos;;&apos;) AS query FROM mysql.user;GRANT REPLICATION SLAVE ON *.* TO &apos;slave_passport&apos;@&apos;10.10.16.51&apos; IDENTIFIED BY &apos;slave_passport&apos;;FLUSH PRIVILEGES;#切换原有主库为从库reset master;reset slave all;CHANGE MASTER TOMASTER_HOST=&apos;10.10.16.24&apos;,MASTER_USER=&apos;slave_passport&apos;,MASTER_PASSWORD=&apos;slave_passport&apos;,MASTER_PORT=3306,MASTER_LOG_FILE=&apos;mysql-bin.000001&apos;,MASTER_LOG_POS=804497686;#检查主库SHOW PROCESSLIST;show master status \G#启动从库SHOW PROCESSLIST;start slave;show slave status \G 常见问题1Slave_SQL_Running:No 一般是事务回滚造成的 123stop slave;set GLOBAL SQL_SLAVE_SKIP_COUNTER=1;start slave;]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql主从配置]]></title>
    <url>%2F2017%2F03%2F23%2F17032301%2F</url>
    <content type="text"><![CDATA[MySQL Replication 又叫做AB复制或者主从复制。它主要用于MySQL的时时备份或者读写分离。在配置之前先做一下准备工作，配置两台mysql服务器，或者在一台服务器上配置两个端口也可以。这里的的实验中就是在一台服务器上跑了两个mysql。 原理：MySQL的Replication是一个异步的复制过程，从一个MySQL实例(Master)复制到另一台MySQL实例上。在Master和Slave之间复制的整个过程主要由3个线程完成，其中两个线程（SQL线程和IO线程）在Slave端，另外一个线程(IO线程)在Master端。 要实现主从复制，首先要在Master端打开Binary Log功能。因为整个复制过程实际上就是Slave从Master上获取二进制日志，然后在自己身上完全按照产生的顺序一次执行日志中记录的各种操作的过程。 复制的具体过程如下： Slave的IO线程连上Master，并请求日志文件指定位置(或从开始的日志)之后的日志的内容。 Master接收到来自Slave的IO线程请求后，负责复制IO线程根据请求的信息读取指定日志之后的日志信息，返回给Slave端的IO线程。返回信息中除了日志所包含的信息，还包含了包括本次返回的信息在Master端的Binary Log文件的名称和位置。 Slave的IO线程接受到信息后，将日志内容一次写入Slave端的Relay Log文件(mysql-relay-bin.xxxx)的末端，并将读取到的Master端的bin-log的文件和位置记录到master-info文件中，以便在下一次读取时能够清楚地告诉Master，下次从bin-log哪个位置开始往后的日志内容。 Log中更新内容后，会马上解析该Log文件中的内容，还原成在Master端真实执行时的可执行的SQL语句，并执行这些SQK语句。实际上Master和Slave执行同样的语句。 1. 配置mysql服务MySql的安装和配置请看 Mysql 安装按照上面的步骤，你可以成功搭建好一个mysql，跑的是3306端口，下面我们搭建第二个mysql，指定的端口为：3307：1234cd /usr/local/cp -r mysql mysql_slavecd mysql_2./scripts/mysql_install_db --user=mysql --datadir=/data/mysql_slave 最后一步是初始化数据库目录，如果出现两个“OK”并且生成/data/mysql2目录才正确，否则请仔细查看错误信息.拷贝配置文件到mysql_2下，并修改相关项目:12cp /etc/my.cnf ./my.cnfvim my.cnf 把12port = 3306socket = /tmp/mysql.sock 改为： 并增加一行123port = 3307socket = /tmp/mysql_slave.sockdatadir = /data/mysql_slave 拷贝编辑启动脚本：12cp /etc/init.d/mysqld /etc/init.d/mysqldslavevim /etc/init.d/mysqldslave 需要修改的部分，修改后为： 123basedir=/usr/local/mysql_slavedatadir=/data/mysql_slaveconf=$basedir/my.cnf 之后启动即可。 至此，在一台机器上已经启动了两个mysql： 12345netstat -lnp |grep mysqldtcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN 7217/mysqld tcp 0 0 0.0.0.0:3307 0.0.0.0:* LISTEN 7469/mysqld unix 2 [ ACC ] STREAM LISTENING 42591 7217/mysqld /tmp/mysql.sockunix 2 [ ACC ] STREAM LISTENING 48423 7469/mysqld /tmp/mysql_slave.sock 2. 配置主从准备工作这里我们打算把3306端口的mysql作为主(master)，而把3307的mysql作为从(slave). 为了让实验更加像生产环境，所以在master上创建一个库db1，并且把mysql的库数据复制给它:1234567mysql -uroot -S /tmp/mysql.sockmysql&gt; create database db1;Query OK, 1 row affected (0.06 sec)mysql&gt; quitBye -S 后面指定mysql的socket文件路径，这也是登陆mysql的一种方法，因为在一台服务器上跑了两个mysql端口，所以，只能用 -S 这样的方法来区分。首先创建了db1库，然后把mysql库的数据复制给它:123456789101112131415161718192021222324252627282930313233343536mysqldump -uroot -S /tmp/mysql.sock mysql &gt; 123.sqlmysql -uroot -S /tmp/mysql.sock db1 &lt; 123.sql//进入mysql后可以看到：mysql&gt; use db1;Database changedmysql&gt; show tables;+---------------------------+| Tables_in_db1 |+---------------------------+| columns_priv || db || event || func || general_log || help_category || help_keyword || help_relation || help_topic || host || ndb_binlog_index || plugin || proc || procs_priv || servers || slow_log || tables_priv || time_zone || time_zone_leap_second || time_zone_name || time_zone_transition || time_zone_transition_type || user |+---------------------------+23 rows in set (0.00 sec) 3. 配置主（master）1vim /etc/my.cnf 在[mysqld]部分查看是否有以下内容，如果没有则添加:12server-id=1log-bin=keso 除了这两行是必须的外，还有两个参数，你可以选择性（2选1）的使用:12binlog-do-db=databasename1,databasename2 #用来指定需要同步的库binlog-ignore-db=databasename1,databasename2 #用来指定忽略不同步的库 完成后重启mysqld服务。然后进入主mysql并授权给从一个用来同步数据的用户 repl 12345678910111213141516mysql&gt; grant replication slave on *.* to &apos;repl&apos;@&apos;127.0.0.1&apos; identified by &apos;111111&apos;;Query OK, 0 rows affected (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) #刷新MySQL的系统权限相关表mysql&gt; flush tables with read lock;Query OK, 0 rows affected (0.00 sec) #锁定数据库，此时不允许更改任何数据 show master status; #查看状态，这些数据是要记录的，一会要在slave端用到+-------------+----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+-------------+----------+--------------+------------------+| keso.000001 | 331 | | |+-------------+----------+--------------+------------------+1 row in set (0.00 sec) 4. 配置从（slave）先修改slave的配置文件my.cnf:1vim /usr/local/mysql_slave/my.cnf 修改1server-id = 2 #可以是出1意外的其他任何数字 总之不能让这个id和master一样，否则会报错。另外在从上，你也可以选择性的增加如下两行，意义同主的那两个可选参数，如果在主上已经定义过了，那么在从上就不用再定义了。12replicate-do-db=databasename1,databasename2replicate-ignore-db=databasename1,databasename2 改完后，重启slave:1/etc/init.d/mysqldslave restart 拷贝master上的db1库的数据到slave上，因为master和slave都在一台服务器上，所以操作起来简单了很多，如果是不同的机器，可能就需要远程拷贝了，希望你注意这一点:12mysql -S /tmp/mysql_slave.sock -e &quot;create database db1&quot;mysql -S /tmp/mysql_slave.sock db1&lt;123.sql 登录从，并执行如下命令：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152mysql -S /tmp/mysql_slave.sock mysql&gt; slave stop ;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; change master to master_host=&apos;127.0.0.1&apos;, master_port=3306,master_user=&apos;repl&apos;, master_password=&apos;111111&apos;,master_log_file=&apos;keso.000001&apos;, master_log_pos=331; Query OK, 0 rows affected (0.00 sec)mysql&gt; slave start;Query OK, 0 rows affected (0.03 sec)mysql&gt; show slave status\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 127.0.0.1 Master_User: repl Master_Port: 3306 Connect_Retry: 60 Master_Log_File: keso.000001 Read_Master_Log_Pos: 331 Relay_Log_File: KesoLinux-relay-bin.000002 Relay_Log_Pos: 246 Relay_Master_Log_File: keso.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 331 Relay_Log_Space: 405 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: 1 row in set (0.00 sec) 确认Slave_IO_Running和Slave_SQL_Running 同时为yes时，才算正常。 5. 测试主从在master上执行如下命令:12345678910select count(*) from db; +----------+| count(*) |+----------+| 2 |+----------+1 row in set (0.00 sec)mysql&gt; truncate table db;Query OK, 0 rows affected (0.00 sec) 这样清空了db1.db表的数据，下面查看slave上的该表数据:123456elect count(*) from db；+----------+| count(*) |+----------+| 0 |+----------+ slave上的该表也被清空了。这样好像不太明显，不妨继续把db表删除试试:1drop table db； 在slave上可以再使用select是可以看到：12select count(*) from db&quot;ERROR 1146 (42S02) at line 1: Table &apos;db1.db&apos; doesn&apos;t exist 主从配置起来很简单，但是这种机制也是非常脆弱的，一旦我们不小心在从上写了数据，那么主从也就被破坏了。另外如果重启master，务必要先把slave停掉，也就是说需要在slave上去执行 slave stop 命令，然后再去重启master的mysql服务，否则很有可能就会中断了。当然重启完后，还需要把slave给开启 slave start.]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[resin 安装与配置]]></title>
    <url>%2F2017%2F03%2F22%2F17032202%2F</url>
    <content type="text"><![CDATA[resin 同样也需要jdk的支持，所以第一步也是安装jdk，安装jdk的方法这里不在复述。下面安装resin。 resin的官网是http://caucho.com/,他分两个版本，resin是开源的，另外一个resinpro为商业版本。我们要用开源版本resin。下载、编译、安装： 123456cd /usr/local/src/wget http://caucho.com/download/resin-4.0.45.tar.gztar zxvf resin-4.0.36.tar.gzcd resin-4.0.36./configure --prefix=/usr/local/resin --with-java-home=/usr/local/jdk1.8.0_101/make &amp;&amp; make install 完成之后启动:1/etc/init.d/resin start 下面简单配置resin 1vim /usr/local/resin/conf/resin.xml 它的配置文件和tomcat是很像的，基本结构为: 123&lt;cluster id=&quot;app&quot;&gt;&lt;host&gt; &lt;/host&gt;&lt;/cluster&gt; 其中虚拟主机配置就在 里： 123&lt;host id=&quot;www.abc.com&quot; root-directory=&quot;.&quot;&gt;&lt;web-app id=&quot;/&quot; root-directory=&quot;/tmp/resin&quot;/&gt;&lt;/host&gt; 这里不是在后增加了一段，而是直接在 里面配置。 编辑一个测试文件：1234vim /tmp/resin/1.jsp&lt;html&gt;&lt;body&gt;&lt;center&gt; Now time is: &lt;%=new java.util.Date()%&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 测试：1curl -x127.0.0.1:8080 www.abc.com/1.jsp 若正确，结果应为： 123&lt;html&gt;&lt;body&gt;&lt;center&gt; Now time is: Wed Mar 22 20:34:47 CST 2017&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat的安装、配置和优化]]></title>
    <url>%2F2017%2F03%2F22%2F17032201%2F</url>
    <content type="text"><![CDATA[前有很多网站使用jsp的程序编写，所以解析jsp的程序就必须要有相关的软件来完成。Tomcat就是用来解析jsp程序的一个软件，Tomcat是Apache 软件基金会（Apache Software Foundation）的Jakarta项目中的一个核心项目，由Apache、Sun和其他一些公司及个人共同开发而成。因为Tomcat技术先进、性能稳定，而且免费，因而深受Java爱好者的喜爱并得到了部分软件开发商的认可，成为目前比较流行的Web 应用服务器。 Tomcat是一个轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP程序的首选。对于一个初学者来说，可以这样认为，当在一台机器上配置好Apache服务器，可利用它响应对HTML 页面的访问请求。实际上Tomcat 部分是Apache服务器的扩展，但它是独立运行的，所以当你运行tomcat时，它实际上作为一个与Apache 独立的进程单独运行的。 安装 TomcatTomcat的安装分为两个步骤：安装JDK和安装Tomcat. JDK(Java Development Kit)是Sun Microsystems针对Java开发员的产品。自从Java推出以来，JDK已经成为使用最广泛的Java SDK. JDK是整个Java的核心，包括了Java运行环境，Java工具和Java基础的类库。所以要想运行jsp的程序必须要有JDK的支持，理所当然安装Tomcat的前提是安装好JDK. 安装JDK下载：jdk-8u101-linux-i586.tar.gzJKD的官网地址为：http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html12cd /usr/local/src/wget http://download.oracle.com/otn-pub/java/jdk/8u121-b13/e9e7ea248e2c4826b92b3f075a80e441/jdk-8u121-linux-i586.tar.gz?AuthParam=1490175465_284e6dd63d69056520fe5f762e5643e7 解压： 123tar zxvf jdk-8u101-linux-i586.tar.gz mv jdk1.8.0_101/ /usr/local/vim /etc/profile.d/java.sh 加入如下配置：123456JAVA_HOME=/usr/local/jdk1.8.0_101/JAVA_BIN=/usr/local/jdk1.8.0_101/binJRE_HOME=/usr/local/jdk1.8.0_101/jrePATH=$PATH:/usr/local/jdk1.8.0_101/bin:/usr/local/jdk1.8.0_101/jre/binCLASSPATH=/usr/local/jdk1.8.0_101/jre/lib:/usr/local/jdk1.8.0_101/lib:/usr/local/jdk1.8.0_101/jre/lib/charsets.jarexport JAVA_HOME JAVA_BIN JRE_HOME PATH CLASSPATH 保存文件后，使其生效:1source /etc/profile.d/java.sh 如果以上配置成功，则下面命令可以看到java的版本：1234java -versionjava version &quot;1.8.0_101&quot;Java(TM) SE Runtime Environment (build 1.8.0_101-b13)Java HotSpot(TM) Client VM (build 25.101-b13, mixed mode) 安装Tomcat下载：123456cd /usr/local/src/wget http://mirror.bit.edu.cn/apache/tomcat/tomcat-7/v7.0.76/bin/apache-tomcat-7.0.76.tar.gztar zxvf apache-tomcat-7.0.76.tar.gzmv apache-tomcat-7.0.76 /usr/local/tomcatcp -pv /usr/local/tomcat/bin/catalina.sh /etc/init.d/tomcatvim /etc/init.d/tomcat 在第二行加入以下内容:1234567# chkconfig: 112 63 37# description: tomcat server init script# Source Function Library. /etc/init.d/functionsJAVA_HOME=/usr/local/jdk1.8.0_101/CATALINA_HOME=/usr/local/tomcat 保存文件后，执行以下操作:123chmod 755 /etc/init.d/tomcatchkconfig --add tomcatchkconfig tomcat on 启动tomcat:1service tomcat start 查看是否启动成功:1ps aux |grep tomcat 如果有进程的话，请在浏览器中输入http://IP:8080/ 你会看到tomcat的主界面。 配置Tomcati. 配置Tomcat 服务的访问端口tomcat默认启动的是8080，如果你想修改为80，则需要修改server.xml文件: 1vim /usr/local/tomcat/conf/server.xml 把1&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; 改为：1&lt;Connector port=&quot;80&quot; protocol=&quot;HTTP/1.1&quot; ii. 配置新的虚拟主机1vim /usr/local/tomcat/conf/server.xml 找到下一行插入新的内容如下:12345&lt;Host name=&quot;www.123.cn&quot; appBase=&quot;/data/tomcatweb&quot; unpackWARs=&quot;false&quot; autoDeploy=&quot;true&quot; xmlValidation=&quot;false&quot; xmlNamespaceAware=&quot;false&quot;&gt; &lt;Context path=&quot;&quot; docBase=&quot;./&quot; debug=&quot;0&quot; reloadable=&quot;true&quot; crossContext=&quot;true&quot;/&gt;&lt;/Host&gt; 保存后，重启tomcat:12service tomcat stopservice tomcat start 测试Tomcat先创建tomcat的测试文件:1vim /data/tomcatweb/test.jsp 加入如下内容:123&lt;html&gt;&lt;body&gt;&lt;center&gt; Now time is: &lt;%=new java.util.Date()%&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 保存后，使用curl测试:1curl -xlocalhost:80 www.123.cn/test.jsp 看看运行结果是否是:123&lt;html&gt;&lt;body&gt;&lt;center&gt; Now time is: Thu Jun 13 15:26:03 CST 2013&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 如果是这样的结果，说明tomcat搭建成功。另外，你也可以在你的真机上，绑定hosts, 用IE来测试它。]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[squid 服务介绍]]></title>
    <url>%2F2017%2F03%2F21%2F17032103%2F</url>
    <content type="text"><![CDATA[Squid是什么Squid是比较知名的代理软件，它不仅可以跑在linux上还可以跑在windows以及Unix上，它的技术已经非常成熟。目前使用Squid的用户也是十分广泛的。Squid与Linux下其它的代理软件如Apache、Socks、TIS FWTK和delegate相比，下载安装简单，配置简单灵活，支持缓存和多种协议。 Squid之所以用的很多，是因为它的缓存功能，Squid缓存不仅可以节省宝贵的带宽资源，也可以大大降低服务器的I/O. 从经济角度考虑，它是很多网站架构中不可或缺的角色。 Squid不仅可以做正向代理，又可以做反向代理。当作为正向代理时，Squid后面是客户端，客户端想上网不管什么网都得经过Squid. 当一个用户(客户端)想要请求一个主页时，它向Squid发出一个申请，要Squid替它请求，然后Squid 连接用户要请求的网站并请求该主页，接着把该主页传给用户同时保留一个备份，当别的用户请求同样的页面时，Squid把保存的备份立即传给用户，使用户觉得速度相当快。使用正向代理时，客户端需要做一些设置，才能实现，也就是平时我们在IE选项中设置的那个代理。而反向代理是，Squid后面为某个站点的服务器，客户端请求该站点时，会先把请求发送到Squid上，然后Squid去处理用户的请求动作。阿铭教你一个特别容易的区分：正向代理，Squid后面是客户端，客户端上网要通过Squid去上；反向代理，Squid后面是服务器，服务器返回给用户数据需要走Squid.正向代理用在企业的办公环境中，员工上网需要通过Squid代理来上网，这样可以节省网络带宽资源。而反向代理用来搭建网站静态项(图片、html、流媒体、js、css等)的缓存服务器，它用于网站架构中。 正向代理： 反向代理： 搭建Squid正向代理CentOS系统自带Squid包，但是需要安装一下: 1yum install -y squid 当然你也可以源码包编译安装，Squid官方网站为 http://www.squid-cache.org/ 当前最新版本为3.3, 下载3.1版本即可，因为CentOS6上提供的版本也为3.1版本。如果你想编译安装Squid, 参考编译参数为:12345678910111213141516171819202122232425262728./configure --prefix=/usr/local/squid \--disable-dependency-tracking \--enable-dlmalloc \--enable-gnuregex \--disable-carp \--enable-async-io=240 \--with-pthreads \--enable-storeio=ufs,aufs,diskd,null \--disable-wccp \--disable-wccpv2 \--enable-kill-parent-hack \--enable-cachemgr-hostname=localhost \--enable-default-err-language=Simplify_Chinese \--with-build-environment=POSIX_V6_ILP32_OFFBIG \--with-maxfd=65535 \--with-aio \--disable-poll \--enable-epoll \--enable-linux-netfilter \--enable-large-cache-files \--disable-ident-lookups \--enable-default-hostsfile=/etc/hosts \--with-dl \--with-large-files \--enable-removal-policies=heap,lru \--enable-delay-pools \--enable-snmp \--disable-internal-dns 这些参数不见得符合你的需求只是提供一个参考，entOS中自带的squid已经满足需求，所以没有编译安装。安装完后，可以查看squid版本:12squid -vSquid Cache: Version 3.1.10 同时还可以看到squid的编译参数。配置一下squid, 来实现正向代理:12rm -f /etc/squid/squid.confvim /etc/squid/squid.conf 我们不使用默认配置文件，删除，重新写入如下配置:1234567891011121314151617181920212223242526272829http_port 3128acl manager proto cache_objectacl localhost src 127.0.0.1/32 ::1acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1acl localnet src 10.0.0.0/8 # RFC1918 possible internal networkacl localnet src 172.16.0.0/12 # RFC1918 possible internal networkacl localnet src 192.168.0.0/16 # RFC1918 possible internal networkacl SSL_ports port 443acl Safe_ports port 80 8080 # httpacl Safe_ports port 21 # ftpacl Safe_ports port 443 # httpsacl CONNECT method CONNECThttp_access allow manager localhosthttp_access deny managerhttp_access deny !Safe_portshttp_access deny CONNECT !SSL_portshttp_access allow localnethttp_access allow localhosthttp_access allow allcache_dir aufs /data/cache 1024 16 256cache_mem 128 MBhierarchy_stoplist cgi-bin ?coredump_dir /var/spool/squidrefresh_pattern ^ftp: 1440 20% 10080refresh_pattern ^gopher: 1440 0% 1440refresh_pattern -i (/cgi-bin/|\?) 0 0% 0refresh_pattern \.(jpg|png|gif|mp3|xml) 1440 50% 2880 ignore-reloadrefresh_pattern . 0 20% 4320visable_hostname kesolinux.com 第一行的 “http_port 3128”这个指的是，squid服务启动后将要监听的端口，也可以是80. “cache_dir” 这个用来指定本地磁盘上的缓存目录，后边的1024为大小，单位是M，具体根据你的磁盘大小决定。“cache_mem”它用来规定缓存占用内存的大小，即把缓存的东西存到内存里，具体也需要根据你机器的内存定，如果你的机器只是跑Squid服务，那么留给系统512M内存外，其他可以都分给squid,但做实验的虚拟机一共才300M内存，所以只分了128M. 配置文件保存好后，可以先检测一下是否有语法错误:1squid -kcheck 如果提示信息为:1squid: ERROR: No running copy 这是说squid还未启动，没有关系，显示成这样说明配置文件没有问题了。在启动前还得再做一件事，就是初始化缓存目录:12345mkdir /data/cachechown -R squid:squid /data/cache/squid -zCreating Swap Directories/data/cache exists 好了，初始化完成后，就可以启动squid了:12/etc/init.d/squid start正在启动 squid：. [确定] 使用curl命令测试： 1234567891011121314151617181920212223242526272829curl -xlocalhost:3128 http://www.aminglinux.com/bbs/static/image/common/logo.png -IHTTP/1.0 200 OKServer: nginx/1.0.0Date: Sat, 08 Jun 2013 04:30:17 GMTContent-Type: image/pngContent-Length: 7785Last-Modified: Wed, 13 Jan 2010 03:33:47 GMTAccept-Ranges: bytesX-Cache: HIT from dx_cache216.5d6d.comX-Cache: MISS from localhost.localdomainX-Cache-Lookup: MISS from localhost.localdomain:3128Via: 1.0 dx_cache216.5d6d.com:80 (squid), 1.0 localhost.localdomain (squid/3.1.10)Connection: keep-alivecurl -xlocalhost:3128 http://www.aminglinux.com/bbs/static/image/common/logo.png -IHTTP/1.0 200 OKServer: nginx/1.0.0Content-Type: image/pngContent-Length: 7785Last-Modified: Wed, 13 Jan 2010 03:33:47 GMTAccept-Ranges: bytesDate: Sat, 08 Jun 2013 04:30:17 GMTX-Cache: HIT from dx_cache216.5d6d.comAge: 360898Warning: 113 localhost.localdomain (squid/3.1.10) This cache hit is still fresh and more than 1 day oldX-Cache: HIT from localhost.localdomainX-Cache-Lookup: HIT from localhost.localdomain:3128Via: 1.0 dx_cache216.5d6d.com:80 (squid), 1.0 localhost.localdomain (squid/3.1.10)Connection: keep-alive 连续访问了两次阿铭论坛的logo图片，可以发现前后两次的不同，其中 “X-Cache-Lookup: HIT from localhost.localdomain:3128” 显示，该请求已经HIT, 它直接从本地的3128端口获取了数据。 有时，我们会有这样的需求，就是想限制某些域名不能通过代理访问，或者说只想代理某几个域名，这如何做呢？在squid.conf中找到:1acl CONNECT method CONNECT 在其下面添加四行:1234cl http proto HTTPacl good_domain dstdomain .baidu.com .qq.comhttp_access allow http good_domainhttp_access deny http !good_domain 其中我的白名单域名为 ”.baidu.com .qq.com” ，这里的 . 表示万能匹配，前面可以是任何字符，你只需要填写你的白名单域名即可。重启squid再来测测看: 123456789101112131415/etc/init.d/squid restartcurl -xlocalhost:80 http://www.jd.com/ -IHTTP/1.0 403 ForbiddenServer: squid/3.1.23Mime-Version: 1.0Date: Tue, 21 Mar 2017 15:10:00 GMTContent-Type: text/htmlContent-Length: 3261X-Squid-Error: ERR_ACCESS_DENIED 0Vary: Accept-LanguageContent-Language: enX-Cache: MISS from kesolinux.comX-Cache-Lookup: NONE from kesolinux.com:3128Via: 1.0 kesolinux.com (squid/3.1.23)Connection: keep-alive 访问JD已经变为403了。如果要设置黑名单呢？道理是一样的: 1234acl http proto HTTPacl bad_domain dstdomain .sina.com .sohu.comhttp_access allow http !bad_domainhttp_access deny http bad_domain 重启squid后，测试发现JD可以访问，但是sina和sohu不能访问了。 搭建Squid反向代理过程其实和前面的正向代理没有什么太大区别，唯一的区别是配置文件中一个地方需要改动一下。需要把:1http_port 3128 改为：1http_port 80 accel vhost vport 并增加你要代理的后端真实服务器信息:1234ache_peer 123.125.119.147 parent 80 0 originserver name=acache_peer 61.135.169.125 parent 80 0 originserver name=bcache_peer_domain a www.qq.comcache_peer_domain b www.baidu.com 其中cache_peer为配置后端的服务器ip以及端口，name后边为要配置的域名，这里和后面的cache_peer_domain相对应。实际的应用中，ip大多为内外ip，而域名也许会有多个，如果是squid要代理一台web上的所有域名，那么就写成这样:1cache_peer 192.168.10.111 80 0 originserver 后面连cache_peer_domain 也省了。 反向代理主要用于缓存静态项，因为诸多静态项目尤其是图片、流媒体等比较耗费带宽，在中国，联通网访问电信的资源本例就慢，如果再去访问大流量的图片、流媒体那更会慢了，所以如果在联通网配置一个squid反向代理，让联通客户端直接访问这个联通squid，而这些静态项已经被缓存在了squid上，这样就大大加快了访问速度。也许你听说过CDN, 其实它的设计原理就是这样的思路。好了，我们再测一测反向代理吧。 因为修改了配置文件，所以需要重启一下squid:1234/etc/init.d/squid restartcurl -xlocalhost:80 http://www.baidu.com/curl -xlocalhost:80 http://www.qq.com/curl -xlocalhost:80 http://www.sina.com/ 你会发现，baidu.com和qq.com都能正常访问，然而sina.com访问503了，这是因为我们并没设置sina.com还有一个知识点，1234567891011121314151617181920212223squid -hUsage: squid [-cdhvzCFNRVYX] [-s | -l facility] [-f config-file] [-[au] port] [-k signal] -a port Specify HTTP port number (default: 3128). -d level Write debugging to stderr also. -f file Use given config-file instead of /etc/squid/squid.conf -h Print help message. -k reconfigure|rotate|shutdown|interrupt|kill|debug|check|parse Parse configuration file, then send signal to running copy (except -k parse) and exit. -s | -l facility Enable logging to syslog. -u port Specify ICP port number (default: 3130), disable with 0. -v Print version. -z Create swap directories -C Do not catch fatal signals. -D OBSOLETE. Scheduled for removal. -F Don&apos;t serve any requests until store is rebuilt. -N No daemon mode. -R Do not set REUSEADDR on port. -S Double-check swap during rebuild. -X Force full debugging. -Y Only return UDP_HIT or UDP_MISS_NOFETCH during fast reload. 上面把squid命令所用到的选项全部打印出来了，最常用的除了 squid -k check 外，还有一个那就是 squid -k reconfigure 它们俩都可以简写:12squid -kchesquid -krec 其中第二条命令表示重新加载配置文件，如果我们更改了配置文件后，不需要重启squid服务，直接使用该命令重新加载配置即可。]]></content>
  </entry>
  <entry>
    <title><![CDATA[samba 部署和优化]]></title>
    <url>%2F2017%2F03%2F21%2F17032102%2F</url>
    <content type="text"><![CDATA[以前我们在windows上共享文件的话，只需右击要共享的文件夹然后选择共享相关的选项设置即可。然而如何实现windows和linux的文件共享呢？这就涉及到了samba服务了，这个软件配置起来也不难，使用也非常简单。 samba配置文件smb.conf安装系统的时候大多会默认安装samba，如果没有安装，在CentOS上只需要运行这个命令安装即可: 1yum install -y samba samba-client Samba的配置文件为/etc/samba/smb.conf，通过修改这个配置文件来完成我们的各种需求。打开这个配置文件，你会发现很多内容都用#或者;注视掉了。先看一下未被注释掉的部分: 123456789101112131415161718[global] workgroup = MYGROUP server string = Samba Server Version %v security = user passdb backend = tdbsam load printers = yes cups options = raw[homes] comment = Home Directories browseable = no writable = yes[printers] comment = All Printers path = /var/spool/samba browseable = no guest ok = no writable = no printable = yes 主要有以上三个部分：[global], [homes], [printers] [homes] 该部分内容共享用户自己的家目录，也就是说，当用户登录到samba服务器上时实际上是进入到了该用户的家目录，用户登陆后，共享名不是homes而是用户自己的标识符，对于单纯的文件共享的环境来说，这部分可以注视掉。[printers] 该部分内容设置打印机共享。[global] 定义全局的配置，workgroup用来定义工作组，相信如果你安装过windows的系统，你会对这个workgroup不陌生。一般情况下，需要我们把这里的MYGROUP改成WORKGROUP（windows默认的工作组名字）。 security = user #这里指定samba的安全等级。关于安全等级有四种： share：用户不需要账户及密码即可登录samba服务器 user：由提供服务的samba服务器负责检查账户及密码（默认） server：检查账户及密码的工作由另一台windows或samba服务器负责 domain：指定windows域控制服务器来验证用户的账户及密码。 passdb backend = tdbsam # passdb backend（用户后台），samba有三种用户后台：smbpasswd, tdbsam和ldapsam. smbpasswd：该方式是使用smb工具smbpasswd给系统用户（真实用户或者虚拟用户）设置一个Samba密码，客户端就用此密码访问Samba资源。smbpasswd在/etc/samba中，有时需要手工创建该文件。 tdbsam：使用数据库文件创建用户数据库。数据库文件叫passdb.tdb，在/etc/samba中。passdb.tdb用户数据库可使用 smbpasswd -a创建Samba用户，要创建的Samba用户必须先是系统用户。也可使用pdbedit创建Samba账户。pdbedit参数很多，列出几个主要的： pdbedit -a username：新建Samba账户。 pdbedit -x username：删除Samba账户。 pdbedit -L：列出Samba用户列表，读取passdb.tdb数据库文件。 pdbedit -Lv：列出Samba用户列表详细信息。 pdbedit -c “[D]” -u username：暂停该Samba用户账号。 pdbedit -c “[]” -u username：恢复该Samba用户账号。 ldapsam：基于LDAP账户管理方式验证用户。首先要建立LDAP服务，设置 “passdb backend = ldapsam:ldap://LDAP Server” load printers 和 cups options 两个参数用来设置打印机相关。 netbios name = MYSERVER # 设置出现在网上邻居中的主机名 hosts allow = 127. 192.168.12. 192.168.13. # 用来设置允许的主机，如果在前面加 ”;” 则表示允许所有主机 log file = /var/log/samba/%m.log #定义samba的日志，这里的%m是上面的netbios name max log size = 50 # 指定日志的最大容量，单位是K Samba实践i. 共享一个目录，任何人都可以访问，即不用输入密码即可访问，要求只读. 打开samba的配置文件/etc/samba/smb.conf 在[global]部分把: MYGROUP改成:WORKGROUP security = user改成:security = share然后在配置文件最后加入： 123456[keso] comment = share all path = /tmp/samba browseable = yes public = yes writable = no 创建测试目录、文件 1234mkdir /tmp/sambachmod 777 /tmp/sambatouch /tmp/samba/sharefilesecho &quot;111111&quot; &gt; /tmp/samba/sharefiles 启动samba服务: 1/etc/init.d/smb start 测试：首先测试你配置的smb.conf是否正确，用下面的命令: 1testparm 你应该会看到一个警告:WARNING: The security=share option is deprecated, 不过影响不大，无需管它。如果没有错误，则在你的windows机器上的浏览器中输入:file://IP/share 看是否能访问到sharefilesii. 共享一个目录，使用用户名和密码登录后才可以访问，要求可以读写.打开samba的配置文件/etc/samba/smb.conf[global] 部分内容如下: 1234567[global] workgroup = WORKGROUP server string = Samba Server Version %v security = user passdb backend = tdbsam load printers = yes cups options = raw 还需要加入以下内容:123456[myshare] comment = share for users path = /samba browseable = yes writable = yes public = no 保存配置文件，创建目录:12mkdir /sambachmod 777 /samba 然后添加用户。因为在[globa]中 “passdb backend = tdbsam”, 所以要使用 pdbedit 来增加用户，注意添加的用户必须在系统中存在，所以需要先创建系统账号: 12useradd user1useradd user2 然后添加user1为samba账号: 1pdbedit -a user1 重启samba服务:1service smb restart 测试,打开IE浏览器输入:file://IP/myshare/,然后输入用户名和密码 使用linux访问samba服务器 Samba服务在linux下同样可以访问。前提是你的linux安装了samba-client软件包。安装完后就可以使用smbclient命令了。具体语法为: 1smbclient //IP/共享名 -U 用户名 出现如上所示的界面。可以打一个 ”?” 列出所有可以使用的命令。常用的有cd, ls, rm, pwd, tar, mkdir, chown, get, put等等，使用 help + 命令可以打印该命令如何使用，其中get是下载，put是上传。另外的方式就是通过mount挂载了，如:1mount -t cifs //10.0.4.67/myshare /mnt -o username=user1,password=123456 格式就是这样，要指定 -t cifs //IP/共享名 本地挂载点 -o后面跟username 和 password 挂载完后就可以像使用本地的目录一样使用共享的目录了，注意共享名后面不能有斜杠。]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vftp 部署和优化]]></title>
    <url>%2F2017%2F03%2F21%2F17032101%2F</url>
    <content type="text"><![CDATA[作为系统默认自带的ftp服务软件，vsftpd使用也是挺多的，下面介绍一下vsftpd。 安装vsftpd 1yum install -y vsftpd db4-utils 这里安装两个软件包，同时会把依赖的包安装上。其中db4-utils 用来生成密码库文件。 建立账号vsftpd默认是可以支持使用系统账号体系登录的，但那样不太安全，我们可以参考下面的方法使用虚拟账号体系。 i. 建立虚拟账号相关联的系统账号 1useradd virftp -s /sbin/nologin ii. ###### 建立虚拟账户的相关文件 12345vim /etc/vsftpd/vsftpd_login //内容如下test1111222aaatest2aaa111ddd iii. ######更改该文件的权限，提升安全级别 1chmod 600 /etc/vsftpd/vsftpd_login iv. ######vsftpd 使用的密码文件肯定不是明文的，需要生成对应的库文件 1db_load -T -t hash -f /etc/vsftpd/vsftpd_login /etc/vsftpd/vsftpd_login.db v. ######建立虚拟账号相关的目录以及配置文件12mkdir /etc/vsftpd/vsftpd_user_confcd /etc/vsftpd/vsftpd_user_conf 3. 创建和用户对应的配置文件123456789101112vim test1 //内容如下：local_root=/home/virftp/test1anonymous_enable=NOwrite_enable=NOlocal_umask=022anon_upload_enable=NOanon_mkdir_write_enable=NOidle_session_timeout=600data_connection_timeout=120max_clients=10max_per_ip=5local_max_rate=50000 说明：local_root 表示该账号的家目录；anonymous_enable 用来限制是否允许匿名账号登录；write_enable 表示是否可写；local_umask 指定umask值；non_upload_enable 是否允许匿名账号上传文件；non_mkdir_write_enable 是否允许匿名账号可写；idle_session_timeout=600 空闲会话超时；data_connection_timeout=120 数据链接超时;max_clients=10 最大链接数local_max_rate=50000 传输速度以上是关键配置参数，其他暂时不用关心。创建test2账号的步骤和test1一样。 12345mkdir /home/virftp/test1chown -R virftp:virftp /homevirftpvim /etc/pam.d/vsftpd //在最开头添加两行：auth sufficient /lib/security/pam_userdb.so db=/etc/vsftpd/vsftpd_loginaccount sufficient /lib/security/pam_userdb.so db=/etc/vsftpd/vsftpd_login 说明：32位系统的库文件路径为：/lib/security/pam_uesrdb.so ；64位系统为：/lib64/security/pam_uesrdb.so 3. 修改全局配置文件/etc/vsftpd.conf1vim /etc/vsftpd/vsftpd.conf 修改内容为： 123456anonymous_enable=NOlocal_enable=YESwrite_enable=YESanon_upload_enable=NOanon_mkdir_write_enable=NOchroot_local_user=YES 添加内容为： 1234guest_enable=YESguest_username=virftpvirtual_use_local_privs=YESuser_config_dir=/etc/vsftpd/vsftpd_user_conf 至此可以启动vsftp服务了 1/etc/init.d/vsftpd start 在21端口没有被占用的前提下，可以成功启动。如果用户登录不了，请查看一下/var/log/secure 日志。]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pureftp 部署和优化]]></title>
    <url>%2F2017%2F03%2F20%2F17032002%2F</url>
    <content type="text"><![CDATA[FTP是File Transfer Protocol（文件传输协议）的英文简称，而中文简称为 “文传协议” 用于Internet上的控制文件的双向传输。同时，它也是一个应用程序（Application）。用户可以通过它把自己的PC机与世界各地所有运行FTP协议的服务器相连，访问服务器上的大量程序和信息。FTP的主要作用，就是让用户连接上一个远程计算机（这些计算机上运行着FTP服务器程序）查看远程计算机有哪些文件，然后把文件从远程计算机上拷到本地计算机，或把本地计算机的文件送到远程计算机去。FTP用的比NFS更多，所以请你一定要熟练配置它。 安装pure-ftpd在CentOS或者RedHat Linux上有自带的ftp软件叫做vsftp,这里使用pure-ftpd搭建ftp服务器，因为这个软件比vsftp配置起来更加灵活和安全。 1. 下载软件pure-ftpd 官网是 http://www.pureftpd.org/project/pure-ftpd。 2. 安装软件123456789101112131415cd /usr/local/src/tar jxf pure-ftpd-1.0.42.tar.bz2 #解压缩cd pure-ftpd-1.0.42./configure \--prefix=/usr/local/pureftpd \--without-inetd \--with-altlog \--with-puredb \--with-throttling \--with-peruserlimits \--with-tls#编译makemake install 配置pure-ftpd1. 修改配置文件12345cd configuration-filemkdir -p /usr/local/pureftpd/etc/cp pure-ftpd.conf /usr/local/pureftpd/etc/pure-ftpd.confcp pure-config.pl /usr/local/pureftpd/sbin/pure-config.plchmod 755 /usr/local/pureftpd/sbin/pure-config.pl 把配置文件修改为： 12345678910111213141516171819202122232425262728ChrootEveryone yesBrokenClientsCompatibility noMaxClientsNumber 50Daemonize yesMaxClientsPerIP 8VerboseLog noDisplayDotFiles yesAnonymousOnly noNoAnonymous noSyslogFacility ftpDontResolve yesMaxIdleTime 15PureDB /usr/local/pureftpd/etc/pureftpd.pdbLimitRecursion 3136 8AnonymousCanCreateDirs noMaxLoad 4AntiWarez yesUmask 133:022MinUID 100AllowUserFXP noAllowAnonymousFXP noProhibitDotFilesWrite noProhibitDotFilesRead noAutoRename noAnonymousCantUpload noPIDFile /usr/local/pureftpd/var/run/pure-ftpd.pidMaxDiskUsage 99CustomerProof yes 2. 启动pure-ftpd1/usr/local/pureftpd/sbin/pure-config.pl /usr/local/pureftpd/etc/pure-ftpd.conf 如果是启动成功，会出现： 1Running: /usr/local/pureftpd/sbin/pure-ftpd -A -c50 -B -C8 -D -fftp -H -I15 -lpuredb:/usr/local/pureftpd/etc/pureftpd.pdb -L3136:8 -m4 -s -U133:022 -u100 -g/usr/local/pureftpd/var/run/pure-ftpd.pid -k99 -Z 如果失败需要重启的话,可以使用下面的命令来实现。 12killall purerf-ftpd/usr/local/pureftpd/sbin/pure-config.pl /usr/local/pureftpd/etc/pure-ftpd.conf 3. 建立账号123456mkdir /tmp/ftpuseradd user3chown -R user3 /tmp/ftp/usr/local/pureftpd/bin/pure-pw useradd ftp_user1 -uuser3 -d /tmp/ftpPassword:Enter it again: 其中，-u将虚拟用户ftp_user1与系统用户uesr3关联在一起，也就是说使用ftp_user1账号登陆ftp后，会以uesr3的身份来读取文件或下载文件。-d后边的目录为ftp_user1账户的家目录，这样可以使ftp_user1只能访问其家目录/tmp/ftp.到这里还未完成，还有最关键的一步，就是创建用户信息数据库文件: 1/usr/local/pureftpd/bin/pure-pw mkdb pure-pw还可以列出当前的ftp账号，当然也可以删除某个账号, 我们再创建一个账号: 12/usr/local/pureftpd/bin/pure-pw useradd ftp_user2 -uuser3 -d /tmp/ftp/usr/local/pureftpd/bin/pure-pw mkdb 列出当前账号: 1/usr/local/pureftpd/bin/pure-pw list 删除账号的命令为: 1/usr/local/pureftpd/bin/pure-pw userdel ftp_user2 4. 测试pure-ftpd测试需要使用的工具叫做lftp, 先安装一下它: 1yum install -y lftp 测试： 123456789lftp ftpuser1@192.168.189.131口令: lftp ftpuser1@192.168.189.131:~&gt; ls drwxr-xr-x 2 504 0 4096 Mar 20 19:57 .drwxr-xr-x 2 504 0 4096 Mar 20 19:57 ..-rw-r--r-- 1 0 0 0 Mar 20 19:57 1.txt-rw-r--r-- 1 0 0 0 Mar 20 19:57 2.txt-rw-r--r-- 1 0 0 0 Mar 20 19:57 3 注意：在登录lftp后可以使用的命令与在shell中是不一样的，通过？可以查询： 1234567891011121314lftp ftpuser1@192.168.189.131:~&gt; ? !&lt;shell-command&gt; (commands) alias [&lt;name&gt; [&lt;value&gt;]] bookmark [SUBCMD] cache [SUBCMD] cat [-b] &lt;files&gt; cd &lt;rdir&gt; chmod [OPTS] mode file... close [-a] [re]cls [opts] [path/][pattern] debug [&lt;level&gt;|off] [-o &lt;file&gt;] du [options] &lt;dirs&gt; exit [&lt;code&gt;|bg] get [OPTS] &lt;rfile&gt; [-o &lt;lfile&gt;] glob [OPTS] &lt;cmd&gt; &lt;args&gt; help [&lt;cmd&gt;] history -w file|-r file|-c|-l [cnt] jobs [-v] kill all|&lt;job_no&gt; lcd &lt;ldir&gt; lftp [OPTS] &lt;site&gt; ls [&lt;args&gt;] mget [OPTS] &lt;files&gt; mirror [OPTS] [remote [local]] mkdir [-p] &lt;dirs&gt; module name [args] more &lt;files&gt; mput [OPTS] &lt;files&gt; mrm &lt;files&gt; mv &lt;file1&gt; &lt;file2&gt; [re]nlist [&lt;args&gt;] open [OPTS] &lt;site&gt; pget [OPTS] &lt;rfile&gt; [-o &lt;lfile&gt;] put [OPTS] &lt;lfile&gt; [-o &lt;rfile&gt;] pwd [-p] queue [OPTS] [&lt;cmd&gt;] quote &lt;cmd&gt; repeat [OPTS] [delay] [command] rm [-r] [-f] &lt;files&gt; rmdir [-f] &lt;dirs&gt; scache [&lt;session_no&gt;] set [OPT] [&lt;var&gt; [&lt;val&gt;]] site &lt;site_cmd&gt; source &lt;file&gt; torrent [-O &lt;dir&gt;] &lt;file&gt; user &lt;user|URL&gt; [&lt;pass&gt;] version wait [&lt;jobno&gt;] zcat &lt;files&gt; zmore &lt;files&gt; 下载文件使用get命令，会自动下载到当前目录；上传当前目录的文件可以用put命令。 12345lftp ftpuser1@192.168.189.131:/&gt; get a.txt 101 bytes transferredlftp ftpuser1@192.168.189.131:~&gt; put graped.1 35 bytes transferred 在linux下还有一个测试工具是ftp，也需要通过yum安装。在windows可以使用filezilla软件测试。]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS部署和优化]]></title>
    <url>%2F2017%2F03%2F20%2F17032001%2F</url>
    <content type="text"><![CDATA[服务端配置NFSCentOS上使用NFS服务，需要安装两个包(nfs-utils和rpcbind),不过当使用yum安装nfs-utils 时会把rpcbind一起安装上 1yum install -y nfs-utils rpcbind 修改配置文件，默认该文件为空，现在编辑它:1vim /etc/exports 写入以下内容： 1/mnt 192.168.189.0/24(rw,sync,all_squash,anonuid=501,anongid=501) 这个配置文件就这样简单一行。共分为三部分，第一部分就是本地要共享出去的目录，第二部分为允许访问的主机（可以是一个IP也可以是一个IP段）第三部分就是小括号里面的，为一些权限选项。下面简单介绍以下权限选项： w ：读写； ro ：只读； sync ：同步模式，内存中数据时时写入磁盘； async ：不同步，把内存中数据定期写入磁盘中； no_root_squash ：加上这个选项后，root用户就会对共享的目录拥有至高的权限控制，就像是对本机的目录操作一样。不安全，不建议使用； root_squash：和上面的选项对应，root用户对共享目录的权限不高，只有普通用户的权限，即限制了root； all_squash：不管使用NFS的用户是谁，他的身份都会被限定成为一个指定的普通用户身； anonuid/anongid ：要和root_squash 以及all_squash一同使用，用于指定使用NFS的用户限定后的uid和gid，前提是本机的/etc/passwd中存在这个uid和gid。 我们刚才配置的文件意思为：其中分享的目录为/mnt，信任的主机为：192.168.189.0/24这个网段，权限为读写，同步，限定所有使用者，并且限定的uid和gid都为501。 编辑好配置文件后，就该启动NFS服务了12/etc/init.d/rpcbind start/etc/init.d/nfs start 客户端上挂载nfs客户端在挂载NFS之前，我们需要先看一看服务端都共享了哪些目录 123showmount -e 192.168.189.131 #IP为服务端IPExport list for 192.168.189.131:/mnt 192.168.189.0/24 可以看到共享的目录为/mnt 信任的IP为192.168.189.0/24这个网段 挂载1234567mount -t -onolock,nfsver=3 192.168.189.131:/mnt /opt #-o后面跟挂载选项，如果不加nfsver=3 则挂载目录下的文件属主和组都是nobodydf -hFilesystem Size Used Avail Use% Mounted on/dev/sda3 18G 1.4G 16G 9% /tmpfs 504M 0 504M 0% /dev/shm/dev/sda1 194M 25M 160M 14% /boot192.168.189.131:/mnt 18G 2.8G 14G 17% /opt 可以看到在多出来一个 /opt分区，它就是NFS的共享目录。 命令exportfs该命令的个选项意义为： -a ：全部挂载或者卸载； -r ：重新挂载； -u ：卸载某一个目录； -v ：显示共享的目录； 当改变/etc/exports配置文件后，不用重启nfs服务而直接用exportfs -arv即可。-o还有一个选项是-o nolock 了，即在挂载nfs服务时，不加锁。 启用这个选项后，我们可以把要挂载的nfs目录写到client上的/etc/fstab文件中： 1192.168.189.131:/tmp/ /test nfs nolock 0 0 挂载时只需要执行 mount -a 即可。 1234567[root@Grapedlinux ~]# mount -a[root@Grapedlinux ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/sda3 18G 1.4G 16G 9% /tmpfs 504M 0 504M 0% /dev/shm/dev/sda1 194M 25M 160M 14% /boot192.168.189.131:/tmp/ 18G 2.8G 14G 17% /test]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25个shell脚本代码分享]]></title>
    <url>%2F2017%2F03%2F19%2F17031901%2F</url>
    <content type="text"><![CDATA[25个shell脚本代码分享引言自己写了一下小的shell实例，虽然很小，但所有的大的程序都是由小的模块推挤起来的。，就分享几个linux的shell脚本吧。 模拟linux登录shell 123456789#/bin/bashecho -n &quot;login:&quot;read name echo -n &quot;passsword&quot;read passwordif [$name = &quot;cht&quot; -a $password = &quot;abc&quot;];then echo &quot;the gost and password is right!&quot;else echo &quot;input is error!&quot;fi 比较两个数的大小 12345678910#/bin/bashecho &quot;please enter two number&quot;read aread bif test $a -eq $bthen echo &quot;NO.1 = NO.2&quot;elif test $a -gt $b then echo &quot;NO.1 &gt; NO.2&quot;else echo &quot;NO.1 &lt; NO.2&quot;fi 查找/root/目录下是否存在该文件 1234567#/bin/bashecho &quot;enter a file name:&quot;read a if test -e /root/$athen echo &quot;the file is exist!&quot;else echo &quot;the file is not exist!&quot;fi for循环的使用 123456#/bin/bashclear for num in 1 2 3 4 5 6 7 8 9 10do echo &quot;$num&quot;done 命令输入 12345678#/bin/bashecho &quot;please enter a user:&quot;read a b = $(whoami)if test $a = $bthen echo &quot;the user is running.&quot;else echo &quot;the user is not running.&quot;fi 删除当前目录下大小为0的文件 123456789101112#/bin/bashfor filename is &apos;ls&apos;do if test -d $filename then b=0 else a=$(ls -l $filename | awk &apos;&#123;print $5&#125;&apos;) if test $a -eq 0 then rm $filename fi fidone 如果/export/um_lpp_source下有文件，那么将其文件系统大小改为3G 1234567891011#/bin/bashwhlie line= &apos;ls /export/um_lpp_source&apos;do if test $line=&quot;&quot; then echo &quot;NULL&quot; sleep 1 else echo $line chfs -a size=3G /export/um_lpp_source exit () fidone 测试IP地址 123456#/bin/bashfor i in 1 2 3 4 5 6 7 8 9do echo &quot;the number if $i computer is&quot; ping -c 192.168.0.$idone 如果test.log的大小大于0，那么将/opt目录下的*.tar.gz 123456789101112#/bin/sha=2while name=&quot;test.log&quot;do sleep 1 b=$(ls -l $name | awk &apos;&#123;print $5&#125;&apos;) if test $b -ge $a then echo &quot;OK&quot;then `cp /opt/*.tar.gz .` exit 0 fidone 打印读取的内容，为下面的例子做准备 12345#/bin/bashwhile read namedoecho $namedone 从0.sh中读取内容并打印 12345/bin/bashwhile read linedo echo $linedone &lt; 0.sh 读取a.c中的内容并做加1运算 1234567#/bin/bashtest -e a.cwhile read linedo a=$(($line+1))done &lt; a.cecho $a 普通无参数函数 123456#/bin/bashp ()&#123;echo &quot;hello&quot;&#125;p 给函数传递参数 12345678910#/bin/bashp_num ()&#123; num=$1 echo $num&#125;for n in $@do p_num $ndone 创建文件夹 1234567891011121314#/bin/bashwhile :do echo &quot;pleasenput file&apos;s name:&quot; read a if test -e /root/$a then echo &quot;the file is existing Please input new file name:&quot; else mkdir $a echo &quot;you aye sussesful!&quot; break fidone 获取本机IP地址 12#/bin/bashifconfig | grep &quot;inet addr:&quot; | awk &apos;&#123; print $2 &#125;&apos;| sed &apos;s/addr://g&apos; 查找最大文件 1234567891011#/bin/basha=0for name in *.*do b=$(ls -l $name | awk &apos;&#123;print $5&#125;&apos;) if test $b -ge $a then a=$b namemax=$name fidoneecho &quot;the max file is $namemax&quot; 查找当前网段内IP用户，重定向到ip.txt文件中 12345678910111213#/bin/basha=1while :do a=$(($a+1)) if test $a -gt 255 then break else echo $(ping -c 1 192.168.0.$a | grep &quot;ttl&quot; | awk &apos;&#123;print $4&#125;&apos;| sed &apos;s/://g&apos;) ip=$(ping -c 1 192.168.0.$a | grep &quot;ttl&quot; | awk &apos;&#123;print $4&#125;&apos;| sed &apos;s/://g&apos;) echo $ip &gt;&gt; ip.txt fidone 打印当前用户 123#/bin/bashecho &quot;Current User is :&quot;echo $(ps | grep &quot;$$&quot; | awk &apos;&#123;print $2&#125;&apos;) case语句练习 123456789101112131415161718#!/bin/bashclearecho &quot;enter a number from 1 to 5:&quot;read numcase $num in 1) echo &quot;you enter 1&quot; ;; 2) echo &quot;you enter 2&quot; ;; 3) echo &quot;you enter 3&quot; ;; 4) echo &quot;you enter 4&quot; ;; 5) echo &quot;you enter 5&quot; ;; *) echo &quot;error&quot; ;;esac yes/no返回不同的结构 123456789101112#!/bin/bashclearecho &quot;enter [y/n]:&quot;read acase $a in y|Y|Yes|YES) echo &quot;you enter $a&quot; ;; n|N|NO|no) echo &quot;you enter $a&quot; ;; *) echo &quot;error&quot; ;;esac 杀进程 12345#/bin/bashpid=&apos;ps -ef|grep &apos;进程相关内容&apos; |grep -v &apos;grep&apos;|awk &apos;&#123;print $2&#125;&apos;&apos;if [-n &quot;$pid&quot;];then kill -9 $pidfi 内置命令的使用 12345678910111213141516#/bin/bashclear echo &quot;Hello, $USER&quot; echo echo &quot;Today &apos;s date id `date`&quot; echo echo &quot;the user is :&quot; who echo echo &quot;this is `uname -s`&quot; echo echo &quot;that&apos;s all folks! &quot; 打印无密码用户 123#/bin/bashecho &quot;No Password User are :&quot;echo $(cat /etc/shadow | grep &quot;!!&quot; | awk &apos;BEGIN &#123; FS=&quot;:&quot; &#125;&#123;print $1&#125;&apos;) 检查端口号是否已经启动 12345678910111213141516171819#!/bin/bashn=1echo &quot;检查xxx服务...&quot;while truedo if test $n -gt 20 then echo &quot;xxx服务启动失败&quot; break fi sleep 5 n=$(($n+1)) port=`netstat -antp | grep &quot;0.0.0.0:8080&quot;` if [ $&#123;#port&#125; -gt 3 ]; then echo &quot;xxx服务已经启动&quot; break; fidone]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php-fpm 配置文件]]></title>
    <url>%2F2017%2F03%2F13%2F17031301%2F</url>
    <content type="text"><![CDATA[先清空php-fpm.conf &gt; /usr/local/php/etc/php-fpm.conf 输入以下内容： [global] pid = /usr/local/php/var/run/php-fpm.pid error_log = /usr/local/php/var/log/php-fpm.log [www] listen = /tmp/php-fcgi.sock user = php-fpm group = php-fpm pm = dynamic pm.max_children = 50 pm.start_servers = 20 pm.min_spare_servers = 5 pm.max_spare_servers = 35 pm.max_requests = 500 rlimit_files = 1024 说明global部分是全局配置，指定pid文件路径已经error_log 路径。 [www] 是一个pool，其实我们还可以再写第二个pool，第二个pool和第一个不一样的地方，首先pool的name，比如叫做[www2]。然后listen肯定就不一样了，比如可以listen=/tmp/php-fcgi2.sock。而user，group也可以和[www]定义不一样。listen.owner这个是定义/tmp/php-fcgi.sock 这个文件的所有者是谁，在php4.5版本之后监听的socket文件权限默认变成了rw——-，如果不定义listen.owner 那么nginx调用这个socket的时候就没有权限了，故在这里我们定义listen.owner为nginx的子进程监听用户。 pm = dynamic 表示以动态的形式启动，在php5.3 版本以后它可以支持动态和静态了，如果是静态，即 pm=static 时，下面的配置只有 pm.max_children 管用。 pm.max_children 表示启动几个php-fpm 的子进程。如果是 dynamic，下面的配置会生效， pm.max_children 表示最大可以启动几个子进程。 pm.start_services 表示一开始有几个子进程 pm.min_spare_servers = 5 表示当php-fpm 空闲时最少要有几个子进程，即如果空闲进程小于此值，则创建新的子进程。 pm.max_spare_servers = 35 表示当php-fpm 空闲时最多要有几个子进程，即如果空闲进程大于此值，则会清理。 pm.max_requests = 500 表示一个子进程最多可以接受多少个请求，比如设置500那么一个进程受理500个请求后自动销毁。 rlimit_files = 1024 表示每个子进程打开的多少个文件句柄。 slowlog = /tmp/www_slow.log 排查网站哪里慢的原因日志 request_slowlog_timeout = 1 和上面的man日志在一起使用 php_admin_value[open_basedir]=/data/www/:/tmp/ 设置多个目录]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 代理详解]]></title>
    <url>%2F2017%2F03%2F12%2F17031211%2F</url>
    <content type="text"><![CDATA[编辑配置文件： vim /usr/local/nginx/conf/vhost/proxy.conf 加入： upstream graped { server 115.239.211.112:80; server 115.239.211.112:80; } server { listen 80; server_name www.baidu.com; location / { proxy_pass http://graped/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; } }]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 禁止指定 user_agent]]></title>
    <url>%2F2017%2F03%2F12%2F17031210%2F</url>
    <content type="text"><![CDATA[编辑配置文件： vim /usr/local/nginx/conf/vhosts/test.conf 加入 if ($http_user_agent ~ &apos;curl|baidu|111111&apos;) { return 403; } 若不想区分大小写，可以写为： if ($http_user_agent ~* &apos;curl|baidu|111111&apos;) { return 403; }]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 配置防盗链]]></title>
    <url>%2F2017%2F03%2F12%2F17031209%2F</url>
    <content type="text"><![CDATA[编辑配置文件：vim /usr/local/nginx/conf/vhosts/test.conf 加入：location ~ .*.(gif|jpg|jped|png|bmp|swf|flv|rar|zip|gz|bz2)$ { access_log off; expires 15d; valid_referers none blocker server_names *.taobao.com *.test.com *.aaa.com *.apelearn.com; if ($invalid_referer) { return 403; } }]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 配置静态文件过期时间]]></title>
    <url>%2F2017%2F03%2F12%2F17031208%2F</url>
    <content type="text"><![CDATA[编辑配置文件：vim /usr/local/nginx/conf/vhosts/test.conf 加入： location ~ .*.(gif|jpg|jped|png|bmp|swf)$ { access_log off; expires 15d; } location ~ \.(js|css) { access_log off; expires 2h; }]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx日志切割]]></title>
    <url>%2F2017%2F03%2F12%2F17031207%2F</url>
    <content type="text"><![CDATA[一、写一个nginx日志切割脚本vim /usr/local/sbin/nginx_logrotate.sh #!/bin/bashd=date -d &quot;-1 day&quot; +%Y%m%d[ -d /tmp/nginx_log ] || mkdir /tmp/nginx_logmv /tmp/access.log /tmp/nginx_log/$d.log/etc/init.d/nginx reload &gt; /dev/nullcd /tmp/nginx_log/gzip -f $d.log 然后写一个计划任务，每天0点0分执行脚本。 二、借助系统的logrotate 工具实现vim /etc/logrotate.d/nginx加入一下内容/tmp/access_log { //日志的路径Daily // 表示日志按天归档Missingok // 表示忽略所有错误，例如在日志不存在的情况下rotate 52 // 表示日志存放的个数，最多52compress // 表示日志要压缩delaycompress // 表示压缩除了当前和最近之外的所有其他版本notifempty // 表示如果日志为空，则不归档。create 644 nobody nobody // 定义归档日志的权限已经所属组，主。sharedscripts // 表示所有日志共享此脚本，postrotate // 后面跟轮换过日志之后要运行的命令[ -f /usr/local/nginx/var/nginx.pid] &amp;&amp; kill -USR1 cat /usr/local/nginx/var/nginx.pidEndscript D// 结束。}]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 不记录指定文件类型的日志]]></title>
    <url>%2F2017%2F03%2F12%2F17031206%2F</url>
    <content type="text"><![CDATA[一、日志格式在nginx.conf 中定义日志格式，配置如下：log_format main ‘$remote_addr - $remote_user [$time_local] $request ‘ ‘“$status” $body_bytes_sent “$http_referer” ‘ ‘“$http_user_agent” “$http_x_forwarded_for”‘; log_format main1 ‘$proxy_add_x_forwarded_for - $remote_user [$time_local] ‘ ‘“$request” $status $body_bytes_sent ‘ ‘“$http_referer” “$http_user_agent”‘; //此日志格式为，ip不仅记录代理的ip还记录远程客户端真实IP。 二、错误日志级别在nginx.conf 中有定义错误日志级别的语句：error_log /usr/local/nginx/logs/nginx_error.log crit;crit表示为crit级别，该级别记录的日志最少。另外还有debug、info、notice、warn、error等。如果502错误比较频繁的出现，建议把级别改为error，以便在更为丰富的错误日志中找到原因。 三、某些类型的文件不记录日志不记录gif、jpg、jped、png、bmp、swf、js、ccs 文件类型的日志。 location ~ .*\.(gif|jpg|jped|png|bmp|swf|js|ccs)$ { access_log off; }]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx域名跳转]]></title>
    <url>%2F2017%2F03%2F12%2F17031205%2F</url>
    <content type="text"><![CDATA[编辑配置文件，修改为： server{ listen 80; server_name www.test.com www.aaa.com www.bbb.com; if ($host != ‘www.test.com&#39;) { rewrite ^/(.)$ http://www.test.com/$1 permanent; } index index.html index.htm index.php; root /data/www; location ~ .admin.php$ { auth_basic “grapedlinux auth”; auth_basic_user_file /usr/local/nginx/conf/.htpasswd; include fastcgi_params; fastcgi_pass unix:/tmp/www.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data/www$fastcgi_script_name; }]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 用户认证]]></title>
    <url>%2F2017%2F03%2F12%2F17031204%2F</url>
    <content type="text"><![CDATA[在nginx虚拟主机中添加：location ~ .*admin.php$ { auth_basic “grapedlinux auth”; auth_basic_user_file /usr/local/nginx/conf/.htpasswd; include fastcgi_params; fastcgi_pass unix:/tmp/www.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data/www$fastcgi_script_name; } 并用htpasswd工具生成密码文件：/usr/local/apache2/bin/htpasswd -c /usr/local/nginx/conf/.htpasswd graped 这样便只有在输入账户密码后才可以访问。]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见的 502 问题解决]]></title>
    <url>%2F2017%2F03%2F12%2F17031203%2F</url>
    <content type="text"><![CDATA[对于LNMP来说，最常见的就是502问题了，配置完环境后，一访问网站直接提示“502 Bad GateWay”。出现502的最大原因大致分为这两种。 一、配置错误。location ~ .php$ { root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/local/nginx/html$fastcgi_script_name; include fastcgi_params;} 如果把fastcgi_pass 后面指定的路径配置错了，那么就会出现502的错误，因为nginx找不到php-fpm了。fastcgi_pass后面可以跟socket 也可以跟ip:port，默认的监听地址为：127.0.0.1:9000。 二、资源耗尽。LNMP架构处理php时，是nginx直接调去后端的php-fpm服务，如果nginx的请求量偏高，而我们又没有给php-fpm配置足够的子进程，那么总有php-fpm资源耗尽的时候，一旦耗尽nginx则找不到php-fpm，此时就会导致502出现。那这时候的解决方案就是去调整php-fpm.conf 中的php.max_children的数值，使其增加。但也不能无限设置，毕竟服务器的资源有限，根据经验，4G内存机器如果只跑php-fpm和nginx，不跑mysql服务，php.max_children可以设置为150，精良不要超过该数值，8G可以设置成300一次类推。 如果不是以上两种错误，可以通过查看日志文件来排查错误，]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[测试PHP解析]]></title>
    <url>%2F2017%2F03%2F12%2F17031202%2F</url>
    <content type="text"><![CDATA[● 配置nginx配置文件 ○ vim /usr/local/nginx/conf/nginx.conf ● 取消下列各行的注释，并修改 SCRIPT_FILENAME/usr/local/nginx/html$fastcgi_script_name ○ location ~ .php$ { ○ root html; ○ fastcgi_pass 127.0.0.1:9000; ○ fastcgi_index index.php; ○ fastcgi_param SCRIPT_FILENAME /usr/local/nginx/html$fastcgi_script_name; ○ include fastcgi_params; ○ } ● 测试配置文件是否正确 ○ /usr/local/nginx/sbin/nginx -t ● 若正确则表明正确 ○ nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok ○ nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful ● 重新加载配置文件 ○ /usr/local/nginx/sbin/nginx -s reload ● 创建测试文件 ○ vim /usr/local/nginx/html/info.php ○ &lt;?php ○ phpinfo(); ○ ?&gt; ● 在浏览器中输入ip地址，若访问成功则PHP解析成功]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx编译安装]]></title>
    <url>%2F2017%2F03%2F12%2F17031201%2F</url>
    <content type="text"><![CDATA[● 下载nginx ○ cd /usr/locar/src ○ wget http://nginx.org/download/nginx-1.8.0.tar.gz ● 解压 ○ tar zxvf nginx-1.8.0.tar.gz ● 编译配置参数 ○ cd nginx-1.8.0./configure \–prefix=/usr/local/nginx \–with-http_realip_module \–with-http_sub_module \–with-http_gzip_static_module \–with-http_stub_status_module \–with-pcre ● 编译nginx ○ make ● 安装nginx ○ make install ● 启动nginx ○ /usr/local/nginx/sbin/nginx]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php 编译安装]]></title>
    <url>%2F2017%2F03%2F12%2F17031200%2F</url>
    <content type="text"><![CDATA[● 下载php ○ cd /usr/local/src ○ wget http://cn2.php.net/distributions/php-5.4.37.tar.bz2 ● 解压php ○ tar jxvf php-5.4.37.tar.bz2 ● 创建相关账户 ○ useradd -s /sbin/nologin php-fpm ● 配置编译参数 ./configure \ --prefix=/usr/local/php \ --with-config-file-path=/usr/local/php/etc \ --enable-fpm \ --with-fpm-user=php-fpm \ --with-fpm-group=php-fpm \ --with-mysql=/usr/local/mysql \ --with-mysql-sock=/tmp/mysql.sock \ --with-libxml-dir \ --with-gd \ --with-jpeg-dir \ --with-png-dir \ --with-freetype-dir \ --with-iconv-dir \ --with-zlib-dir \ --with-mcrypt \ --enable-soap \ --enable-gd-native-ttf \ --enable-ftp \ --enable-mbstring \ --enable-exif \ --disable-ipv6 \ --with-pear \ --with-curl \ --with-openssl ● 编译php ○ make ● 安装php ○ make install ● 修改配置文件 ○ cp php.ini-production /usr/local/php/etc/php.ini ○ vim /usr/local/php/etc/php-fpm.conf ● 把如下内容加入该文件： [global] pid = /usr/local/php/var/run/php-fpm.pid error_log = /usr/local/php/var/log/php-fpm.log [www] listen = /tmp/php-fcgi.sock user = php-fpm group = php-fpm pm = dynamic pm.max_children = 50 pm.start_servers = 20 pm.min_spare_servers = 5 pm.max_spare_servers = 35 pm.max_requests = 500 rlimit_files = 1024 ● 保存配置文件后，检验配置是否正确的方法为: /usr/local/php/sbin/php-fpm -t ● 若正确则会出现 NOTICE: configuration file /usr/local/php/etc/php-fpm.conf test is successful ● 拷贝启动脚本 cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm ● 授予执行权限 chmod 755 /etc/init.d/php-fpm ● 加入系统服务列表 chkconfig --add php-fpm chkconfig php-fpm on ● 启动 service php-fpm start]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令find的35个实例]]></title>
    <url>%2F2017%2F03%2F11%2F17040402%2F</url>
    <content type="text"><![CDATA[本文大部分参考来自http://www.tecmint.com/35-practical-examples-of-linux-find-command/。之前在CSDN上看过一篇类似的，但是翻译出现了很大的问题。这里我自己重新翻译测试，并整理，如有不足还请谅解。Linux 查找命令是Linux系统中最重要和最常用的命令之一。查找用于根据与参数匹配的文件指定的条件来搜索和查找文件和目录列表的命令。查找可以在各种条件下使用，您可以通过权限，用户，组，文件类型，日期，大小等可能的条件查找文件。 通过这篇文章，我们以实例的形式分享我们的日常Linux查找命令体验及其用法。在本文中，我们将向您展示Linux中最常用的35查找命令示例。我们将该部分分为五个部分，从基本到提前使用find命令。 第一部分：查找名称查找文件的基本查找命令 第二部分：根据他们的权限查找文件 第三部分：基于所有者和组的搜索文件 第四部分：根据日期和时间查找文件和目录 第五部分：根据大小查找文件和目录 第六部分：在Linux中查找多个文件名 第一部分 - 查找名称查找文件的基本查找命令1.使用当前目录中的名称查找文件，例如，在当前工作目录中查找名称为test.c的所有文件。1find test.c 2.在主目录下查找文件，例如，查找/ home目录下的所有文件，名称为test。1find /home -name test 3.使用名称和忽略案例查找文件，例如，找到名称为test的所有文件，并在/ home目录中同时包含大写和小写字母。1find /home -iname test 4.使用名称查找目录，例如：在/目录中查找名称为test的所有目录。1find / -type d -name test 5.使用名称查找PHP文件1find -type f test.php 6.查找目录中的所有PHP文件1find -type f &quot;*.php&quot; 第二部分 - 根据他们的权限查找文件7.查找权限为777的所有文件1find type f -perm 0777 -print 8.查找所有没有777权限的文件1find / type ! -perm 777 9.查找权限设置为644的所有SGID位文件。1find / -perm 2644 10.找到具有551权限的粘滞位文件,查找权限为551的所有Sticky Bit设置文件。1find / -perm 1551 11.查找SUID文件,查找所有SUID集文件。1find / -perm /u=s 12.查找SGID文件,查找所有SGID设置文件1find / -perm /u=s 13.查找只读文件,查找所有只读文件。1find / -perm /u=r 14.查找可执行文件,查找所有可执行文件。1find / -perm /u=x 15.找到777个权限和Chmod到644的文件,查找所有777个权限文件，并使用chmod命令将权限设置为644.1find / -type f -perm 0777 -print -exec chmod 644 &#123;&#125; \; 16.找到具有777个权限的目录和Chmod到755,查找所有777个权限目录，并使用chmod命令将权限设置为755。1find / -type d -perm 777 -print -exec chmod 755 &#123;&#125; \; 17.查找并删除单个文件,找到一个名为test.c的文件并将其删除1find -type f -name &quot;test.c&quot; -exec rm -f &#123;&#125; \; 18.查找并删除多个文件,查找和删除多个文件，如.mp31find -type f -name &quot;*.mp3&quot; -exec rm -f &#123;&#125; \; 19.查找所有空文件,在特定路径下查找所有空文件。1find /tmp -type f -empty 20.查找所有空目录1find / -type d -empty 21.文件所有隐藏文件,要查找所有隐藏的文件，请使用以下命令。1find / -type f -name &quot;.*&quot; 第三部分 - 基于所有者和组的搜索文件22.查找基于用户的单个文件,在所有者root的/root目录下查找名为test.c的所有或单个文件。1find / -user root -name test.c 23.查找基于用户的所有文件,查找~目录下属于用户neil的所有文件。1find ~ -user neil 24.查找基于组的所有文件,查找/ home目录下属于Group Developer的所有文件。1find /home -group developer 25.查找用户的特定文件,查找~目录下的用户neil的所有.c文件1find ~ -uesr neil -iname &quot;*.c&quot; 第四部分 - 根据日期和时间查找文件和目录26.查找最近50天修改的文件1find / -mtime 50 27.查找最近50天访问的文件1find / -atime 50 28.查找最后50-100天修改的文件1find / -mtime +50 –mtime -100 29.在过去1小时内查找更改的文件1find / -cmin -60 30.在最近1小时内查找修改的文件1find / -mmin -60 31.查找最近1小时内访问的文件1find / -amin -60 第五部分 - 根据大小查找文件和目录32.找到50MB的文件1find / -size 50M 33.查找大小在50MB到100MB之间1find / -size +50M -size -100M 34.查找并删除100MB的文件1find / -size +100M -exec rm -rf &#123;&#125; \; 35.查找特定文件并删除，查找超过10MB的所有.mp3文件，并使用一个命令删除它们1find / -type f -name *.mp3 -size +10M -exec rm &#123;&#125; \;]]></content>
      <categories>
        <category>command</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux调优]]></title>
    <url>%2F2017%2F03%2F11%2F17031101%2F</url>
    <content type="text"><![CDATA[一、硬件方面 ● cpu ● 内存 （增加内存） ● 存储 （使用raid，使用ssd) ● 网卡 （使用千兆网卡，或者双网卡绑定） 二、系统方面 ● 内核参数优化（网络相关、内存相关、缓冲缓存相关） ● 文件系统方面（分区调优，格式化时根据存储文件特性，指定合适的块大小，noatime，日志隔离，软raid，有效使用/dev/shm，关闭不必要的服务） ● cpu优化 （进程绑定，中断绑定） 三、应用程序方面 ● nginx、apache、php-fpm、mysql、tomcat、squid等应用，是可以通过调节各个参数获得性能优化的。 ● web优化，比如可以把用户请求合并（js、css合并），使用cdn加速静态页访问速度，把图片文档压缩减少带宽传输， ● 优化网站程序 四、架构方面 ● 使用简单并且稳定的架构方案 ● 多使用缓存（squid,varnish,memcache,nosql相关：redis，mongodb) 五、参考方案 ● http://os.51cto.com/art/201303/385726.htm （调优那些事） ● http://www.111cn.net/sys/linux/58433.htm （io/系统/内存性能调优） ● http://hong.im/2013/04/20/linux-tcp-tuning/ （高流量大并发Linux TCP 性能调优） ● http://wenku.baidu.com/view/0985c9dba58da0116c1749ae.html （文库–LINUX性能调优方法总结） ● http://my.oschina.net/sharelinux/blog?catalog=289503 （浅谈linux性能调优系列） ● http://colobu.com/2014/09/18/linux-tcpip-tuning/ （TCP/IP协议栈） ● https://blog.linuxeye.com/379.html（mysql调优） ● http://www.tuicool.com/articles/RbUNn2 （nignx+php-fpm 高并发参数配置及linux内核参数优化） ● http://blog.csdn.net/wangsg2014/article/details/38804873 （nignx参数优化） ● http://os.51cto.com/art/201003/192112.htm （apache参数优化） ● http://www.phpboy.net/apache/488.html（apache参数优化） ● http://www.360doc.com/relevant/178008993_more.shtml （apache参数优化文档库） ● http://www.cnblogs.com/R-zqiang/archive/2012/06/12/2545768.html (php.ini参数优化） ● http://www.cnblogs.com/ggjucheng/archive/2013/04/16/3024731.html （tomcat调优） ● http://www.php-oa.com/2008/02/03/squidyouhua.html （squid调优） ● http://www.neters.cn/archives/548.html （squid优化指南） ● http://handao.blog.techweb.com.cn/archives/134.html （squid优化相关的内核参数调整）]]></content>
      <categories>
        <category>system</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
</search>
